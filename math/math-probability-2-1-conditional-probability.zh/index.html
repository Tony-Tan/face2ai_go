<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>【概率论】2-1:条件概率(Conditional Probability) | 谭升的博客</title><meta name=keywords content="条件概率,乘法原理,全概率公式"><meta name=description content="Abstract: 本文介绍条件概率的定义及相关知识，提出全概率公式
Keywords: Conditional Probability，Multiplication Rule，Partitions
，Law of total Probability"><meta name=author content="谭升"><link rel=canonical href=https://go.face2ai.com/math/math-probability-2-1-conditional-probability.zh/><link crossorigin=anonymous href=../../assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe+FVUFzPh7U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=../../assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://go.face2ai.com/logo.png><link rel=icon type=image/png sizes=16x16 href=https://go.face2ai.com/logo.png><link rel=icon type=image/png sizes=32x32 href=https://go.face2ai.com/logo.png><link rel=apple-touch-icon href=https://go.face2ai.com/logo.png><link rel=mask-icon href=https://go.face2ai.com/logo.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-105335860-3","auto"),ga("send","pageview"))</script><meta property="og:title" content="【概率论】2-1:条件概率(Conditional Probability)"><meta property="og:description" content="Abstract: 本文介绍条件概率的定义及相关知识，提出全概率公式
Keywords: Conditional Probability，Multiplication Rule，Partitions
，Law of total Probability"><meta property="og:type" content="article"><meta property="og:url" content="https://go.face2ai.com/math/math-probability-2-1-conditional-probability.zh/"><meta property="article:section" content="math"><meta property="article:published_time" content="2018-01-31T10:34:36+00:00"><meta property="article:modified_time" content="2023-04-04T15:19:02+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="【概率论】2-1:条件概率(Conditional Probability)"><meta name=twitter:description content="Abstract: 本文介绍条件概率的定义及相关知识，提出全概率公式
Keywords: Conditional Probability，Multiplication Rule，Partitions
，Law of total Probability"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Maths","item":"https://go.face2ai.com/math/"},{"@type":"ListItem","position":3,"name":"【概率论】2-1:条件概率(Conditional Probability)","item":"https://go.face2ai.com/math/math-probability-2-1-conditional-probability.zh/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"【概率论】2-1:条件概率(Conditional Probability)","name":"【概率论】2-1:条件概率(Conditional Probability)","description":"Abstract: 本文介绍条件概率的定义及相关知识，提出全概率公式 Keywords: Conditional Probability，Multiplication Rule，Partitions ，Law of total Probability\n","keywords":["条件概率","乘法原理","全概率公式"],"articleBody":"Abstract: 本文介绍条件概率的定义及相关知识，提出全概率公式 Keywords: Conditional Probability，Multiplication Rule，Partitions ，Law of total Probability\n条件概率 关于学习看过不同人的很多说法，大部分来自“知乎（分享你新编的故事）”，虽然有些不太可信，但是有一些确实有点道理，比如有人问是否应该着重训练微积分的计算能力，其实这个问题我个人也有过，原因就是经过高考的人有点不太能把握“什么程度才能叫做一项知识学会了”，因为就算你对一个知识点非常透彻，但是还是有人能通过这个知识点创造出你完全不会解的题，于是我们就开始怀疑自己到底到底学会没学会，那微积分有必要反复做题么？有一个答案的大概意思是，反复训练微积分，就像反复训练加减法一样，过了小学，这个训练就没有必要进行了，这个似乎很有道理。 那么我们准备做机器学习的同学们有必要反复训练自己的基础算法么？比如线性回归啊，感知机啊什么的么？开始的时候当然很有必要，但是当你进入一定阶段了，就要研究其背后的分析方法的原理了，所以，会用算法，理解算法，分析算法是完全不同的层次，就像小学，大学还有博士阶段一样。所以，打好基础，学好数学，才能读博士.当然现在如火如荼的环境下，小学生就业也非常乐观。 今天继续概率论的讨论，本来想把事件的独立也添加到本文，但是后来分析了一下，内容太多容易乱，所以本文只介绍条件概率，还是那句话，好就不能快，多就不能省，虽然感觉时间紧迫，但是也要一步一步来。\n条件概率的定义 The Definition of Conditional Probability 概率本身用途有限，为什么？首先从我们的知识图上可以看到微积分，线性代数，概率论本身处于数学基础，基础很少被直接应用于平时的问题中，而概率更是如此，除了算算彩票，骰子，基本没有什么场景能完全满足概率的“条件”，但是作为基础，统计和随机过程则是非常实际的应用方法，概率对于统计的一个作用就是：当知道某个特定的事件被观察到的时候，通过概率论的知识，可以更新某些事件的概率。 比如我们观察一个试验，事件A是我们关心的，试验结束后，我们得到的关于A是否发生的信息是事件B发生了，那么此时事件A的概率被称为条件B发生时A的条件概率。\n Definition Conditional Probability: Sippose that we learn that an event B has occurred and that we wish to compute the probability of another event A taking into account that probability of the event A given that the event B has occurred and is denoted $Pr(A|B)$ . If $Pr(B)0$ ,we compute this probability as: $$ Pr(A|B)=\\frac{Pr(A\\cap B)}{Pr(B)} $$ ps:The conditional probability $Pr(A|B)$ is not defined if $Pr(B)=0$\n 翻译一下，当我们知道事件B已经发生并且我们希望计算另外一个事件A的时候考虑当B发生时A的概率，那就是条件概率 $Pr(A|B)$ 。当$Pr(B)=0$ 时，条件概率无定义\n但是我们应该注意到，所有事件的概率都是条件的，比如试验：扔一个均匀的硬币，事件A表示正面，那么概率$Pr(A)$ 的条件就是\"扔一个均匀硬币\"，如果把扔一个均匀的硬币这个事件看做事件B，那么出现正面的概率是$Pr(A|B)$ ，这里事件B是肯定发生的，所以作为条件给出，如果事件B不是肯定发生，那么就要用我们下面给出的计算法则计算正面出现的概率了。 以上是从Subjective Interpretation的角度定义的，但是从Frequency Interpretation的角度，我们可以这么理解，一个重复$N$ 次的试验事件B发生的$N_B$次数与试验次数的比例近似于$Pr(B)=\\frac{N_B}{N}$ 事件A和事件B同时发生的次数$N_{A\\cap B}$ 与试验次数$N$ 的比例近似于$Pr(A\\cap B)=\\frac{N_{A\\cap B}}{N}$，所以当B事件发生时，A事件也发生的概率接近于比例：$\\frac{N_{A\\cap B}}{N_B}=\\frac{\\frac{N_{A\\cap B}}{N}}{\\frac{N_B}{N}}=\\frac{Pr(A\\cap B)}{Pr(B)}$\n通过上面的几个表达式可以了解关于频率观点下的条件概率的计算方法。\n 举个例子： 条件描述：扔两个六面体骰子，每个面出现概率相等，两个骰子互不影响。 事件的概率：那么当我们知道其结果的和是奇数的条件下，其和小于8的事件T的概率是多少？ 分析：首先我们通过条件知道这两个骰子出现每个数字概率相等为 $\\frac{1}{6}$ 那么就可以分析出所有结果了：     event Probability     2 $\\frac{1}{36}$   3 $\\frac{2}{36}$   4 $\\frac{3}{36}$   5 $\\frac{4}{36}$   6 $\\frac{5}{36}$   7 $\\frac{6}{36}$   8 $\\frac{5}{36}$   9 $\\frac{4}{36}$   10 $\\frac{3}{36}$   11 $\\frac{2}{36}$   12 $\\frac{1}{36}$    那么： $$ Pr(A\\cap B)=\\frac{2}{36}+\\frac{4}{36}+\\frac{6}{36}=\\frac{12}{36}=\\frac{1}{3}\\ Pr(B)=\\frac{2}{36}+\\frac{4}{36}+\\frac{6}{36}+\\frac{4}{36}+\\frac{2}{36}=\\frac{1}{2} $$ Hence: $$ Pr(A|B)=\\frac{Pr(A\\cap B)}{Pr(B)}=\\frac{2}{3} $$ 2. 再举个例子，两个箱子，装着不同的螺丝，箱子A装着长螺丝7个和短螺丝3个，B装长螺丝6个短螺丝4个，这两个箱子被随机分给我们，如果我们有 $\\frac{1}{3}$ 的概率被分到箱子A，$\\frac{2}{3}$ 的概率被分到箱子B，那么当我们已知被分到A箱子的时候，我们拿出一个长螺丝的概率是多少？\n这道题看起来很复杂，当然求问题的解很简单，$\\frac{Pr(N_L\\cap A)}{Pr(A)}=\\frac{7}{7+3}$ ，但是这道明显是个分步的试验，首先得到什么样的箱子是个未知的随机事件，然后从箱子里拿螺丝还是随机事件，但是当我们已知是哪个箱子了以后，拿螺丝的过程将会被很容易的描述\n在进入下一部分之前我想简单分析下什么时候可能条件概率，第一种就是一个试验，结果被划分成不同的事件，试验结束后，可以观察到某个事件B发生了，这是我们会更新我们在试验前计算的事件A的概率，称之为条件概率$Pr(A|B)$ ；第二种是分步的试验，第二步的试验产生的事件A可能根据第一步的不同而不同，所以当第一步产生了事件B，那么事件A的概率将会被重新计算为$Pr(A|B)$ 其值等于 $\\frac{Pr(A\\cap B)}{Pr(B)}$ 的结果。 同时我们观察这个关系式可以得出$Pr(B)\\leq 1$所以$Pr(A|B)\\leq Pr(A\\cap B)$，这个关系式是确定的，但是$Pr(A|B)\\leq \\geq Pr(A)$ 之间的大小不确定。\n乘法原则 The Multiplication Rule 乘法原则在之前的计数方法里有提到过，就是分步试验每步有不同的结果，那么组合起来其满足乘法关系，这里的乘法法则是通过上面条件概率的定义得出的：\n Definition Multiplication Rule for Conditional Probability: $$ if \\quad Pr(B)0:\\quad Pr(A\\cap B)=Pr(B)Pr(A|B)\\ if \\quad Pr(A)0:\\quad Pr(A\\cap B)=Pr(A)Pr(B|A) $$\n 这两个式子是上面条件概率公式的变形，但是却有了不同含义，我们把它定义为条件概率的乘法原则\n Definition Multiplication Rule for Conditional Probability:Suppose that $A_1,A_2,A_3\\dots A_n$ are events such that $Pr(A_1\\cap A_2\\cap A_3\\dots \\cap A_{n-1})0$ then $$ Pr(A_1\\cap A_2\\cap A_3\\dots \\cap A_n)=\\ Pr(A_1)Pr(A_2|A_1)Pr(A_3|A_1\\cap A_2)\\dots Pr(A_n|A_1\\cap A_2 \\cap A_3 \\cap \\dots \\cap A_{n-1}) $$\n 这个公式的证明很容易，把等号右边的式子前两个结合，得到一个事件并的事件，把它设为一个新事件$C_i$并进行替换和迭代，就能根据上面的$Pr(A\\cap C_i)=Pr(C_i)Pr(A|C_i)$ 把全部整合，最后得到等号左边的结果。\n举个例子来使用上面的公式，如果一个盒子里有r个红色球，b个蓝色球，其中r和b均大于2，那么我们每次随机取出一个球，without replacement，那么我们取出4个球，其排列是\"红，蓝，红，蓝\"的概率是多少呢？ 分析，首先取出球的概率是会相互影响的，因为是without replacement，除了第一个，后面的球的概率都会因为上一次的取出而改变，所以我们假设取出序列为\"红，蓝，红，蓝\"的事件为$R_1\\cap B_2\\cap R_3\\cap B_4$ 那么 $$ Pr(R_1\\cap B_2\\cap R_3\\cap B_4)=Pr(R_1)Pr(B_2|R_1)Pr(R_3|R_1\\cap B_2)Pr(B_4|R_1\\cap B_2\\cap R_3)\\ =\\frac{r}{r+b}\\frac{b}{r+b-1}\\frac{r-1}{r+b-2}\\frac{b-1}{r+b-3} $$ 这里主要的一个关键点就是分步试验的后面步骤受到前面步骤的影响，所以最后的结果是用条件概率给出的乘法关系。 条件概率的性质和普通概率的性质一样，因为我们开篇的时候说过所有的概率都是条件概率，只不过有些条件是规定的必然出现的，我们就把这个条件省略掉当成已知试验条件，不用考虑进行计算。 为了验证上面这句话，我们给出下面这个定理:\n Suppose that $A_1,A_2,A_3\\dots A_n,B$ are events such that $Pr(B)0$ and $Pr(A_1\\cap A_2\\cap A_3 \\dots A_{n-1}|B)0$ then: $$ Pr(A_1\\cap A_2\\cap \\dots A_n|B)=\\ Pr(A_1|B)Pr(A_2|A_1\\cap B)Pr(A_3|A_2\\cap A_1\\cap B)\\dots Pr(A_n|A_{n-1} \\cap \\dots \\cap A_2\\cap A_1\\cap B) $$\n 上面这个过程的证明和上面乘法原理的证明一样，就是通过等号右边每两个结合运用乘法原理，能够得到和等号左边一样的结果。 我们只要掌握一个规律就可以，那就是，条件概率和普通的概率一样，加上某个条件时，其计算方法和不加这个条件时候计算方法一致。\n条件概率与分割，全概率公式 Conditional Probability and Partition - Law of total Probability 在1-1的T3中，我们介绍了当一个样本空间被划分成两部分的时候，概率的计算方法，那么如果我们把切分继续下去，也就是一个样本空间我们把它切成k块不相交的子空间时，那么响应的计算会有什么变换呢？\n Definition partition Let S denote the sample space of some experiment,and consider k events $B_1 \\dots B_k$ in S such that $B_1 \\dots B_k$ are disjoint and $\\bigcup^k_{i=1}B_i=S$ It is said that these events from a partition of S\n 翻译下，意思是说把样本空间打碎成k个disjointed的事件，这些事件可以组合成S，那么打碎的过程叫做partition\n一般来说，当一个碎片发生时，整个试验的不确定性将会降低，因为其结果空间变得小了，但并不意味着这个碎片上含有的事件的概率会升高。\n根据上面打碎原理，我们可以得出下面的全概率公式，\n Theorem Law of total probability:Suppose that the events $B_1 \\dots B_k$ from a partition of the space S and $Pr(B_j)0$ for $j=1,\\dots ,k$ Then ,for every event A in S: $$ Pr(A)=\\sum^k_{j=1}Pr(B_j)Pr(A|B_j) $$\n 上述公式为全概率公式，将一个样本空间分割成k个不相交的小空间，然后每个空间上有事件A的一部分在整个空间上的概率为$Pr(A\\cap B_j)=Pr(A|B_j)Pr(B_j)$ 把他们都加起来就是完整的事件A的概率了。 全概率公式可以通过乘法原理和partition的定义获得，当然也可以画图证明，通过集合论的知识也可以。\n①画图： 圆圈是内是A，各分块内都有A的一部分，$B_i\\cap A$，那么所有的部分加起来就是完整的A，通过下面集合论也可以完整的解释\n②集合论： $$ A=(B_1\\cap A)\\cup(B_1\\cap A)\\cup\\dots \\cup(B_k\\cap A) $$ 并且 $(B_j\\cap A)$ 之间是disjointed ，所以 $$ Pr(A)=\\sum^k_{j=1}Pr(B_j\\cap A)\\ if \\quad Pr(B_j)0 (j=1\\dots k)\\quad then \\quad Pr(B_j\\cap A)=Pr(B_j)Pr(A|B_j) $$ 就可以得到上述的全概率公式了。\n同样全概率公式也有条件版本： $$ Pr(A|C)=\\sum^k_{j=1}Pr(B_j|C)Pr(A|B_j\\cap C) $$ 通过画图可以简单的了解一下最简单的情况： 怎么样很机制吧，给完整的样本空间S再加个套，这样$Pr(S)\\neq 1$ 而是一个小于1的概率了，这种情况下产生了一个条件概率版本的全概率公式。 如果从分析的方法看： $$ A\\cap C=(B_1\\cap A \\cap C)\\cup(B_1\\cap A \\cap C)\\cup\\dots \\cup(B_k\\cap A \\cap C) $$ 并且 $(B_j\\cap A|C)$ 之间是disjointed ，所以 $$ Pr(A| C)=\\sum^k_{j=1}Pr(B_j\\cap A | C)=\\sum^k_{j=1}\\frac{Pr(B_j\\cap A \\cap C)}{Pr(C)}\\ if \\quad Pr(B_j)0 (j=1\\dots k)\\quad then \\quad Pr(B_j\\cap A|C)=Pr(B_j)Pr(A|B_j\\cap C) $$ 证明过程和上述完全一致，这里就不再描述了。\n扩展试验 Augmented Experiment  Definition Augmented Experiment: If desired,any experiment can be augmented to include the potential or hypothetical observation of as much additional information as we would find useful to help us calculate any probabilities that we desire\n 上面这个定义是告诉我们所有的试验如果需要都能通过潜在或者假想的条件将其变成条件概率的形式，如果有利于计算，我们可以这样进行扩展。\n总结 果然一个条件概率就写了一天，如果加上独立事件肯定没办法写好，明天继续。。\n","wordCount":"501","inLanguage":"en","datePublished":"2018-01-31T10:34:36Z","dateModified":"2023-04-04T15:19:02+08:00","author":{"@type":"Person","name":"谭升"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://go.face2ai.com/math/math-probability-2-1-conditional-probability.zh/"},"publisher":{"@type":"Organization","name":"谭升的博客","logo":{"@type":"ImageObject","url":"https://go.face2ai.com/logo.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://go.face2ai.com accesskey=h title="谭升的博客 (Alt + H)">谭升的博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://go.face2ai.com/math/ title=数学><span>数学</span></a></li><li><a href=https://go.face2ai.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://go.face2ai.com/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://go.face2ai.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://go.face2ai.com/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://go.face2ai.com>Home</a>&nbsp;»&nbsp;<a href=https://go.face2ai.com/math/>Maths</a></div><h1 class=post-title>【概率论】2-1:条件概率(Conditional Probability)</h1><div class=post-meta><span title="2018-01-31 10:34:36 +0000 UTC">January 31, 2018</span>&nbsp;·&nbsp;谭升</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e6%9d%a1%e4%bb%b6%e6%a6%82%e7%8e%87 aria-label=条件概率>条件概率</a><ul><li><a href=#%e6%9d%a1%e4%bb%b6%e6%a6%82%e7%8e%87%e7%9a%84%e5%ae%9a%e4%b9%89-the-definition-of-conditional-probability aria-label="条件概率的定义 The Definition of Conditional Probability">条件概率的定义 The Definition of Conditional Probability</a></li><li><a href=#%e4%b9%98%e6%b3%95%e5%8e%9f%e5%88%99-the-multiplication-rule aria-label="乘法原则 The Multiplication Rule">乘法原则 The Multiplication Rule</a></li><li><a href=#%e6%9d%a1%e4%bb%b6%e6%a6%82%e7%8e%87%e4%b8%8e%e5%88%86%e5%89%b2%e5%85%a8%e6%a6%82%e7%8e%87%e5%85%ac%e5%bc%8f-conditional-probability-and-partition---law-of-total-probability aria-label="条件概率与分割，全概率公式 Conditional Probability and Partition - Law of total Probability">条件概率与分割，全概率公式 Conditional Probability and Partition - Law of total Probability</a></li><li><a href=#%e6%89%a9%e5%b1%95%e8%af%95%e9%aa%8c-augmented-experiment aria-label="扩展试验 Augmented Experiment">扩展试验 Augmented Experiment</a></li><li><a href=#%e6%80%bb%e7%bb%93 aria-label=总结>总结</a></li></ul></li></ul></div></details></div><div class=post-content><p><strong>Abstract:</strong> 本文介绍条件概率的定义及相关知识，提出全概率公式
<strong>Keywords:</strong> Conditional Probability，Multiplication Rule，Partitions
，Law of total Probability</p><h1 id=条件概率>条件概率<a hidden class=anchor aria-hidden=true href=#条件概率>#</a></h1><p>关于学习看过不同人的很多说法，大部分来自“知乎（分享你新编的故事）”，虽然有些不太可信，但是有一些确实有点道理，比如有人问是否应该着重训练微积分的计算能力，其实这个问题我个人也有过，原因就是经过高考的人有点不太能把握“什么程度才能叫做一项知识学会了”，因为就算你对一个知识点非常透彻，但是还是有人能通过这个知识点创造出你完全不会解的题，于是我们就开始怀疑自己到底到底学会没学会，那微积分有必要反复做题么？有一个答案的大概意思是，反复训练微积分，就像反复训练加减法一样，过了小学，这个训练就没有必要进行了，这个似乎很有道理。
那么我们准备做机器学习的同学们有必要反复训练自己的基础算法么？比如线性回归啊，感知机啊什么的么？开始的时候当然很有必要，但是当你进入一定阶段了，就要研究其背后的分析方法的原理了，所以，会用算法，理解算法，分析算法是完全不同的层次，就像小学，大学还有博士阶段一样。所以，打好基础，学好数学，才能读博士.当然现在如火如荼的环境下，小学生就业也非常乐观。
今天继续概率论的讨论，本来想把事件的独立也添加到本文，但是后来分析了一下，内容太多容易乱，所以本文只介绍条件概率，还是那句话，好就不能快，多就不能省，虽然感觉时间紧迫，但是也要一步一步来。</p><h2 id=条件概率的定义-the-definition-of-conditional-probability>条件概率的定义 The Definition of Conditional Probability<a hidden class=anchor aria-hidden=true href=#条件概率的定义-the-definition-of-conditional-probability>#</a></h2><p>概率本身用途有限，为什么？首先从我们的知识图上可以看到微积分，线性代数，概率论本身处于数学基础，基础很少被直接应用于平时的问题中，而概率更是如此，除了算算彩票，骰子，基本没有什么场景能完全满足概率的“条件”，但是作为基础，统计和随机过程则是非常实际的应用方法，概率对于统计的一个作用就是：当知道某个特定的事件被观察到的时候，通过概率论的知识，可以更新某些事件的概率。
比如我们观察一个试验，事件A是我们关心的，试验结束后，我们得到的关于A是否发生的信息是事件B发生了，那么此时事件A的概率被称为条件B发生时A的条件概率。</p><blockquote><p>Definition Conditional Probability: Sippose that we learn that an event B has occurred and that we wish to compute the probability of another event A taking into account that probability of the event A given that the event B has occurred and is denoted $Pr(A|B)$ . If $Pr(B)>0$ ,we compute this probability as:
$$
Pr(A|B)=\frac{Pr(A\cap B)}{Pr(B)}
$$
ps:The conditional probability $Pr(A|B)$ is not defined if $Pr(B)=0$</p></blockquote><p>翻译一下，当我们知道事件B已经发生并且我们希望计算另外一个事件A的时候考虑当B发生时A的概率，那就是条件概率 $Pr(A|B)$ 。当$Pr(B)=0$ 时，条件概率无定义</p><p>但是我们应该注意到，所有事件的概率都是条件的，比如试验：扔一个均匀的硬币，事件A表示正面，那么概率$Pr(A)$ 的条件就是"扔一个均匀硬币"，如果把扔一个均匀的硬币这个事件看做事件B，那么出现正面的概率是$Pr(A|B)$ ，这里事件B是肯定发生的，所以作为条件给出，如果事件B不是肯定发生，那么就要用我们下面给出的计算法则计算正面出现的概率了。
以上是从<a href=http://face2ai.com/Math-Probability-1-0-Introduction/>Subjective Interpretation</a>的角度定义的，但是从<a href=http://face2ai.com/Math-Probability-1-0-Introduction/>Frequency Interpretation</a>的角度，我们可以这么理解，一个重复$N$ 次的试验事件B发生的$N_B$次数与试验次数的比例近似于$Pr(B)=\frac{N_B}{N}$ 事件A和事件B同时发生的次数$N_{A\cap B}$ 与试验次数$N$ 的比例近似于$Pr(A\cap B)=\frac{N_{A\cap B}}{N}$，所以当B事件发生时，A事件也发生的概率接近于比例：$\frac{N_{A\cap B}}{N_B}=\frac{\frac{N_{A\cap B}}{N}}{\frac{N_B}{N}}=\frac{Pr(A\cap B)}{Pr(B)}$</p><p>通过上面的几个表达式可以了解关于频率观点下的条件概率的计算方法。</p><ol><li>举个例子：
条件描述：扔两个六面体骰子，每个面出现概率相等，两个骰子互不影响。
事件的概率：那么当我们知道其结果的和是奇数的条件下，其和小于8的事件T的概率是多少？
分析：首先我们通过条件知道这两个骰子出现每个数字概率相等为 $\frac{1}{6}$ 那么就可以分析出所有结果了：</li></ol><table><thead><tr><th style=text-align:center>event</th><th style=text-align:center>Probability</th></tr></thead><tbody><tr><td style=text-align:center>2</td><td style=text-align:center>$\frac{1}{36}$</td></tr><tr><td style=text-align:center>3</td><td style=text-align:center>$\frac{2}{36}$</td></tr><tr><td style=text-align:center>4</td><td style=text-align:center>$\frac{3}{36}$</td></tr><tr><td style=text-align:center>5</td><td style=text-align:center>$\frac{4}{36}$</td></tr><tr><td style=text-align:center>6</td><td style=text-align:center>$\frac{5}{36}$</td></tr><tr><td style=text-align:center>7</td><td style=text-align:center>$\frac{6}{36}$</td></tr><tr><td style=text-align:center>8</td><td style=text-align:center>$\frac{5}{36}$</td></tr><tr><td style=text-align:center>9</td><td style=text-align:center>$\frac{4}{36}$</td></tr><tr><td style=text-align:center>10</td><td style=text-align:center>$\frac{3}{36}$</td></tr><tr><td style=text-align:center>11</td><td style=text-align:center>$\frac{2}{36}$</td></tr><tr><td style=text-align:center>12</td><td style=text-align:center>$\frac{1}{36}$</td></tr></tbody></table><p>那么：
$$
Pr(A\cap B)=\frac{2}{36}+\frac{4}{36}+\frac{6}{36}=\frac{12}{36}=\frac{1}{3}\
Pr(B)=\frac{2}{36}+\frac{4}{36}+\frac{6}{36}+\frac{4}{36}+\frac{2}{36}=\frac{1}{2}
$$
Hence:
$$
Pr(A|B)=\frac{Pr(A\cap B)}{Pr(B)}=\frac{2}{3}
$$
2. 再举个例子，两个箱子，装着不同的螺丝，箱子A装着长螺丝7个和短螺丝3个，B装长螺丝6个短螺丝4个，这两个箱子被随机分给我们，如果我们有 $\frac{1}{3}$ 的概率被分到箱子A，$\frac{2}{3}$ 的概率被分到箱子B，那么当我们已知被分到A箱子的时候，我们拿出一个长螺丝的概率是多少？</p><p>这道题看起来很复杂，当然求问题的解很简单，$\frac{Pr(N_L\cap A)}{Pr(A)}=\frac{7}{7+3}$ ，但是这道明显是个分步的试验，首先得到什么样的箱子是个未知的随机事件，然后从箱子里拿螺丝还是随机事件，但是当我们已知是哪个箱子了以后，拿螺丝的过程将会被很容易的描述</p><p>在进入下一部分之前我想简单分析下什么时候可能条件概率，第一种就是一个试验，结果被划分成不同的事件，试验结束后，可以观察到某个事件B发生了，这是我们会更新我们在试验前计算的事件A的概率，称之为条件概率$Pr(A|B)$ ；第二种是分步的试验，第二步的试验产生的事件A可能根据第一步的不同而不同，所以当第一步产生了事件B，那么事件A的概率将会被重新计算为$Pr(A|B)$ 其值等于 $\frac{Pr(A\cap B)}{Pr(B)}$ 的结果。
同时我们观察这个关系式可以得出$Pr(B)\leq 1$所以$Pr(A|B)\leq Pr(A\cap B)$，这个关系式是确定的，但是$Pr(A|B)\leq \geq Pr(A)$ 之间的大小不确定。</p><h2 id=乘法原则-the-multiplication-rule>乘法原则 The Multiplication Rule<a hidden class=anchor aria-hidden=true href=#乘法原则-the-multiplication-rule>#</a></h2><p>乘法原则在之前的计数方法里有提到过，就是分步试验每步有不同的结果，那么组合起来其满足乘法关系，这里的乘法法则是通过上面条件概率的定义得出的：</p><blockquote><p>Definition Multiplication Rule for Conditional Probability:
$$
if \quad Pr(B)>0:\quad Pr(A\cap B)=Pr(B)Pr(A|B)\
if \quad Pr(A)>0:\quad Pr(A\cap B)=Pr(A)Pr(B|A)
$$</p></blockquote><p>这两个式子是上面条件概率公式的变形，但是却有了不同含义，我们把它定义为条件概率的乘法原则</p><blockquote><p>Definition Multiplication Rule for Conditional Probability:Suppose that $A_1,A_2,A_3\dots A_n$ are events such that $Pr(A_1\cap A_2\cap A_3\dots \cap A_{n-1})>0$ then
$$
Pr(A_1\cap A_2\cap A_3\dots \cap A_n)=\
Pr(A_1)Pr(A_2|A_1)Pr(A_3|A_1\cap A_2)\dots Pr(A_n|A_1\cap A_2 \cap A_3 \cap \dots \cap A_{n-1})
$$</p></blockquote><p>这个公式的证明很容易，把等号右边的式子前两个结合，得到一个事件并的事件，把它设为一个新事件$C_i$并进行替换和迭代，就能根据上面的$Pr(A\cap C_i)=Pr(C_i)Pr(A|C_i)$ 把全部整合，最后得到等号左边的结果。</p><p>举个例子来使用上面的公式，如果一个盒子里有r个红色球，b个蓝色球，其中r和b均大于2，那么我们每次随机取出一个球，without replacement，那么我们取出4个球，其排列是"红，蓝，红，蓝"的概率是多少呢？
分析，首先取出球的概率是会相互影响的，因为是without replacement，除了第一个，后面的球的概率都会因为上一次的取出而改变，所以我们假设取出序列为"红，蓝，红，蓝"的事件为$R_1\cap B_2\cap R_3\cap B_4$
那么
$$
Pr(R_1\cap B_2\cap R_3\cap B_4)=Pr(R_1)Pr(B_2|R_1)Pr(R_3|R_1\cap B_2)Pr(B_4|R_1\cap B_2\cap R_3)\
=\frac{r}{r+b}\frac{b}{r+b-1}\frac{r-1}{r+b-2}\frac{b-1}{r+b-3}
$$
这里主要的一个关键点就是分步试验的后面步骤受到前面步骤的影响，所以最后的结果是用条件概率给出的乘法关系。
条件概率的性质和普通概率的性质一样，因为我们开篇的时候说过所有的概率都是条件概率，只不过有些条件是规定的必然出现的，我们就把这个条件省略掉当成已知试验条件，不用考虑进行计算。
为了验证上面这句话，我们给出下面这个定理:</p><blockquote><p>Suppose that $A_1,A_2,A_3\dots A_n,B$ are events such that $Pr(B)>0$ and $Pr(A_1\cap A_2\cap A_3 \dots A_{n-1}|B)>0$ then:
$$
Pr(A_1\cap A_2\cap \dots A_n|B)=\
Pr(A_1|B)Pr(A_2|A_1\cap B)Pr(A_3|A_2\cap A_1\cap B)\dots Pr(A_n|A_{n-1} \cap \dots \cap A_2\cap A_1\cap B)
$$</p></blockquote><p>上面这个过程的证明和上面乘法原理的证明一样，就是通过等号右边每两个结合运用乘法原理，能够得到和等号左边一样的结果。
我们只要掌握一个规律就可以，那就是，条件概率和普通的概率一样，加上某个条件时，其计算方法和不加这个条件时候计算方法一致。</p><h2 id=条件概率与分割全概率公式-conditional-probability-and-partition---law-of-total-probability>条件概率与分割，全概率公式 Conditional Probability and Partition - Law of total Probability<a hidden class=anchor aria-hidden=true href=#条件概率与分割全概率公式-conditional-probability-and-partition---law-of-total-probability>#</a></h2><p>在<a href=http://face2ai.com/Math-Probability-1-1-Definition-of-Probability/>1-1的T3</a>中，我们介绍了当一个样本空间被划分成两部分的时候，概率的计算方法，那么如果我们把切分继续下去，也就是一个样本空间我们把它切成k块不相交的子空间时，那么响应的计算会有什么变换呢？</p><blockquote><p>Definition partition Let S denote the sample space of some experiment,and consider k events $B_1 \dots B_k$ in S such that $B_1 \dots B_k$ are disjoint and $\bigcup^k_{i=1}B_i=S$ It is said that these events from a partition of S</p></blockquote><p>翻译下，意思是说把样本空间打碎成k个disjointed的事件，这些事件可以组合成S，那么打碎的过程叫做partition</p><p>一般来说，当一个碎片发生时，整个试验的不确定性将会降低，因为其结果空间变得小了，但并不意味着这个碎片上含有的事件的概率会升高。</p><p>根据上面打碎原理，我们可以得出下面的全概率公式，</p><blockquote><p>Theorem Law of total probability:Suppose that the events $B_1 \dots B_k$ from a partition of the space S and $Pr(B_j)>0$ for $j=1,\dots ,k$ Then ,for every event A in S:
$$
Pr(A)=\sum^k_{j=1}Pr(B_j)Pr(A|B_j)
$$</p></blockquote><p>上述公式为全概率公式，将一个样本空间分割成k个不相交的小空间，然后每个空间上有事件A的一部分在整个空间上的概率为$Pr(A\cap B_j)=Pr(A|B_j)Pr(B_j)$ 把他们都加起来就是完整的事件A的概率了。
全概率公式可以通过乘法原理和partition的定义获得，当然也可以画图证明，通过集合论的知识也可以。</p><p>①画图：
<img loading=lazy src=https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/Math-Probability-1-5-Conditional-Probability/law_of_total_probability.png alt>
圆圈是内是A，各分块内都有A的一部分，$B_i\cap A$，那么所有的部分加起来就是完整的A，通过下面集合论也可以完整的解释</p><p>②集合论：
$$
A=(B_1\cap A)\cup(B_1\cap A)\cup\dots \cup(B_k\cap A)
$$
并且 $(B_j\cap A)$ 之间是disjointed ，所以
$$
Pr(A)=\sum^k_{j=1}Pr(B_j\cap A)\
if \quad Pr(B_j)>0 (j=1\dots k)\quad then \quad Pr(B_j\cap A)=Pr(B_j)Pr(A|B_j)
$$
就可以得到上述的全概率公式了。</p><p>同样全概率公式也有条件版本：
$$
Pr(A|C)=\sum^k_{j=1}Pr(B_j|C)Pr(A|B_j\cap C)
$$
通过画图可以简单的了解一下最简单的情况：
<img loading=lazy src=https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/Math-Probability-1-5-Conditional-Probability/law_of_total_probability2.png alt></p><p>怎么样很机制吧，给完整的样本空间S再加个套，这样$Pr(S)\neq 1$ 而是一个小于1的概率了，这种情况下产生了一个条件概率版本的全概率公式。
如果从分析的方法看：
$$
A\cap C=(B_1\cap A \cap C)\cup(B_1\cap A \cap C)\cup\dots \cup(B_k\cap A \cap C)
$$
并且 $(B_j\cap A|C)$ 之间是disjointed ，所以
$$
Pr(A| C)=\sum^k_{j=1}Pr(B_j\cap A | C)=\sum^k_{j=1}\frac{Pr(B_j\cap A \cap C)}{Pr(C)}\
if \quad Pr(B_j)>0 (j=1\dots k)\quad then \quad Pr(B_j\cap A|C)=Pr(B_j)Pr(A|B_j\cap C)
$$
证明过程和上述完全一致，这里就不再描述了。</p><h2 id=扩展试验-augmented-experiment>扩展试验 Augmented Experiment<a hidden class=anchor aria-hidden=true href=#扩展试验-augmented-experiment>#</a></h2><blockquote><p>Definition Augmented Experiment: If desired,any experiment can be augmented to include the potential or hypothetical observation of as much additional information as we would find useful to help us calculate any probabilities that we desire</p></blockquote><p>上面这个定义是告诉我们所有的试验如果需要都能通过潜在或者假想的条件将其变成条件概率的形式，如果有利于计算，我们可以这样进行扩展。</p><h2 id=总结>总结<a hidden class=anchor aria-hidden=true href=#总结>#</a></h2><p>果然一个条件概率就写了一天，如果加上独立事件肯定没办法写好，明天继续。。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://go.face2ai.com/tags/%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87/>条件概率</a></li><li><a href=https://go.face2ai.com/tags/%E4%B9%98%E6%B3%95%E5%8E%9F%E7%90%86/>乘法原理</a></li><li><a href=https://go.face2ai.com/tags/%E5%85%A8%E6%A6%82%E7%8E%87%E5%85%AC%E5%BC%8F/>全概率公式</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share 【概率论】2-1:条件概率(Conditional Probability) on twitter" href="https://twitter.com/intent/tweet/?text=%e3%80%90%e6%a6%82%e7%8e%87%e8%ae%ba%e3%80%912-1%3a%e6%9d%a1%e4%bb%b6%e6%a6%82%e7%8e%87%28Conditional%20Probability%29&url=https%3a%2f%2fgo.face2ai.com%2fmath%2fmath-probability-2-1-conditional-probability.zh%2f&hashtags=%e6%9d%a1%e4%bb%b6%e6%a6%82%e7%8e%87%2c%e4%b9%98%e6%b3%95%e5%8e%9f%e7%90%86%2c%e5%85%a8%e6%a6%82%e7%8e%87%e5%85%ac%e5%bc%8f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【概率论】2-1:条件概率(Conditional Probability) on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fgo.face2ai.com%2fmath%2fmath-probability-2-1-conditional-probability.zh%2f&title=%e3%80%90%e6%a6%82%e7%8e%87%e8%ae%ba%e3%80%912-1%3a%e6%9d%a1%e4%bb%b6%e6%a6%82%e7%8e%87%28Conditional%20Probability%29&summary=%e3%80%90%e6%a6%82%e7%8e%87%e8%ae%ba%e3%80%912-1%3a%e6%9d%a1%e4%bb%b6%e6%a6%82%e7%8e%87%28Conditional%20Probability%29&source=https%3a%2f%2fgo.face2ai.com%2fmath%2fmath-probability-2-1-conditional-probability.zh%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【概率论】2-1:条件概率(Conditional Probability) on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fgo.face2ai.com%2fmath%2fmath-probability-2-1-conditional-probability.zh%2f&title=%e3%80%90%e6%a6%82%e7%8e%87%e8%ae%ba%e3%80%912-1%3a%e6%9d%a1%e4%bb%b6%e6%a6%82%e7%8e%87%28Conditional%20Probability%29"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【概率论】2-1:条件概率(Conditional Probability) on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fgo.face2ai.com%2fmath%2fmath-probability-2-1-conditional-probability.zh%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【概率论】2-1:条件概率(Conditional Probability) on whatsapp" href="https://api.whatsapp.com/send?text=%e3%80%90%e6%a6%82%e7%8e%87%e8%ae%ba%e3%80%912-1%3a%e6%9d%a1%e4%bb%b6%e6%a6%82%e7%8e%87%28Conditional%20Probability%29%20-%20https%3a%2f%2fgo.face2ai.com%2fmath%2fmath-probability-2-1-conditional-probability.zh%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【概率论】2-1:条件概率(Conditional Probability) on telegram" href="https://telegram.me/share/url?text=%e3%80%90%e6%a6%82%e7%8e%87%e8%ae%ba%e3%80%912-1%3a%e6%9d%a1%e4%bb%b6%e6%a6%82%e7%8e%87%28Conditional%20Probability%29&url=https%3a%2f%2fgo.face2ai.com%2fmath%2fmath-probability-2-1-conditional-probability.zh%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://go.face2ai.com>谭升的博客</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerHTML="copy";function s(){e.innerHTML="copied!",setTimeout(()=>{e.innerHTML="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>