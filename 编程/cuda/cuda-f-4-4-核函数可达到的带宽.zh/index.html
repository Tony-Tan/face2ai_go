<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>【CUDA 基础】4.4 核函数可达到的带宽 | 谭升的博客</title><meta name=keywords content="带宽,吞吐量,矩阵转置"><meta name=description content="Abstract: 本文通过矩阵转置这一个例子，调整，优化核函数，使其达到最优的内存带宽
Keywords: 带宽，吞吐量，矩阵转置"><meta name=author content="谭升"><link rel=canonical href=https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-4-4-%E6%A0%B8%E5%87%BD%E6%95%B0%E5%8F%AF%E8%BE%BE%E5%88%B0%E7%9A%84%E5%B8%A6%E5%AE%BD.zh/><link crossorigin=anonymous href=../../../assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe+FVUFzPh7U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=../../../assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://go.face2ai.com/logo.png><link rel=icon type=image/png sizes=16x16 href=https://go.face2ai.com/logo.png><link rel=icon type=image/png sizes=32x32 href=https://go.face2ai.com/logo.png><link rel=apple-touch-icon href=https://go.face2ai.com/logo.png><link rel=mask-icon href=https://go.face2ai.com/logo.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-105335860-3","auto"),ga("send","pageview"))</script><meta property="og:title" content="【CUDA 基础】4.4 核函数可达到的带宽"><meta property="og:description" content="Abstract: 本文通过矩阵转置这一个例子，调整，优化核函数，使其达到最优的内存带宽
Keywords: 带宽，吞吐量，矩阵转置"><meta property="og:type" content="article"><meta property="og:url" content="https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-4-4-%E6%A0%B8%E5%87%BD%E6%95%B0%E5%8F%AF%E8%BE%BE%E5%88%B0%E7%9A%84%E5%B8%A6%E5%AE%BD.zh/"><meta property="article:section" content="编程"><meta property="article:published_time" content="2018-05-13T12:08:02+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="【CUDA 基础】4.4 核函数可达到的带宽"><meta name=twitter:description content="Abstract: 本文通过矩阵转置这一个例子，调整，优化核函数，使其达到最优的内存带宽
Keywords: 带宽，吞吐量，矩阵转置"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":3,"name":"【CUDA 基础】4.4 核函数可达到的带宽","item":"https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-4-4-%E6%A0%B8%E5%87%BD%E6%95%B0%E5%8F%AF%E8%BE%BE%E5%88%B0%E7%9A%84%E5%B8%A6%E5%AE%BD.zh/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"【CUDA 基础】4.4 核函数可达到的带宽","name":"【CUDA 基础】4.4 核函数可达到的带宽","description":"Abstract: 本文通过矩阵转置这一个例子，调整，优化核函数，使其达到最优的内存带宽 Keywords: 带宽，吞吐量，矩阵转置\n","keywords":["带宽","吞吐量","矩阵转置"],"articleBody":"Abstract: 本文通过矩阵转置这一个例子，调整，优化核函数，使其达到最优的内存带宽 Keywords: 带宽，吞吐量，矩阵转置\n核函数可达到的带宽 下面是废话，与本文知识无关，可以直接跳到下面红字处开始本文知识的学习。 废话继续，这两天没更新博客了，上一篇是转发的MIT人工智能实验室的研究指南，也就是告诉刚入学的研究生怎么做研究，要怎么积累，那篇文章发表在1988年，MIT的AI实验室网站目前仍然能检索的到，通读全文，感受很多，也学会了很多东西，当一个健康的框架搭好了以后，后面的好功能会源源不断的涌现，教育也是，当一套体系形成，那么就会有源源不断的人才和成果出现，相反，如果体系本身漏洞百出，根基不稳，短时间真的改不了，人也一样，价值观一旦确定，这个人的人生也就基本定型了——正所谓三岁看老。 今天废话有点多，如果没兴趣，可以直接跳到这里 上一章我们研究怎么通过调整线程网格结构和核函数来达到SM的最高利用率，今天我们来研究如何达到内存带宽的最大利用率。 还是要提那个老例子，但是说实话，这的很形象，也很有用，记住这个例子基本就能了解CUDA的优化大概要从哪入手了： 一条大路（内存读取总线）连接了工厂生产车间（GPU）和材料仓库（全局内存），生产车间又有很多的工作小组（SM），材料仓库有很多小库房（内存分块），工作小组同时生产相同的产品互不干扰（并行），我们有车从材料仓库开往工厂车间，什么时候发车，运输什么由工作小组远程电话指挥（内存请求），发车前，从材料仓库装货的时候，还要听从仓库管理员的分配，因为可能同一间库房可能只允许一个车来拿材料（内存块访问阻塞），然后这些车单向的开往工厂，这时候就是交通问题了，如果我们的路是单向（从仓库到工厂）8车道，每秒钟能通过16辆车，那么我们把这个指标称为带宽。当然我们还有一条路是将成品运输到成品仓库，这也是一条路，与原料库互不干扰，和材料仓库到工厂的路一样，也有宽度，也是单向的，如果这条路堵住，和仓库到工厂的路堵住一样，此时工厂要停工等待。 最理想的状态是，路上全是车，并且全都高速行驶，工厂里的所有工人都在满负荷工作，没有等待，这就是优化的最终目标，如果这个目标达到了，还想进一步提高效率，那么你就只能优化你的工艺了（算法） 上面的这个就是粗糙的GPU工作过程。例子还是比较贴切的，但是有点描述粗糙，多读两遍应该会有点收获的。 内存延迟是影响核函数的一大关键，内存延迟，也就是从你发起内存请求到数据进入SM的寄存器的整个时间。 内存带宽，也就是SM访问内存的速度，它以单位时间内传输的字节数进行测量。 上一节我们用了两种方法改善内核性能：\n 最大化线程束的数量来隐藏内存延迟，维持更多的正在执行的内存访问达到更好的总线利用率 通过适当的对齐和合并访问，提高带宽效率  然而，当前内核本身的内存访问方式就有问题，上面两种优化相当于给一个拖拉机优化空气动力学外观，杯水车薪。 我们本文要做的就是看看这个核函数对应的问题，其极限效率是多少，在理想效率之下，我们来进行优化，我们本文那矩阵转置来进行研究，看看如何把一种看起来没办法优化的内核，重新设计让它达到更好的性能。\n内存带宽 多数内核对带宽敏感，也就是说，工人们生产效率特别高，而原料来的很慢，这限制了生产速度。去哪聚内存中数据的安排方式和线程束的访问方式都对带宽有显著影响。一般有如下两种带宽\n 理论带宽 有效带宽  理论带宽就是硬件设计的绝对最大值，硬件限制了这个最大值为多少，比如对于不使用ECC的Fermi M2090来说，理论峰值 117.6 GB/s 有效带宽是核函数实际达到的带宽，是测量带宽，可以用下面公式计算: $$ 有效带宽=\\frac{(读字节数 + 写字节数)\\times 10^{-9}}{运行时间}\\tag{1} $$ 注意吞吐量和带宽的区别，吞吐量是衡量计算核心效率的，用的单位是每秒多少十亿次浮点运算(gflops)，有效吞吐量其不止和有效带宽有关，还和带宽的利用率等因素有关，当然最主要的还是设备的运算核心。 当然，也有内存吞吐量这种说法这种说法就是单位时间上内存访问的总量，用单位 GB/s 表示，这个值越大表示读取到的数据越多，但是这些数据不一定是有用的。 接下来我们研究如何调整核函数来提高有效带宽\n矩阵转置问题 矩阵转置(点击查看详情)就是交换矩阵的坐标，我们本文研究有二维矩阵，转置结果如下：\n使用串行编程很容易实现：\nvoid transformMatrix2D_CPU(float * MatA,float * MatB,int nx,int ny) { for(int j=0;jny;j++) { for(int i=0;inx;i++) { MatB[i*nx+j]=MatA[j*nx+i]; } } } 这段代码应该比较容易懂，这是串行解决的方法，必须要注意的是，我们所有的数据，结构体也好，数组也好，多维数组也好，所有的数据，在内存硬件层面都是一维排布的，所以我们这里也是使用一维的数组作为输入输出，那么从真实的角度看内存中的数据就是下面这样的：\n通过这个图能得出一个结论，转置操作：\n 读：原矩阵行进行读取，请求的内存是连续的，可以进行合并访问 写：写到转置矩阵的列中，访问是交叉的  图中的颜色需要大家注意一下，读的过程同一颜色可以看成是合并读取的，但是转置发生后写入的过程，是交叉的。 交叉访问是使得内存访问变差的罪魁。但是作为矩阵转置本身，这个是无法避免的。但是在这种无法避免的交叉访问前提下，我们怎么能提升效率就变成了一个有趣的课题。 我们接下来所有方法都会有按照行读取和按照列读取的版本，来对比效率，看看是交叉读有优势，还是交叉写有优势。 如果按照我们上文的观点，如果按照下面两种方法进行读\n最初的想法肯定是：按照图一合并读更有效率，因为写的时候不需要经过一级缓存，所以对于有一级缓存的程序，合并的读取应该是更有效率的。如果你这么想，恭喜你，你想的不对（我当时也是这么想的）。 我们需要补充下关于一级缓存的作用，上文我们讲到合并，可能第一印象就是一级缓存是缓冲从全局内存里过来的数据一样，但是我们忽略了一些东西，就是内存发起加载请求的时候，会现在一级缓存里看看有没有这个数据，如果有，这个就是一个命中，这和CPU的缓存运行原理是一样的，如果命中了，就不需要再去全局内存读了，如果用在上面这个例子，虽然按照列读是不合并的，但是使用一级缓存加载过来的数据在后面会被使用，我们必须要注意虽然，一级缓存一次读取128字节的数据，其中只有一个单位是有用的，但是剩下的并不会被马上覆盖，粒度是128字节，但是一级缓存的大小有几k或是更大，这些数据很有可能不会被替换，所以，我们按列读取数据，虽然第一行只用了一个，但是下一列的时候，理想情况是所有需要读取的元素都在一级缓存中，这时候，数据直接从缓存里面读取，美滋滋！\n为转置核函数设置上限和下限 在优化之前，我们要给自己一个目标，也就是理论上极限是多少，比如我们测得理论极限是10，而我们已经花了一天时间优化到了9.8，就没必要再花10天优化到9.9了，因为这已经很接近极限了，如果不知道极限，那么就会在无限的接近中浪费时间。 我们本例子中的瓶颈在交叉访问，所以我们假设没有交叉访问，和全是交叉访问的情况，来给出上限和下限：\n 行读取，行存储来复制矩阵(上限) 列读取，列存储来复制矩阵(下限)  __global__ void copyRow(float * MatA,float * MatB,int nx,int ny) { int ix=threadIdx.x+blockDim.x*blockIdx.x; int iy=threadIdx.y+blockDim.y*blockIdx.y; int idx=ix+iy*nx; if (ixnx \u0026\u0026 iyny) { MatB[idx]=MatA[idx]; } } __global__ void copyCol(float * MatA,float * MatB,int nx,int ny) { int ix=threadIdx.x+blockDim.x*blockIdx.x; int iy=threadIdx.y+blockDim.y*blockIdx.y; int idx=ix*ny+iy; if (ixnx \u0026\u0026 iyny) { MatB[idx]=MatA[idx]; } } 我们使用命令行编译，开启一级缓存：\nnvcc -O3 -arch=sm_35 -Xptxas -dlcm=ca -I ../include/ transform_matrix2D.cu -o transform_matrix2D 可以得到：\n   核函数 试验1 试验2 试验3 平均值     上限 0.001611 0.001614 0.001606 0.001610   下限 0.004191 0.004210 0.004205 0.004202    这个时间是三次测试出来的平均值，基本可以肯定在当前数据规模下，上限在0.001610s，下限在0.004202s，不可能超过上限，当然如果你能跌破下限也算是人才了！ 另外，我们我们全文用的主函数我只在此列举一次，完成代码库在https://github.com/Tony-Tan/CUDA_Freshman\nint main(int argc,char** argv) { printf(\"strating...\\n\"); initDevice(0); int nx=112; int ny=112; int nxy=nx*ny; int nBytes=nxy*sizeof(float); int transform_kernel=0; if(argc=2) transform_kernel=atoi(argv[1]); //Malloc  float* A_host=(float*)malloc(nBytes); float* B_host=(float*)malloc(nBytes); initialData(A_host,nxy); //cudaMalloc  float *A_dev=NULL; float *B_dev=NULL; CHECK(cudaMalloc((void**)\u0026A_dev,nBytes)); CHECK(cudaMalloc((void**)\u0026B_dev,nBytes)); CHECK(cudaMemcpy(A_dev,A_host,nBytes,cudaMemcpyHostToDevice)); CHECK(cudaMemset(B_dev,0,nBytes)); int dimx=32; int dimy=32; // cpu compute  double iStart=cpuSecond(); transformMatrix2D_CPU(A_host,B_host,nx,ny); double iElaps=cpuSecond()-iStart; printf(\"CPU Execution Time elapsed %f sec\\n\",iElaps); // 2d block and 2d grid  dim3 block(dimx,dimy); dim3 grid((nx-1)/block.x+1,(ny-1)/block.y+1); dim3 block_1(dimx,dimy); dim3 grid_1((nx-1)/(block_1.x*4)+1,(ny-1)/block_1.y+1); iStart=cpuSecond(); switch(transform_kernel) { case 0: copyRowgrid,block(A_dev,B_dev,nx,ny); break; case 1: copyColgrid,block(A_dev,B_dev,nx,ny); break; case 2: transformNaiveRowgrid,block(A_dev,B_dev,nx,ny); break; case 3: transformNaiveColgrid,block(A_dev,B_dev,nx,ny); break; case 4: transformNaiveColUnrollgrid_1,block_1(A_dev,B_dev,nx,ny); break; case 5: transformNaiveColUnrollgrid_1,block_1(A_dev,B_dev,nx,ny); break; case 6: transformNaiveRowDiagonalgrid,block(A_dev,B_dev,nx,ny); break; case 7: transformNaiveColDiagonalgrid,block(A_dev,B_dev,nx,ny); break; default: break; } CHECK(cudaDeviceSynchronize()); iElaps=cpuSecond()-iStart; printf(\" Time elapsed %f sec\\n\",iElaps); CHECK(cudaMemcpy(B_host,B_dev,nBytes,cudaMemcpyDeviceToHost)); checkResult(B_host,B_host,nxy); cudaFree(A_dev); cudaFree(B_dev); free(A_host); free(B_host); cudaDeviceReset(); return 0; } switch部分可以写成函数指针的方式，但是问题不大（原文写的应该是函数指针的方式）。 我的笔记本是1050ti的显卡，这个表可能是主机版本的1050ti的指标，可以看出其理论贷款是112GB/s 我们使用公式(1)来算一下两种极限的带宽： $$ \\text{copyRow}=\\frac{1\\times2^{12+12}\\times 4\\times 2\\times 10^{-9}}{0.001610}=\\frac{0.134217728}{0.001610}=83.3650 \\text{ GB/s}\\ \\text{copyCol}=\\frac{1\\times2^{12+12}\\times 4\\times 2\\times 10^{-9}}{0.004202}=\\frac{0.134217728}{0.004202}=31.9414 \\text{ GB/s} $$\n朴素转置：读取行与读取列 接下来我们看最naive的两种转置方法，不加任何优化，也就是我们一瞬间就想到的方案：\n__global__ void transformNaiveRow(float * MatA,float * MatB,int nx,int ny) { int ix=threadIdx.x+blockDim.x*blockIdx.x; int iy=threadIdx.y+blockDim.y*blockIdx.y; int idx_row=ix+iy*nx; int idx_col=ix*ny+iy; if (ixnx \u0026\u0026 iyny) { MatB[idx_col]=MatA[idx_row]; } } __global__ void transformNaiveCol(float * MatA,float * MatB,int nx,int ny) { int ix=threadIdx.x+blockDim.x*blockIdx.x; int iy=threadIdx.y+blockDim.y*blockIdx.y; int idx_row=ix+iy*nx; int idx_col=ix*ny+iy; if (ixnx \u0026\u0026 iyny) { MatB[idx_row]=MatA[idx_col]; } } 运行时间：\n   核函数 试验1 试验2 试验3 平均值     transformNaiveRow 0.004008 0.004005 0.004012 0.004008   transformNaiveCol 0.002126 0.002118 0.002124 0.002123    $$ \\text{transformNaiveRow}=\\frac{1\\times2^{12+12}\\times 4\\times 2\\times 10^{-9}}{0.001610}=\\frac{0.134217728}{0.004008}= 33.4874 \\text{ GB/s}\\ \\text{transformNaiveCol}=\\frac{1\\times2^{12+12}\\times 4\\times 2\\times 10^{-9}}{0.004202}=\\frac{0.134217728}{0.002123}= 63.2207 \\text{ GB/s} $$\n使用按列读取效果更好，这和我们前面分析的基本一致。 下面是使用一级缓存的加载存储吞吐量    核函数 加载吞吐量 存储吞吐量     copyRow 81.263 40.631   copyCol 120.93 120.93   transformNaiveRow 31.717 126.87   transformNaiveCol 243.64 30.454    按列读取的高吞吐量的原因就是上面我们说的缓存命中，这里也能看到吞吐量是可以超过带宽的，因为带宽衡量的是从全局内存到SM的速度极限，而吞吐量是SM获得数据的总量除以时间，而这些数据可以来自一级缓存，而不必千里迢迢从主存读取。 这里有个疑问：虽然交叉读取缓存命中率高了，但是似乎并没有减少从主存读取数据的数据量，那为什么速度会有提高呢？ 我认为应该是延迟隐藏部分出的问题，导致了交叉读取效率变高，当然只是我的猜测后面还要验证一下。\n展开转置：读取行与读取列 接下来这个是老套路了，有效地隐藏延迟，从展开操作开始：\n__global__ void transformNaiveRowUnroll(float * MatA,float * MatB,int nx,int ny) { int ix=threadIdx.x+blockDim.x*blockIdx.x*4; int iy=threadIdx.y+blockDim.y*blockIdx.y; int idx_row=ix+iy*nx; int idx_col=ix*ny+iy; if (ixnx \u0026\u0026 iyny) { MatB[idx_col]=MatA[idx_row]; MatB[idx_col+ny*1*blockDim.x]=MatA[idx_row+1*blockDim.x]; MatB[idx_col+ny*2*blockDim.x]=MatA[idx_row+2*blockDim.x]; MatB[idx_col+ny*3*blockDim.x]=MatA[idx_row+3*blockDim.x]; } } __global__ void transformNaiveColUnroll(float * MatA,float * MatB,int nx,int ny) { int ix=threadIdx.x+blockDim.x*blockIdx.x*4; int iy=threadIdx.y+blockDim.y*blockIdx.y; int idx_row=ix+iy*nx; int idx_col=ix*ny+iy; if (ixnx \u0026\u0026 iyny) { MatB[idx_row]=MatA[idx_col]; MatB[idx_row+1*blockDim.x]=MatA[idx_col+ny*1*blockDim.x]; MatB[idx_row+2*blockDim.x]=MatA[idx_col+ny*2*blockDim.x]; MatB[idx_row+3*blockDim.x]=MatA[idx_col+ny*3*blockDim.x]; } } 结果如图\n   核函数 试验1 试验2 试验3 平均值     transformNaiveRowUnroll 0.001544 0.001550 001541 0.001545   transformNaiveColUnroll 0.001545 0.001539 0.001546 0.001543    这里出现了尴尬的一幕，没错，我们突破上限了，上限是按行合并读取，合并存储，不存在交叉的情况，这种理想情况不可能发生在转置中，所以我们说这是上限。而我们使用展开的交叉访问居然得到了比上限更快的速度，所以我断定，如果把上限展开，速度肯定会更快，但是我们这里还把他叫做上限，虽然并不是真正的上限。 想要知道真正的上限是什么，就要从硬件角度算理论上限，实际测出来的上限很有可能不正确。\n对角转置：读取行与读取列 接下来我们使用一点新技巧，这个技巧的来源是DRAM的特性导致的，还记得我们例子中对原料仓库的描述么，那里面有很多小库房，这些小库房同时可能只允许一台车拿东西，在DRAM中内存是分区规划的，如果过多的访问同一个区，会产生排队的现象，也就是要等待，为了避免这种情况，我们最好均匀的访问DRAM的某一段，DRAM的分区是每256个字节算一个分区，所以我们最好错开同一个分区的访问，方法就是调整块的ID，这时候你可能有问题了，我们并不知道块的执行顺序，那应该怎么调呢，这个问题没有啥官方解释，我自己的理解是，硬件执行线程块必然是按照某种规则进行的，按照123执行，可能要比按照随机执行好，因为想要随机执行，还要有生成随机顺序这一步，根本没必要，我们之所以说块的执行顺序不确定，其实是为了避免大家把它理解为确定顺序，而实际上可能有某些原因导致顺序错乱，但是这个绝对不是硬件设计时故意而为之的。 我们这个对角转置的目的就是使得读取DRAM位置均匀一点，别都集中在一个分区上，方法是打乱线程块，因为连续的线程块可能访问相近的DRAM地址。 我们的方案是使用一个函数 $f(x,y)=(m,n)$ 一个一一对应的函数，将原始笛卡尔坐标打乱。 注意，所有这些线程块的顺序什么的都是在编程模型基础上的，跟硬件没什么关系，这些都是逻辑层面的，实际上线程块ID对应的是哪个线程块也是我们自己规定的而已。 说实话，这个代码有点难理解，当然你也不用死记硬背这种用法，似乎没有程序员被代码，甚至入门的过程都不用背，我们要理解的就是线程块ID和线程块之间的对应，以及新ID和原始ID的对应，以及新ID对应的块， 原始的线程块ID 新设计的线程块ID\n__global__ void transformNaiveRowDiagonal(float * MatA,float * MatB,int nx,int ny) { int block_y=blockIdx.x; int block_x=(blockIdx.x+blockIdx.y)%gridDim.x; int ix=threadIdx.x+blockDim.x*block_x; int iy=threadIdx.y+blockDim.y*block_y; int idx_row=ix+iy*nx; int idx_col=ix*ny+iy; if (ixnx \u0026\u0026 iyny) { MatB[idx_col]=MatA[idx_row]; } } __global__ void transformNaiveColDiagonal(float * MatA,float * MatB,int nx,int ny) { int block_y=blockIdx.x; int block_x=(blockIdx.x+blockIdx.y)%gridDim.x; int ix=threadIdx.x+blockDim.x*block_x; int iy=threadIdx.y+blockDim.y*block_y; int idx_row=ix+iy*nx; int idx_col=ix*ny+iy; if (ixnx \u0026\u0026 iyny) { MatB[idx_row]=MatA[idx_col]; } } 这个速度还没有展开的版本快，甚至没有naive的交叉读取速度快，但书上说的是效率有提高，可能是CUDA升级后的原因吧，或者其他原因的影响，但是DRAM分区会出现排队这种现象值得注意。\n瘦块来增加并行性 接下来老套路，调整一下线程块的尺寸我们看看有没有啥变化，当然，我们以naive的列读取作为对照。\n   block尺寸 测试1 测试2 测试3 平均值     (32,32) 0.002166 0.002122 0.002125 0.002138   (32,16) 0.001677 0.001696 0.001703 0.001692   (32,8) 0.001925 0.001929 0.001925 0.001926   (64,16) 0.002117 0.002146 0.002113 0.002125   (64,8) 0.001949 0.001945 0.001945 0.001946   (128,8) 0.002228 0.002230 0.002229 0.002229    这是简单的实验结果，可见（32，16）的这种模式效率最高\n总结 本文主要讲解内存带宽对效率的影响以及如何有效地通过调整读取方式来突破内存存储瓶颈，这是我们优化CUDA程序非常重要的手段\n","wordCount":"587","inLanguage":"en","datePublished":"2018-05-13T12:08:02Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"谭升"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-4-4-%E6%A0%B8%E5%87%BD%E6%95%B0%E5%8F%AF%E8%BE%BE%E5%88%B0%E7%9A%84%E5%B8%A6%E5%AE%BD.zh/"},"publisher":{"@type":"Organization","name":"谭升的博客","logo":{"@type":"ImageObject","url":"https://go.face2ai.com/logo.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://go.face2ai.com accesskey=h title="谭升的博客 (Alt + H)">谭升的博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://go.face2ai.com/math/ title=数学><span>数学</span></a></li><li><a href=https://go.face2ai.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://go.face2ai.com/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://go.face2ai.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://go.face2ai.com/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://go.face2ai.com>Home</a></div><h1 class=post-title>【CUDA 基础】4.4 核函数可达到的带宽</h1><div class=post-meta><span title="2018-05-13 12:08:02 +0000 UTC">May 13, 2018</span>&nbsp;·&nbsp;谭升</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e6%a0%b8%e5%87%bd%e6%95%b0%e5%8f%af%e8%be%be%e5%88%b0%e7%9a%84%e5%b8%a6%e5%ae%bd aria-label=核函数可达到的带宽>核函数可达到的带宽</a><ul><li><a href=#%e5%86%85%e5%ad%98%e5%b8%a6%e5%ae%bd aria-label=内存带宽>内存带宽</a></li><li><a href=#%e7%9f%a9%e9%98%b5%e8%bd%ac%e7%bd%ae%e9%97%ae%e9%a2%98 aria-label=矩阵转置问题>矩阵转置问题</a><ul><li><a href=#%e4%b8%ba%e8%bd%ac%e7%bd%ae%e6%a0%b8%e5%87%bd%e6%95%b0%e8%ae%be%e7%bd%ae%e4%b8%8a%e9%99%90%e5%92%8c%e4%b8%8b%e9%99%90 aria-label=为转置核函数设置上限和下限>为转置核函数设置上限和下限</a></li><li><a href=#%e6%9c%b4%e7%b4%a0%e8%bd%ac%e7%bd%ae%e8%af%bb%e5%8f%96%e8%a1%8c%e4%b8%8e%e8%af%bb%e5%8f%96%e5%88%97 aria-label=朴素转置：读取行与读取列>朴素转置：读取行与读取列</a></li><li><a href=#%e5%b1%95%e5%bc%80%e8%bd%ac%e7%bd%ae%e8%af%bb%e5%8f%96%e8%a1%8c%e4%b8%8e%e8%af%bb%e5%8f%96%e5%88%97 aria-label=展开转置：读取行与读取列>展开转置：读取行与读取列</a></li><li><a href=#%e5%af%b9%e8%a7%92%e8%bd%ac%e7%bd%ae%e8%af%bb%e5%8f%96%e8%a1%8c%e4%b8%8e%e8%af%bb%e5%8f%96%e5%88%97 aria-label=对角转置：读取行与读取列>对角转置：读取行与读取列</a></li><li><a href=#%e7%98%a6%e5%9d%97%e6%9d%a5%e5%a2%9e%e5%8a%a0%e5%b9%b6%e8%a1%8c%e6%80%a7 aria-label=瘦块来增加并行性>瘦块来增加并行性</a></li></ul></li><li><a href=#%e6%80%bb%e7%bb%93 aria-label=总结>总结</a></li></ul></li></ul></div></details></div><div class=post-content><p><strong>Abstract:</strong> 本文通过矩阵转置这一个例子，调整，优化核函数，使其达到最优的内存带宽
<strong>Keywords:</strong> 带宽，吞吐量，矩阵转置</p><h1 id=核函数可达到的带宽>核函数可达到的带宽<a hidden class=anchor aria-hidden=true href=#核函数可达到的带宽>#</a></h1><p>下面是废话，与本文知识无关，可以直接跳到下面红字处开始本文知识的学习。
废话继续，这两天没更新博客了，上一篇是转发的MIT人工智能实验室的研究指南，也就是告诉刚入学的研究生怎么做研究，要怎么积累，那篇文章发表在1988年，MIT的AI实验室网站目前仍然能检索的到，通读全文，感受很多，也学会了很多东西，当一个健康的框架搭好了以后，后面的好功能会源源不断的涌现，教育也是，当一套体系形成，那么就会有源源不断的人才和成果出现，相反，如果体系本身漏洞百出，根基不稳，短时间真的改不了，人也一样，价值观一旦确定，这个人的人生也就基本定型了——正所谓三岁看老。
<font color=ff0000>今天废话有点多，如果没兴趣，可以直接跳到这里</font>
上一章我们研究怎么通过调整线程网格结构和核函数来达到SM的最高利用率，今天我们来研究如何达到内存带宽的最大利用率。
还是要提那个老例子，但是说实话，这的很形象，也很有用，记住这个例子基本就能了解CUDA的优化大概要从哪入手了：
<strong>一条大路（<font color=00ff00>内存读取总线</font>）连接了工厂生产车间（<font color=00ff00>GPU</font>）和材料仓库（<font color=00ff00>全局内存</font>），生产车间又有很多的工作小组（<font color=00ff00>SM</font>），材料仓库有很多小库房（<font color=00ff00>内存分块</font>），工作小组同时生产相同的产品互不干扰（<font color=00ff00>并行</font>），我们有车从材料仓库开往工厂车间，什么时候发车，运输什么由工作小组远程电话指挥（<font color=00ff00>内存请求</font>），发车前，从材料仓库装货的时候，还要听从仓库管理员的分配，因为可能同一间库房可能只允许一个车来拿材料（<font color=00ff00>内存块访问阻塞</font>），然后这些车单向的开往工厂，这时候就是交通问题了，如果我们的路是单向（从仓库到工厂）8车道，每秒钟能通过16辆车，那么我们把这个指标称为带宽。当然我们还有一条路是将成品运输到成品仓库，这也是一条路，与原料库互不干扰，和材料仓库到工厂的路一样，也有宽度，也是单向的，如果这条路堵住，和仓库到工厂的路堵住一样，此时工厂要停工等待。
最理想的状态是，路上全是车，并且全都高速行驶，工厂里的所有工人都在满负荷工作，没有等待，这就是优化的最终目标，如果这个目标达到了，还想进一步提高效率，那么你就只能优化你的工艺了（<font color=00ff00>算法</font>）</strong>
上面的这个就是粗糙的GPU工作过程。例子还是比较贴切的，但是有点描述粗糙，多读两遍应该会有点收获的。
内存延迟是影响核函数的一大关键，内存延迟，也就是从你发起内存请求到数据进入SM的寄存器的整个时间。
内存带宽，也就是SM访问内存的速度，它以单位时间内传输的字节数进行测量。
上一节我们用了两种方法改善内核性能：</p><ul><li>最大化线程束的数量来隐藏内存延迟，维持更多的正在执行的内存访问达到更好的总线利用率</li><li>通过适当的对齐和合并访问，提高带宽效率</li></ul><p>然而，当前内核本身的内存访问方式就有问题，上面两种优化相当于给一个拖拉机优化空气动力学外观，杯水车薪。
我们本文要做的就是看看这个核函数对应的问题，其极限效率是多少，在理想效率之下，我们来进行优化，我们本文那矩阵转置来进行研究，看看如何把一种看起来没办法优化的内核，重新设计让它达到更好的性能。</p><h2 id=内存带宽>内存带宽<a hidden class=anchor aria-hidden=true href=#内存带宽>#</a></h2><p>多数内核对带宽敏感，也就是说，工人们生产效率特别高，而原料来的很慢，这限制了生产速度。去哪聚内存中数据的安排方式和线程束的访问方式都对带宽有显著影响。一般有如下两种带宽</p><ul><li>理论带宽</li><li>有效带宽</li></ul><p>理论带宽就是硬件设计的绝对最大值，硬件限制了这个最大值为多少，比如对于不使用ECC的Fermi M2090来说，理论峰值 117.6 GB/s
有效带宽是核函数实际达到的带宽，是测量带宽，可以用下面公式计算:
$$
有效带宽=\frac{(读字节数 + 写字节数)\times 10^{-9}}{运行时间}\tag{1}
$$
注意吞吐量和带宽的区别，吞吐量是衡量计算核心效率的，用的单位是每秒多少十亿次浮点运算(gflops)，有效吞吐量其不止和有效带宽有关，还和带宽的利用率等因素有关，当然最主要的还是设备的运算核心。
当然，也有内存吞吐量这种说法这种说法就是单位时间上内存访问的总量，用单位 GB/s 表示，这个值越大表示读取到的数据越多，但是这些数据不一定是有用的。
接下来我们研究如何调整核函数来提高有效带宽</p><h2 id=矩阵转置问题>矩阵转置问题<a hidden class=anchor aria-hidden=true href=#矩阵转置问题>#</a></h2><p><a href=https://face2ai.com/Math-Linear-Algebra-Chapter-2-7/>矩阵转置(点击查看详情)</a>就是交换矩阵的坐标，我们本文研究有二维矩阵，转置结果如下：</p><p><img loading=lazy src=./4-4-1.png alt=4-4-1></p><p>使用串行编程很容易实现：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>void</span> <span class=nf>transformMatrix2D_CPU</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatA</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatB</span><span class=p>,</span><span class=kt>int</span> <span class=n>nx</span><span class=p>,</span><span class=kt>int</span> <span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>j</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;</span><span class=n>ny</span><span class=p>;</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;</span><span class=n>nx</span><span class=p>;</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=n>MatB</span><span class=p>[</span><span class=n>i</span><span class=o>*</span><span class=n>nx</span><span class=o>+</span><span class=n>j</span><span class=p>]</span><span class=o>=</span><span class=n>MatA</span><span class=p>[</span><span class=n>j</span><span class=o>*</span><span class=n>nx</span><span class=o>+</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>这段代码应该比较容易懂，这是串行解决的方法，必须要注意的是，我们所有的数据，结构体也好，数组也好，多维数组也好，所有的数据，在内存硬件层面都是一维排布的，所以我们这里也是使用一维的数组作为输入输出，那么从真实的角度看内存中的数据就是下面这样的：</p><p><img loading=lazy src=./4-4-2.png alt=4-4-2></p><p>通过这个图能得出一个结论，转置操作：</p><ul><li>读：原矩阵行进行读取，请求的内存是连续的，可以进行合并访问</li><li>写：写到转置矩阵的列中，访问是交叉的</li></ul><p>图中的颜色需要大家注意一下，读的过程同一颜色可以看成是合并读取的，但是转置发生后写入的过程，是交叉的。
交叉访问是使得内存访问变差的罪魁。但是作为矩阵转置本身，这个是无法避免的。但是在这种无法避免的交叉访问前提下，我们怎么能提升效率就变成了一个有趣的课题。
我们接下来所有方法都会有按照行读取和按照列读取的版本，来对比效率，看看是交叉读有优势，还是交叉写有优势。
如果按照我们上文的观点，如果按照下面两种方法进行读</p><p><img loading=lazy src=./4-4-3.png alt=4-4-3></p><p>最初的想法肯定是：按照图一合并读更有效率，因为写的时候不需要经过一级缓存，所以对于有一级缓存的程序，合并的读取应该是更有效率的。如果你这么想，恭喜你，你想的不对（我当时也是这么想的）。
我们需要补充下关于一级缓存的作用，上文我们讲到合并，可能第一印象就是一级缓存是缓冲从全局内存里过来的数据一样，但是我们忽略了一些东西，就是内存发起加载请求的时候，会现在一级缓存里看看有没有这个数据，如果有，这个就是一个命中，这和CPU的缓存运行原理是一样的，如果命中了，就不需要再去全局内存读了，如果用在上面这个例子，虽然按照列读是不合并的，但是使用一级缓存加载过来的数据在后面会被使用，我们必须要注意虽然，一级缓存一次读取128字节的数据，其中只有一个单位是有用的，但是剩下的并不会被马上覆盖，粒度是128字节，但是一级缓存的大小有几k或是更大，这些数据很有可能不会被替换，所以，我们按列读取数据，虽然第一行只用了一个，但是下一列的时候，理想情况是所有需要读取的元素都在一级缓存中，这时候，数据直接从缓存里面读取，美滋滋！</p><h3 id=为转置核函数设置上限和下限>为转置核函数设置上限和下限<a hidden class=anchor aria-hidden=true href=#为转置核函数设置上限和下限>#</a></h3><p>在优化之前，我们要给自己一个目标，也就是理论上极限是多少，比如我们测得理论极限是10，而我们已经花了一天时间优化到了9.8，就没必要再花10天优化到9.9了，因为这已经很接近极限了，如果不知道极限，那么就会在无限的接近中浪费时间。
我们本例子中的瓶颈在交叉访问，所以我们假设没有交叉访问，和全是交叉访问的情况，来给出上限和下限：</p><ul><li>行读取，行存储来复制矩阵(上限)</li><li>列读取，列存储来复制矩阵(下限)</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>copyRow</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatA</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatB</span><span class=p>,</span><span class=kt>int</span> <span class=n>nx</span><span class=p>,</span><span class=kt>int</span> <span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>ix</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>iy</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>y</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>y</span><span class=o>*</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>y</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx</span><span class=o>=</span><span class=n>ix</span><span class=o>+</span><span class=n>iy</span><span class=o>*</span><span class=n>nx</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>ix</span><span class=o>&lt;</span><span class=n>nx</span> <span class=o>&amp;&amp;</span> <span class=n>iy</span><span class=o>&lt;</span><span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=n>MatB</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=o>=</span><span class=n>MatA</span><span class=p>[</span><span class=n>idx</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>copyCol</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatA</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatB</span><span class=p>,</span><span class=kt>int</span> <span class=n>nx</span><span class=p>,</span><span class=kt>int</span> <span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>ix</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>iy</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>y</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>y</span><span class=o>*</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>y</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx</span><span class=o>=</span><span class=n>ix</span><span class=o>*</span><span class=n>ny</span><span class=o>+</span><span class=n>iy</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>ix</span><span class=o>&lt;</span><span class=n>nx</span> <span class=o>&amp;&amp;</span> <span class=n>iy</span><span class=o>&lt;</span><span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=n>MatB</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=o>=</span><span class=n>MatA</span><span class=p>[</span><span class=n>idx</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>我们使用命令行编译，开启一级缓存：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>nvcc -O3 -arch<span class=o>=</span>sm_35 -Xptxas -dlcm<span class=o>=</span>ca -I ../include/ transform_matrix2D.cu -o transform_matrix2D
</span></span></code></pre></div><p><img loading=lazy src=./4-4-4.png alt=4-4-4></p><p>可以得到：</p><table><thead><tr><th style=text-align:center>核函数</th><th style=text-align:center>试验1</th><th style=text-align:center>试验2</th><th style=text-align:center>试验3</th><th style=text-align:center>平均值</th></tr></thead><tbody><tr><td style=text-align:center>上限</td><td style=text-align:center>0.001611</td><td style=text-align:center>0.001614</td><td style=text-align:center>0.001606</td><td style=text-align:center>0.001610</td></tr><tr><td style=text-align:center>下限</td><td style=text-align:center>0.004191</td><td style=text-align:center>0.004210</td><td style=text-align:center>0.004205</td><td style=text-align:center>0.004202</td></tr></tbody></table><p>这个时间是三次测试出来的平均值，基本可以肯定在当前数据规模下，上限在0.001610s，下限在0.004202s，不可能超过上限，当然如果你能跌破下限也算是人才了！
另外，我们我们全文用的主函数我只在此列举一次，完成代码库在<a href=https://github.com/Tony-Tan/CUDA_Freshman>https://github.com/Tony-Tan/CUDA_Freshman</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>(</span><span class=kt>int</span> <span class=n>argc</span><span class=p>,</span><span class=kt>char</span><span class=o>**</span> <span class=n>argv</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=n>printf</span><span class=p>(</span><span class=s>&#34;strating...</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>initDevice</span><span class=p>(</span><span class=mi>0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>nx</span><span class=o>=</span><span class=mi>1</span><span class=o>&lt;&lt;</span><span class=mi>12</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>ny</span><span class=o>=</span><span class=mi>1</span><span class=o>&lt;&lt;</span><span class=mi>12</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>nxy</span><span class=o>=</span><span class=n>nx</span><span class=o>*</span><span class=n>ny</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>nBytes</span><span class=o>=</span><span class=n>nxy</span><span class=o>*</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>transform_kernel</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span><span class=p>(</span><span class=n>argc</span><span class=o>&gt;=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>transform_kernel</span><span class=o>=</span><span class=n>atoi</span><span class=p>(</span><span class=n>argv</span><span class=p>[</span><span class=mi>1</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>  <span class=c1>//Malloc
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=kt>float</span><span class=o>*</span> <span class=n>A_host</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nBytes</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span><span class=o>*</span> <span class=n>B_host</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nBytes</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>initialData</span><span class=p>(</span><span class=n>A_host</span><span class=p>,</span><span class=n>nxy</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1>//cudaMalloc
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=kt>float</span> <span class=o>*</span><span class=n>A_dev</span><span class=o>=</span><span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>B_dev</span><span class=o>=</span><span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>A_dev</span><span class=p>,</span><span class=n>nBytes</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>B_dev</span><span class=p>,</span><span class=n>nBytes</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>A_dev</span><span class=p>,</span><span class=n>A_host</span><span class=p>,</span><span class=n>nBytes</span><span class=p>,</span><span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemset</span><span class=p>(</span><span class=n>B_dev</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=n>nBytes</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>dimx</span><span class=o>=</span><span class=mi>32</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>dimy</span><span class=o>=</span><span class=mi>32</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1>// cpu compute
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=kt>double</span> <span class=n>iStart</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=n>transformMatrix2D_CPU</span><span class=p>(</span><span class=n>A_host</span><span class=p>,</span><span class=n>B_host</span><span class=p>,</span><span class=n>nx</span><span class=p>,</span><span class=n>ny</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>double</span> <span class=n>iElaps</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>()</span><span class=o>-</span><span class=n>iStart</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>printf</span><span class=p>(</span><span class=s>&#34;CPU Execution Time elapsed %f sec</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>iElaps</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1>// 2d block and 2d grid
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=n>dim3</span> <span class=n>block</span><span class=p>(</span><span class=n>dimx</span><span class=p>,</span><span class=n>dimy</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>dim3</span> <span class=n>grid</span><span class=p>((</span><span class=n>nx</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>/</span><span class=n>block</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=mi>1</span><span class=p>,(</span><span class=n>ny</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>/</span><span class=n>block</span><span class=p>.</span><span class=n>y</span><span class=o>+</span><span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>dim3</span> <span class=n>block_1</span><span class=p>(</span><span class=n>dimx</span><span class=p>,</span><span class=n>dimy</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>dim3</span> <span class=n>grid_1</span><span class=p>((</span><span class=n>nx</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>block_1</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>4</span><span class=p>)</span><span class=o>+</span><span class=mi>1</span><span class=p>,(</span><span class=n>ny</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>/</span><span class=n>block_1</span><span class=p>.</span><span class=n>y</span><span class=o>+</span><span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>iStart</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=k>switch</span><span class=p>(</span><span class=n>transform_kernel</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=k>case</span> <span class=mi>0</span><span class=o>:</span>
</span></span><span class=line><span class=cl>    <span class=n>copyRow</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid</span><span class=p>,</span><span class=n>block</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>A_dev</span><span class=p>,</span><span class=n>B_dev</span><span class=p>,</span><span class=n>nx</span><span class=p>,</span><span class=n>ny</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>case</span> <span class=mi>1</span><span class=o>:</span>
</span></span><span class=line><span class=cl>    <span class=n>copyCol</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid</span><span class=p>,</span><span class=n>block</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>A_dev</span><span class=p>,</span><span class=n>B_dev</span><span class=p>,</span><span class=n>nx</span><span class=p>,</span><span class=n>ny</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>case</span> <span class=mi>2</span><span class=o>:</span>
</span></span><span class=line><span class=cl>    <span class=n>transformNaiveRow</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid</span><span class=p>,</span><span class=n>block</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>A_dev</span><span class=p>,</span><span class=n>B_dev</span><span class=p>,</span><span class=n>nx</span><span class=p>,</span><span class=n>ny</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>case</span> <span class=mi>3</span><span class=o>:</span>
</span></span><span class=line><span class=cl>        <span class=n>transformNaiveCol</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid</span><span class=p>,</span><span class=n>block</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>A_dev</span><span class=p>,</span><span class=n>B_dev</span><span class=p>,</span><span class=n>nx</span><span class=p>,</span><span class=n>ny</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>case</span> <span class=mi>4</span><span class=o>:</span>
</span></span><span class=line><span class=cl>        <span class=n>transformNaiveColUnroll</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid_1</span><span class=p>,</span><span class=n>block_1</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>A_dev</span><span class=p>,</span><span class=n>B_dev</span><span class=p>,</span><span class=n>nx</span><span class=p>,</span><span class=n>ny</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>case</span> <span class=mi>5</span><span class=o>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>transformNaiveColUnroll</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid_1</span><span class=p>,</span><span class=n>block_1</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>A_dev</span><span class=p>,</span><span class=n>B_dev</span><span class=p>,</span><span class=n>nx</span><span class=p>,</span><span class=n>ny</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>case</span> <span class=mi>6</span><span class=o>:</span>
</span></span><span class=line><span class=cl>        <span class=n>transformNaiveRowDiagonal</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid</span><span class=p>,</span><span class=n>block</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>A_dev</span><span class=p>,</span><span class=n>B_dev</span><span class=p>,</span><span class=n>nx</span><span class=p>,</span><span class=n>ny</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>case</span> <span class=mi>7</span><span class=o>:</span>
</span></span><span class=line><span class=cl>        <span class=n>transformNaiveColDiagonal</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid</span><span class=p>,</span><span class=n>block</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>A_dev</span><span class=p>,</span><span class=n>B_dev</span><span class=p>,</span><span class=n>nx</span><span class=p>,</span><span class=n>ny</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>default</span><span class=o>:</span>
</span></span><span class=line><span class=cl>    <span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaDeviceSynchronize</span><span class=p>());</span>
</span></span><span class=line><span class=cl>  <span class=n>iElaps</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>()</span><span class=o>-</span><span class=n>iStart</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>printf</span><span class=p>(</span><span class=s>&#34; Time elapsed %f sec</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>iElaps</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>B_host</span><span class=p>,</span><span class=n>B_dev</span><span class=p>,</span><span class=n>nBytes</span><span class=p>,</span><span class=n>cudaMemcpyDeviceToHost</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>checkResult</span><span class=p>(</span><span class=n>B_host</span><span class=p>,</span><span class=n>B_host</span><span class=p>,</span><span class=n>nxy</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>A_dev</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>B_dev</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>A_host</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>B_host</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaDeviceReset</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>switch部分可以写成函数指针的方式，但是问题不大（原文写的应该是函数指针的方式）。
我的笔记本是1050ti的显卡，这个表可能是主机版本的1050ti的指标，可以看出其理论贷款是112GB/s
<img loading=lazy src=./4-4-5.png alt=4-4-5></p><p>我们使用公式(1)来算一下两种极限的带宽：
$$
\text{copyRow}=\frac{1\times2^{12+12}\times 4\times 2\times 10^{-9}}{0.001610}=\frac{0.134217728}{0.001610}=83.3650 \text{ GB/s}\
\text{copyCol}=\frac{1\times2^{12+12}\times 4\times 2\times 10^{-9}}{0.004202}=\frac{0.134217728}{0.004202}=31.9414 \text{ GB/s}
$$</p><h3 id=朴素转置读取行与读取列>朴素转置：读取行与读取列<a hidden class=anchor aria-hidden=true href=#朴素转置读取行与读取列>#</a></h3><p>接下来我们看最naive的两种转置方法，不加任何优化，也就是我们一瞬间就想到的方案：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>transformNaiveRow</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatA</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatB</span><span class=p>,</span><span class=kt>int</span> <span class=n>nx</span><span class=p>,</span><span class=kt>int</span> <span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>ix</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>iy</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>y</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>y</span><span class=o>*</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>y</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx_row</span><span class=o>=</span><span class=n>ix</span><span class=o>+</span><span class=n>iy</span><span class=o>*</span><span class=n>nx</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx_col</span><span class=o>=</span><span class=n>ix</span><span class=o>*</span><span class=n>ny</span><span class=o>+</span><span class=n>iy</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>ix</span><span class=o>&lt;</span><span class=n>nx</span> <span class=o>&amp;&amp;</span> <span class=n>iy</span><span class=o>&lt;</span><span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=n>MatB</span><span class=p>[</span><span class=n>idx_col</span><span class=p>]</span><span class=o>=</span><span class=n>MatA</span><span class=p>[</span><span class=n>idx_row</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>transformNaiveCol</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatA</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatB</span><span class=p>,</span><span class=kt>int</span> <span class=n>nx</span><span class=p>,</span><span class=kt>int</span> <span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>ix</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>iy</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>y</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>y</span><span class=o>*</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>y</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx_row</span><span class=o>=</span><span class=n>ix</span><span class=o>+</span><span class=n>iy</span><span class=o>*</span><span class=n>nx</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx_col</span><span class=o>=</span><span class=n>ix</span><span class=o>*</span><span class=n>ny</span><span class=o>+</span><span class=n>iy</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>ix</span><span class=o>&lt;</span><span class=n>nx</span> <span class=o>&amp;&amp;</span> <span class=n>iy</span><span class=o>&lt;</span><span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=n>MatB</span><span class=p>[</span><span class=n>idx_row</span><span class=p>]</span><span class=o>=</span><span class=n>MatA</span><span class=p>[</span><span class=n>idx_col</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>运行时间：</p><p><img loading=lazy src=./4-4-6.png alt=4-4-6></p><table><thead><tr><th style=text-align:center>核函数</th><th style=text-align:center>试验1</th><th style=text-align:center>试验2</th><th style=text-align:center>试验3</th><th style=text-align:center>平均值</th></tr></thead><tbody><tr><td style=text-align:center>transformNaiveRow</td><td style=text-align:center>0.004008</td><td style=text-align:center>0.004005</td><td style=text-align:center>0.004012</td><td style=text-align:center>0.004008</td></tr><tr><td style=text-align:center>transformNaiveCol</td><td style=text-align:center>0.002126</td><td style=text-align:center>0.002118</td><td style=text-align:center>0.002124</td><td style=text-align:center>0.002123</td></tr></tbody></table><p>$$
\text{transformNaiveRow}=\frac{1\times2^{12+12}\times 4\times 2\times 10^{-9}}{0.001610}=\frac{0.134217728}{0.004008}= 33.4874 \text{ GB/s}\
\text{transformNaiveCol}=\frac{1\times2^{12+12}\times 4\times 2\times 10^{-9}}{0.004202}=\frac{0.134217728}{0.002123}= 63.2207 \text{ GB/s}
$$</p><p>使用按列读取效果更好，这和我们前面分析的基本一致。
下面是使用一级缓存的加载存储吞吐量
<img loading=lazy src=./4-4-7.png alt=4-4-7></p><p><img loading=lazy src=./4-4-8.png alt=4-4-8></p><table><thead><tr><th style=text-align:center>核函数</th><th style=text-align:center>加载吞吐量</th><th style=text-align:center>存储吞吐量</th></tr></thead><tbody><tr><td style=text-align:center>copyRow</td><td style=text-align:center>81.263</td><td style=text-align:center>40.631</td></tr><tr><td style=text-align:center>copyCol</td><td style=text-align:center>120.93</td><td style=text-align:center>120.93</td></tr><tr><td style=text-align:center>transformNaiveRow</td><td style=text-align:center>31.717</td><td style=text-align:center>126.87</td></tr><tr><td style=text-align:center>transformNaiveCol</td><td style=text-align:center>243.64</td><td style=text-align:center>30.454</td></tr></tbody></table><p>按列读取的高吞吐量的原因就是上面我们说的缓存命中，这里也能看到吞吐量是可以超过带宽的，因为带宽衡量的是从全局内存到SM的速度极限，而吞吐量是SM获得数据的总量除以时间，而这些数据可以来自一级缓存，而不必千里迢迢从主存读取。
这里有个疑问：虽然交叉读取缓存命中率高了，但是似乎并没有减少从主存读取数据的数据量，那为什么速度会有提高呢？
我认为应该是延迟隐藏部分出的问题，导致了交叉读取效率变高，当然只是我的猜测后面还要验证一下。</p><h3 id=展开转置读取行与读取列>展开转置：读取行与读取列<a hidden class=anchor aria-hidden=true href=#展开转置读取行与读取列>#</a></h3><p>接下来这个是老套路了，有效地隐藏延迟，从展开操作开始：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>transformNaiveRowUnroll</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatA</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatB</span><span class=p>,</span><span class=kt>int</span> <span class=n>nx</span><span class=p>,</span><span class=kt>int</span> <span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>ix</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>4</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>iy</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>y</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>y</span><span class=o>*</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>y</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx_row</span><span class=o>=</span><span class=n>ix</span><span class=o>+</span><span class=n>iy</span><span class=o>*</span><span class=n>nx</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx_col</span><span class=o>=</span><span class=n>ix</span><span class=o>*</span><span class=n>ny</span><span class=o>+</span><span class=n>iy</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>ix</span><span class=o>&lt;</span><span class=n>nx</span> <span class=o>&amp;&amp;</span> <span class=n>iy</span><span class=o>&lt;</span><span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=n>MatB</span><span class=p>[</span><span class=n>idx_col</span><span class=p>]</span><span class=o>=</span><span class=n>MatA</span><span class=p>[</span><span class=n>idx_row</span><span class=p>];</span>
</span></span><span class=line><span class=cl>      <span class=n>MatB</span><span class=p>[</span><span class=n>idx_col</span><span class=o>+</span><span class=n>ny</span><span class=o>*</span><span class=mi>1</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>=</span><span class=n>MatA</span><span class=p>[</span><span class=n>idx_row</span><span class=o>+</span><span class=mi>1</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>];</span>
</span></span><span class=line><span class=cl>      <span class=n>MatB</span><span class=p>[</span><span class=n>idx_col</span><span class=o>+</span><span class=n>ny</span><span class=o>*</span><span class=mi>2</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>=</span><span class=n>MatA</span><span class=p>[</span><span class=n>idx_row</span><span class=o>+</span><span class=mi>2</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>];</span>
</span></span><span class=line><span class=cl>      <span class=n>MatB</span><span class=p>[</span><span class=n>idx_col</span><span class=o>+</span><span class=n>ny</span><span class=o>*</span><span class=mi>3</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>=</span><span class=n>MatA</span><span class=p>[</span><span class=n>idx_row</span><span class=o>+</span><span class=mi>3</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>transformNaiveColUnroll</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatA</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatB</span><span class=p>,</span><span class=kt>int</span> <span class=n>nx</span><span class=p>,</span><span class=kt>int</span> <span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>ix</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>4</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>iy</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>y</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>y</span><span class=o>*</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>y</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx_row</span><span class=o>=</span><span class=n>ix</span><span class=o>+</span><span class=n>iy</span><span class=o>*</span><span class=n>nx</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx_col</span><span class=o>=</span><span class=n>ix</span><span class=o>*</span><span class=n>ny</span><span class=o>+</span><span class=n>iy</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>ix</span><span class=o>&lt;</span><span class=n>nx</span> <span class=o>&amp;&amp;</span> <span class=n>iy</span><span class=o>&lt;</span><span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>MatB</span><span class=p>[</span><span class=n>idx_row</span><span class=p>]</span><span class=o>=</span><span class=n>MatA</span><span class=p>[</span><span class=n>idx_col</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=n>MatB</span><span class=p>[</span><span class=n>idx_row</span><span class=o>+</span><span class=mi>1</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>=</span><span class=n>MatA</span><span class=p>[</span><span class=n>idx_col</span><span class=o>+</span><span class=n>ny</span><span class=o>*</span><span class=mi>1</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=n>MatB</span><span class=p>[</span><span class=n>idx_row</span><span class=o>+</span><span class=mi>2</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>=</span><span class=n>MatA</span><span class=p>[</span><span class=n>idx_col</span><span class=o>+</span><span class=n>ny</span><span class=o>*</span><span class=mi>2</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=n>MatB</span><span class=p>[</span><span class=n>idx_row</span><span class=o>+</span><span class=mi>3</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>=</span><span class=n>MatA</span><span class=p>[</span><span class=n>idx_col</span><span class=o>+</span><span class=n>ny</span><span class=o>*</span><span class=mi>3</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>结果如图</p><p><img loading=lazy src=./4-4-9.png alt=4-4-9></p><table><thead><tr><th style=text-align:center>核函数</th><th style=text-align:center>试验1</th><th style=text-align:center>试验2</th><th style=text-align:center>试验3</th><th style=text-align:center>平均值</th></tr></thead><tbody><tr><td style=text-align:center>transformNaiveRowUnroll</td><td style=text-align:center>0.001544</td><td style=text-align:center>0.001550</td><td style=text-align:center>001541</td><td style=text-align:center>0.001545</td></tr><tr><td style=text-align:center>transformNaiveColUnroll</td><td style=text-align:center>0.001545</td><td style=text-align:center>0.001539</td><td style=text-align:center>0.001546</td><td style=text-align:center>0.001543</td></tr></tbody></table><p>这里出现了尴尬的一幕，没错，我们突破上限了，上限是按行合并读取，合并存储，不存在交叉的情况，这种理想情况不可能发生在转置中，所以我们说这是上限。而我们使用展开的交叉访问居然得到了比上限更快的速度，所以我断定，如果把上限展开，速度肯定会更快，但是我们这里还把他叫做上限，虽然并不是真正的上限。
想要知道真正的上限是什么，就要从硬件角度算理论上限，实际测出来的上限很有可能不正确。</p><h3 id=对角转置读取行与读取列>对角转置：读取行与读取列<a hidden class=anchor aria-hidden=true href=#对角转置读取行与读取列>#</a></h3><p>接下来我们使用一点新技巧，这个技巧的来源是DRAM的特性导致的，还记得我们例子中对原料仓库的描述么，那里面有很多小库房，这些小库房同时可能只允许一台车拿东西，在DRAM中内存是分区规划的，如果过多的访问同一个区，会产生排队的现象，也就是要等待，为了避免这种情况，我们最好均匀的访问DRAM的某一段，DRAM的分区是每256个字节算一个分区，所以我们最好错开同一个分区的访问，方法就是调整块的ID，这时候你可能有问题了，我们并不知道块的执行顺序，那应该怎么调呢，这个问题没有啥官方解释，我自己的理解是，硬件执行线程块必然是按照某种规则进行的，按照123执行，可能要比按照随机执行好，因为想要随机执行，还要有生成随机顺序这一步，根本没必要，我们之所以说块的执行顺序不确定，其实是为了避免大家把它理解为确定顺序，而实际上可能有某些原因导致顺序错乱，但是这个绝对不是硬件设计时故意而为之的。
我们这个对角转置的目的就是使得读取DRAM位置均匀一点，别都集中在一个分区上，方法是打乱线程块，因为连续的线程块可能访问相近的DRAM地址。
我们的方案是使用一个函数 $f(x,y)=(m,n)$ 一个一一对应的函数，将原始笛卡尔坐标打乱。
注意，所有这些线程块的顺序什么的都是在编程模型基础上的，跟硬件没什么关系，这些都是逻辑层面的，实际上线程块ID对应的是哪个线程块也是我们自己规定的而已。
说实话，这个代码有点难理解，当然你也不用死记硬背这种用法，似乎没有程序员被代码，甚至入门的过程都不用背，我们要理解的就是线程块ID和线程块之间的对应，以及新ID和原始ID的对应，以及新ID对应的块，
原始的线程块ID
<img loading=lazy src=./4-4-10.png alt=4-4-10></p><p>新设计的线程块ID</p><p><img loading=lazy src=./4-4-11.png alt=4-4-11></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>transformNaiveRowDiagonal</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatA</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatB</span><span class=p>,</span><span class=kt>int</span> <span class=n>nx</span><span class=p>,</span><span class=kt>int</span> <span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>block_y</span><span class=o>=</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>block_x</span><span class=o>=</span><span class=p>(</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>y</span><span class=p>)</span><span class=o>%</span><span class=n>gridDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>ix</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>block_x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>iy</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>y</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>y</span><span class=o>*</span><span class=n>block_y</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx_row</span><span class=o>=</span><span class=n>ix</span><span class=o>+</span><span class=n>iy</span><span class=o>*</span><span class=n>nx</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx_col</span><span class=o>=</span><span class=n>ix</span><span class=o>*</span><span class=n>ny</span><span class=o>+</span><span class=n>iy</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>ix</span><span class=o>&lt;</span><span class=n>nx</span> <span class=o>&amp;&amp;</span> <span class=n>iy</span><span class=o>&lt;</span><span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=n>MatB</span><span class=p>[</span><span class=n>idx_col</span><span class=p>]</span><span class=o>=</span><span class=n>MatA</span><span class=p>[</span><span class=n>idx_row</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>transformNaiveColDiagonal</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatA</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>MatB</span><span class=p>,</span><span class=kt>int</span> <span class=n>nx</span><span class=p>,</span><span class=kt>int</span> <span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>block_y</span><span class=o>=</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>block_x</span><span class=o>=</span><span class=p>(</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>y</span><span class=p>)</span><span class=o>%</span><span class=n>gridDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>ix</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>block_x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>iy</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>y</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>y</span><span class=o>*</span><span class=n>block_y</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx_row</span><span class=o>=</span><span class=n>ix</span><span class=o>+</span><span class=n>iy</span><span class=o>*</span><span class=n>nx</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx_col</span><span class=o>=</span><span class=n>ix</span><span class=o>*</span><span class=n>ny</span><span class=o>+</span><span class=n>iy</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>ix</span><span class=o>&lt;</span><span class=n>nx</span> <span class=o>&amp;&amp;</span> <span class=n>iy</span><span class=o>&lt;</span><span class=n>ny</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=n>MatB</span><span class=p>[</span><span class=n>idx_row</span><span class=p>]</span><span class=o>=</span><span class=n>MatA</span><span class=p>[</span><span class=n>idx_col</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><img loading=lazy src=./4-4-12.png alt=4-4-12></p><p>这个速度还没有展开的版本快，甚至没有naive的交叉读取速度快，但书上说的是效率有提高，可能是CUDA升级后的原因吧，或者其他原因的影响，但是DRAM分区会出现排队这种现象值得注意。</p><h3 id=瘦块来增加并行性>瘦块来增加并行性<a hidden class=anchor aria-hidden=true href=#瘦块来增加并行性>#</a></h3><p>接下来老套路，调整一下线程块的尺寸我们看看有没有啥变化，当然，我们以naive的列读取作为对照。</p><table><thead><tr><th style=text-align:center>block尺寸</th><th style=text-align:center>测试1</th><th style=text-align:center>测试2</th><th style=text-align:center>测试3</th><th style=text-align:center>平均值</th></tr></thead><tbody><tr><td style=text-align:center>(32,32)</td><td style=text-align:center>0.002166</td><td style=text-align:center>0.002122</td><td style=text-align:center>0.002125</td><td style=text-align:center>0.002138</td></tr><tr><td style=text-align:center>(32,16)</td><td style=text-align:center>0.001677</td><td style=text-align:center>0.001696</td><td style=text-align:center>0.001703</td><td style=text-align:center>0.001692</td></tr><tr><td style=text-align:center>(32,8)</td><td style=text-align:center>0.001925</td><td style=text-align:center>0.001929</td><td style=text-align:center>0.001925</td><td style=text-align:center>0.001926</td></tr><tr><td style=text-align:center>(64,16)</td><td style=text-align:center>0.002117</td><td style=text-align:center>0.002146</td><td style=text-align:center>0.002113</td><td style=text-align:center>0.002125</td></tr><tr><td style=text-align:center>(64,8)</td><td style=text-align:center>0.001949</td><td style=text-align:center>0.001945</td><td style=text-align:center>0.001945</td><td style=text-align:center>0.001946</td></tr><tr><td style=text-align:center>(128,8)</td><td style=text-align:center>0.002228</td><td style=text-align:center>0.002230</td><td style=text-align:center>0.002229</td><td style=text-align:center>0.002229</td></tr></tbody></table><p>这是简单的实验结果，可见（32，16）的这种模式效率最高</p><p><img loading=lazy src=./4-4-13.png alt=4-4-13></p><h2 id=总结>总结<a hidden class=anchor aria-hidden=true href=#总结>#</a></h2><p>本文主要讲解内存带宽对效率的影响以及如何有效地通过调整读取方式来突破内存存储瓶颈，这是我们优化CUDA程序非常重要的手段</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://go.face2ai.com/tags/%E5%B8%A6%E5%AE%BD/>带宽</a></li><li><a href=https://go.face2ai.com/tags/%E5%90%9E%E5%90%90%E9%87%8F/>吞吐量</a></li><li><a href=https://go.face2ai.com/tags/%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE/>矩阵转置</a></li></ul><nav class=paginav><a class=prev href=https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-4-5-%E4%BD%BF%E7%94%A8%E7%BB%9F%E4%B8%80%E5%86%85%E5%AD%98%E7%9A%84%E5%90%91%E9%87%8F%E5%8A%A0%E6%B3%95.zh/><span class=title>« Prev</span><br><span>【CUDA 基础】4.5 使用统一内存的向量加法</span></a>
<a class=next href=https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-4-3-%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F.zh/><span class=title>Next »</span><br><span>【CUDA 基础】4.3 内存访问模式</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】4.4 核函数可达到的带宽 on twitter" href="https://twitter.com/intent/tweet/?text=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%914.4%20%e6%a0%b8%e5%87%bd%e6%95%b0%e5%8f%af%e8%be%be%e5%88%b0%e7%9a%84%e5%b8%a6%e5%ae%bd&url=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-4-4-%25E6%25A0%25B8%25E5%2587%25BD%25E6%2595%25B0%25E5%258F%25AF%25E8%25BE%25BE%25E5%2588%25B0%25E7%259A%2584%25E5%25B8%25A6%25E5%25AE%25BD.zh%2f&hashtags=%e5%b8%a6%e5%ae%bd%2c%e5%90%9e%e5%90%90%e9%87%8f%2c%e7%9f%a9%e9%98%b5%e8%bd%ac%e7%bd%ae"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】4.4 核函数可达到的带宽 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-4-4-%25E6%25A0%25B8%25E5%2587%25BD%25E6%2595%25B0%25E5%258F%25AF%25E8%25BE%25BE%25E5%2588%25B0%25E7%259A%2584%25E5%25B8%25A6%25E5%25AE%25BD.zh%2f&title=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%914.4%20%e6%a0%b8%e5%87%bd%e6%95%b0%e5%8f%af%e8%be%be%e5%88%b0%e7%9a%84%e5%b8%a6%e5%ae%bd&summary=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%914.4%20%e6%a0%b8%e5%87%bd%e6%95%b0%e5%8f%af%e8%be%be%e5%88%b0%e7%9a%84%e5%b8%a6%e5%ae%bd&source=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-4-4-%25E6%25A0%25B8%25E5%2587%25BD%25E6%2595%25B0%25E5%258F%25AF%25E8%25BE%25BE%25E5%2588%25B0%25E7%259A%2584%25E5%25B8%25A6%25E5%25AE%25BD.zh%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】4.4 核函数可达到的带宽 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-4-4-%25E6%25A0%25B8%25E5%2587%25BD%25E6%2595%25B0%25E5%258F%25AF%25E8%25BE%25BE%25E5%2588%25B0%25E7%259A%2584%25E5%25B8%25A6%25E5%25AE%25BD.zh%2f&title=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%914.4%20%e6%a0%b8%e5%87%bd%e6%95%b0%e5%8f%af%e8%be%be%e5%88%b0%e7%9a%84%e5%b8%a6%e5%ae%bd"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】4.4 核函数可达到的带宽 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-4-4-%25E6%25A0%25B8%25E5%2587%25BD%25E6%2595%25B0%25E5%258F%25AF%25E8%25BE%25BE%25E5%2588%25B0%25E7%259A%2584%25E5%25B8%25A6%25E5%25AE%25BD.zh%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】4.4 核函数可达到的带宽 on whatsapp" href="https://api.whatsapp.com/send?text=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%914.4%20%e6%a0%b8%e5%87%bd%e6%95%b0%e5%8f%af%e8%be%be%e5%88%b0%e7%9a%84%e5%b8%a6%e5%ae%bd%20-%20https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-4-4-%25E6%25A0%25B8%25E5%2587%25BD%25E6%2595%25B0%25E5%258F%25AF%25E8%25BE%25BE%25E5%2588%25B0%25E7%259A%2584%25E5%25B8%25A6%25E5%25AE%25BD.zh%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】4.4 核函数可达到的带宽 on telegram" href="https://telegram.me/share/url?text=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%914.4%20%e6%a0%b8%e5%87%bd%e6%95%b0%e5%8f%af%e8%be%be%e5%88%b0%e7%9a%84%e5%b8%a6%e5%ae%bd&url=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-4-4-%25E6%25A0%25B8%25E5%2587%25BD%25E6%2595%25B0%25E5%258F%25AF%25E8%25BE%25BE%25E5%2588%25B0%25E7%259A%2584%25E5%25B8%25A6%25E5%25AE%25BD.zh%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://go.face2ai.com>谭升的博客</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerHTML="copy";function s(){e.innerHTML="copied!",setTimeout(()=>{e.innerHTML="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>