<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>【CUDA 基础】5.6 线程束洗牌指令 | 谭升的博客</title><meta name=keywords content="线程束洗牌指令"><meta name=description content="Abstract: 本文介绍线程束洗牌指令的用法
Keywords: 线程束洗牌指令"><meta name=author content="谭升"><link rel=canonical href=https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-5-6-%E7%BA%BF%E7%A8%8B%E6%9D%9F%E6%B4%97%E7%89%8C%E6%8C%87%E4%BB%A4.zh/><link crossorigin=anonymous href=../../../assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe+FVUFzPh7U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=../../../assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://go.face2ai.com/logo.png><link rel=icon type=image/png sizes=16x16 href=https://go.face2ai.com/logo.png><link rel=icon type=image/png sizes=32x32 href=https://go.face2ai.com/logo.png><link rel=apple-touch-icon href=https://go.face2ai.com/logo.png><link rel=mask-icon href=https://go.face2ai.com/logo.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-105335860-3","auto"),ga("send","pageview"))</script><meta property="og:title" content="【CUDA 基础】5.6 线程束洗牌指令"><meta property="og:description" content="Abstract: 本文介绍线程束洗牌指令的用法
Keywords: 线程束洗牌指令"><meta property="og:type" content="article"><meta property="og:url" content="https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-5-6-%E7%BA%BF%E7%A8%8B%E6%9D%9F%E6%B4%97%E7%89%8C%E6%8C%87%E4%BB%A4.zh/"><meta property="article:section" content="编程"><meta property="article:published_time" content="2018-06-06T19:53:12+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="【CUDA 基础】5.6 线程束洗牌指令"><meta name=twitter:description content="Abstract: 本文介绍线程束洗牌指令的用法
Keywords: 线程束洗牌指令"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":3,"name":"【CUDA 基础】5.6 线程束洗牌指令","item":"https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-5-6-%E7%BA%BF%E7%A8%8B%E6%9D%9F%E6%B4%97%E7%89%8C%E6%8C%87%E4%BB%A4.zh/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"【CUDA 基础】5.6 线程束洗牌指令","name":"【CUDA 基础】5.6 线程束洗牌指令","description":"Abstract: 本文介绍线程束洗牌指令的用法 Keywords: 线程束洗牌指令\n","keywords":["线程束洗牌指令"],"articleBody":"Abstract: 本文介绍线程束洗牌指令的用法 Keywords: 线程束洗牌指令\n线程束洗牌指令 前面介绍了共享内存，常量内存，只读内存的使用，今天我们来研究一个比较特殊的机制，名字也很特殊，叫做线程束洗牌指令。 支持线程束洗牌指令的设备最低也要3.0以上， 洗牌指令，shuffle instruction作用在线程束内，允许两个线程见相互访问对方的寄存器。这就给线程束内的线程相互交换信息提供了了一种新的渠道，我们知道，核函数内部的变量都在寄存器中，一个线程束可以看做是32个内核并行执行，换句话说这32个核函数中寄存器变量在硬件上其实都是邻居，这样就为相互访问提供了物理基础，线程束内线程相互访问数据不通过共享内存或者全局内存，使得通信效率高很多，线程束洗牌指令传递数据，延迟极低，切不消耗内存 线程束洗牌指令是线程束内线程通讯的极佳方式。 我们先提出一个叫做束内线程的概念，英文名lane，简单的说，就是一个线程束内的索引，所以束内线程的ID在 $【0,31】$ 内，且唯一，唯一是指线程束内唯一，一个线程块可能有很多个束内线程的索引，就像一个网格中有很多相同的threadIdx.x 一样，同时还有一个线程束的ID，可以通过以下方式计算线程在当前线程块内的束内索引，和线程束ID：\nunsigned int LaneID=threadIdx.x%32; unsigned int warpID=threadIdx.x/32; 根据上面的计算公式，一个线程块内的threadIdx.x=1,33,65等对应的laneID都是1\n线程束洗牌指令的不同形式 线程束洗牌指令有两组：一组用于整形变量，另一种用于浮点型变量。一共有四种形式的洗牌指令。 在线程束内交换整形变量，其基本函数如下：\nint __shfl(int var,int srcLane,int width=warpSize); 这个指令必须好好研究一下，因为这里的输入非常之乱，谁乱？var乱，一个int值，这个变量很明显是当前线程中的一个变量，作为输入，其传递的给函数的并不是这个变量存储的值，而是这个变量名，换句话说，当前线程中有var这个变量，比如我们说1号线程的var值是1，那么2号线程中的var值不一定是1，所以，这个__shfl返回的就是var值，哪个线程var值呢？srcLane这个线程的，srcLane并不是当前线程的束内线程，而是结合with计算出来的相对线程位置，比如我想得到3号线程内存的var值，而且width=16，那么就是，0~15的束内线程接收0+3位置处的var值，也就是3号束内线程的var值，16~32的束内线程接收16+3=19位置处的var变量。 这个是非常重要的，虽然有些困难，但是却相当灵活。width的默认参数是32.srcLane我们后面简单的叫他束内线程，注意我们必须心理明白只有width是默认值的时候，他才是真正的束内线程。 图示如下\n接着是另一个指令，其主要特点是从与调用线程相关的线程中复制数据。\nint __shfl_up(int var,unsigned int delta,int with=warpSize); 这个函数的作用是调用线程得到当前束内线程编号减去delta的编号的线程内的var值，with和__shfl中都一样，默认是32，作用效果如下：\n如果是with其他值，我们可以根据前面的讲解，把线程束再分成若干个大小为with的块，进行上图的操作。 最左边两个元素没有前面的delta号线程，所以不做任何操作，保持原值。\n同样下一个指令是上面的反转版本：\nint __shfl_down(int var,unsigned int delta,int with=warpSize); 作用和参数和up一模一样，图示如下：\n最后一个洗牌指令比较夸张，也是很灵活的一个指令\nint __shfl_xor(int var,int laneMask,int with=warpSize); xor是异或操作，这个指令如果学过硬件或者c语言学的比较扎实的人可能知道，这是电路里面最最最最最重要的操作，没有之一，什么是异或？逻辑中我们假设只有0，1两种信号，用 “^”表示异或:\n0^0=0; 1^0=1; 0^1=1; 1^1=0; 二元操作，只要两个不同就会得到真，否则为假 那么我们的__shfl_xor操作就是包含抑或操作在内的洗牌指令，怎么算呢？ 如果我们输入的laneMask是1，其对应的二进制是 $000\\cdots001$ ,当前线程的索引是0~31之间的一个数，那么我们用laneMask与当前线程索引进行抑或操作得到的就是目标线程的编号了，这里laneMask是1，那么我们把1与0~31分别抑或就会得到：\n000001^000000=000001; 000001^000001=000000; 000001^000010=000011; 000001^000011=000010; 000001^000100=000101; 000001^000101=000100; . . . 000001^011110=011111; 000001^011111=011110; 这就是当前线程的束内线程编号和目标线程束内县城编号之间的对应关系，画成图会非常犀利：\n这就是4个线程束洗牌指令对整形的操作了。对应的浮点型不需要该函数名，而是只要把var改成float就行了，函数就会自动重载了。\n线程束内的共享内存数据 接下来我们用代码实现以下，看看每一个指令的作用效果，洗牌指令可以用于下面三种整数变量类型中：\n 标量变量 数组 向量型变量  跨线程束值的广播 这个就是 __shfl函数作用结果了，代码如下\n__global__ void test_shfl_broadcast(int *in,int*out,int const srcLans) { int value=in[threadIdx.x]; value=__shfl(value,srcLans,BDIM); out[threadIdx.x]=value; } 这里面的过程就不用说了，注意var参数对应value就是我们要找的目标，srcLane这里是2，所以，我们取得了2号书内线程的value值给了当前线程，于是所有束内线程的value都是2了： 计算结果：\n线程束内上移 这里使用__shfl_up指令进行上移。代码如下\n__global__ void test_shfl_up(int *in,int*out,int const delta) { int value=in[threadIdx.x]; value=__shfl_up(value,delta,BDIM); out[threadIdx.x]=value; } 运行结果：\n线程束内下移 这里使用__shfl_down指令进行上移。代码如下\n__global__ void test_shfl_down(int *in,int*out,int const delta) { int value=in[threadIdx.x]; value=__shfl_down(value,delta,BDIM); out[threadIdx.x]=value; } 运行结果：\n线程束内环绕移动 然后是循环移动，我们修改__shfl中的参数，把静态的目标改成一个动态的目标，如下：\n__global__ void test_shfl_wrap(int *in,int*out,int const offset) { int value=in[threadIdx.x]; value=__shfl(value,threadIdx.x+offset,BDIM); out[threadIdx.x]=value; } 当offset=2的时候，得到结果：\n前14个元素的值是可以预料到的，但是14号，15号并没有像__shfl_down那样保持不变，而是获得了0号和1号的值，那么我们有必要相信，__shfl中计算目标线程编号的那步有取余操作，对with取余，我们真正得到的数据来自\nsrcLane=srcLane%width; 这样就说的过去了，同理我们通过将srclane设置成-2的话就能得到对应的向上的环绕移动。\n跨线程束的蝴蝶交换 接着我们看看__shfl_xor像我说的这个操作非常之灵活，可以组合出任何你想要的到的变换，我们先来个简单的就是我们上面讲原理的时候得到的结论：\n__global__ void test_shfl_xor(int *in,int*out,int const mask) { int value=in[threadIdx.x]; value=__shfl_xor(value,mask,BDIM); out[threadIdx.x]=value; } mask我们设置成1，然后就能得到下面的结果：\n忍不住画了个叉，哈哈 这些都是预料之中的，接着我们看点高级的。也解释下为什么说可以操作数组，好吧我之前也蒙了。\n跨线程束交换数组值 我们要交换数组了，假如线程内有数组，然后我们交换数组的位置，我们可以用下面代码实现一个简单小数组的例子：\n__global__ void test_shfl_xor_array(int *in,int*out,int const mask) { //1.  int idx=threadIdx.x*SEGM; //2.  int value[SEGM]; for(int i=0;iSEGM;i++) value[i]=in[idx+i]; //3.  value[0]=__shfl_xor(value[0],mask,BDIM); value[1]=__shfl_xor(value[1],mask,BDIM); value[2]=__shfl_xor(value[2],mask,BDIM); value[3]=__shfl_xor(value[3],mask,BDIM); //4.  for(int i=0;iSEGM;i++) out[idx+i]=value[i]; } 有逻辑的地方代码就会变得复杂，我们从头看，首先我们定义了一个宏SEGM为4，然后每个线程束包含一个SEGM大小的数组，当然，这些数据数存在寄存器中的，如果数组过大可能会溢出到本地内存中，不用担心，也在片上，这个数组比较小，寄存器足够了。 我们看每一步都做了什么\n 计算数组的起始地址，因为我们的输入数据是一维的，每个线程包含其中长度为SEGM的一段数据，所以，这个操作就是计算出当前线程对应的数组的起始位置 声明数组，在寄存器中开辟地址，这句编译时就会给他们分配地址，然后从全局内存中读数据。 计算当前线程中数组中的元素，与要交换的目标的线程的之间的抑或，此时mask为1，那么就相当于将多个寄存器变量进行跨线程束的蝴蝶交换 将寄存器内的交换结果写会到全局内存  这个看起来有点复杂，但是其实就是把上面的蝴蝶交换重复执行。\n大蝴蝶~ 跨线程束不是跨越线程束，而是横跨当前线程束的意思，这个标题有点让人迷惑。\n跨线程束使用数组索引交换数值 接下来这个是个扩展了，交换了两个之间的一对值，并且这里是我们第一次写设备函数，也就是只能被核函数调用的函数：\n__inline__ __device__ void swap(int *value,int laneIdx,int mask,int firstIdx,int secondIdx) { bool pred=((laneIdx%(2))==0); if(pred) { int tmp=value[firstIdx]; value[firstIdx]=value[secondIdx]; value[secondIdx]=tmp; } value[secondIdx]=__shfl_xor(value[secondIdx],mask,BDIM); if(pred) { int tmp=value[firstIdx]; value[firstIdx]=value[secondIdx]; value[secondIdx]=tmp; } } __global__ void test_shfl_swap(int *in,int* out,int const mask,int firstIdx,int secondIdx) { //1.  int idx=threadIdx.x*SEGM; int value[SEGM]; for(int i=0;iSEGM;i++) value[i]=in[idx+i]; //2.  swap(value,threadIdx.x,mask,firstIdx,secondIdx); //3.  for(int i=0;iSEGM;i++) out[idx+i]=value[i]; } 这个过程有点复杂，这里面每一句指令的意思都很明确，而且与上面数组交换类似\n 和上面数组交换类似，不赘述 交换数组内的first和second，然后xor在second位置的元素，然后再次重新交换first和second的元素 写入全局变量。  2的描述看起来简单，但是实际上比较麻烦，我们画个图来表示：\n对照代码每一步变换的过程都画了绿线，所以看起来还是好理解的，运行结果：\n使用线程束洗牌指令的并行规约 前面我们已经很详细的介绍过归约算法了，从线程块之间到线程间的归约我们都进行了研究，包括使用共享内存以及各种展开方式，今天我们使用线程束洗牌指令完成归约，主要目标就是减少线程间数据传递的延迟，达到更快的效率： 我们主要考虑三个层面的归约：\n 线程束级归约 线程块级归约 网格级归约  一个线程块有过个线程束，每个执行自己的归约，每个线程束不适用共享内存，而是使用线程束洗牌指令，代码如下：\n__inline__ __device__ int warpReduce(int localSum) { localSum += __shfl_xor(localSum, 16); localSum += __shfl_xor(localSum, 8); localSum += __shfl_xor(localSum, 4); localSum += __shfl_xor(localSum, 2); localSum += __shfl_xor(localSum, 1); return localSum; } __global__ void reduceShfl(int * g_idata,int * g_odata,unsigned int n) { //set thread ID  __shared__ int smem[DIM]; unsigned int idx = blockDim.x*blockIdx.x+threadIdx.x; //convert global data pointer to the  //1. \tint mySum=g_idata[idx]; int laneIdx=threadIdx.x%warpSize; int warpIdx=threadIdx.x/warpSize; //2. \tmySum=warpReduce(mySum); //3. \tif(laneIdx==0) smem[warpIdx]=mySum; __syncthreads(); //4. \tmySum=(threadIdx.xDIM)?smem[laneIdx]:0; if(warpIdx==0) mySum=warpReduce(mySum); //5.  if(threadIdx.x==0) g_odata[blockIdx.x]=mySum; } 代码解释:\n 从全局内存读取数据，计算线程束ID和当前线程的束内线程ID 计算当前线程束内的归约结果，使用的xor，这里需要动手计算下每个线程和这些2的幂次计算的结果因为每个线程束只有32个线程，所以二进制最高位就是16，那么xor 16 是计算0+16，1+17，2+18，这些位置的和,计算完成后前16位是结果，16到31是一样结果，重复了一边，同理xor 8是计算0+8，1+9，2+10,…,前8位结果有效，后面是复制前面的答案，最后就得到当前线程束的归约结果。 然后把线程束结果存储到共享内存中 然后继续2中的过程计算3中得到的数据，完整的重复 5.将最后结果存入全局内存  其他几个核函数前面文章都介绍过，我们通过实践可以看出使用线程束洗牌指令进行的归约效率最高。主要原因是使用寄存器进行数据交换而不需要任何位置的内存介入。 本文完整的代码在github:https://github.com/Tony-Tan/CUDA_Freshman（欢迎随手star😝 ）\n总结 本文介绍线程束洗牌指令的一些用法，其吸引人的地方就是不需要通过内存进行线程间数据交换，具有非常高的性能。 至此我们已经完成了第五章的学习，后面我们进入流和事件相关知识的学习。\n","wordCount":"364","inLanguage":"en","datePublished":"2018-06-06T19:53:12Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"谭升"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-5-6-%E7%BA%BF%E7%A8%8B%E6%9D%9F%E6%B4%97%E7%89%8C%E6%8C%87%E4%BB%A4.zh/"},"publisher":{"@type":"Organization","name":"谭升的博客","logo":{"@type":"ImageObject","url":"https://go.face2ai.com/logo.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://go.face2ai.com accesskey=h title="谭升的博客 (Alt + H)">谭升的博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://go.face2ai.com/math/ title=数学><span>数学</span></a></li><li><a href=https://go.face2ai.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://go.face2ai.com/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://go.face2ai.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://go.face2ai.com/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://go.face2ai.com>Home</a></div><h1 class=post-title>【CUDA 基础】5.6 线程束洗牌指令</h1><div class=post-meta><span title="2018-06-06 19:53:12 +0000 UTC">June 6, 2018</span>&nbsp;·&nbsp;谭升</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e7%ba%bf%e7%a8%8b%e6%9d%9f%e6%b4%97%e7%89%8c%e6%8c%87%e4%bb%a4 aria-label=线程束洗牌指令>线程束洗牌指令</a><ul><li><a href=#%e7%ba%bf%e7%a8%8b%e6%9d%9f%e6%b4%97%e7%89%8c%e6%8c%87%e4%bb%a4%e7%9a%84%e4%b8%8d%e5%90%8c%e5%bd%a2%e5%bc%8f aria-label=线程束洗牌指令的不同形式>线程束洗牌指令的不同形式</a></li><li><a href=#%e7%ba%bf%e7%a8%8b%e6%9d%9f%e5%86%85%e7%9a%84%e5%85%b1%e4%ba%ab%e5%86%85%e5%ad%98%e6%95%b0%e6%8d%ae aria-label=线程束内的共享内存数据>线程束内的共享内存数据</a><ul><li><a href=#%e8%b7%a8%e7%ba%bf%e7%a8%8b%e6%9d%9f%e5%80%bc%e7%9a%84%e5%b9%bf%e6%92%ad aria-label=跨线程束值的广播>跨线程束值的广播</a></li><li><a href=#%e7%ba%bf%e7%a8%8b%e6%9d%9f%e5%86%85%e4%b8%8a%e7%a7%bb aria-label=线程束内上移>线程束内上移</a></li><li><a href=#%e7%ba%bf%e7%a8%8b%e6%9d%9f%e5%86%85%e4%b8%8b%e7%a7%bb aria-label=线程束内下移>线程束内下移</a></li><li><a href=#%e7%ba%bf%e7%a8%8b%e6%9d%9f%e5%86%85%e7%8e%af%e7%bb%95%e7%a7%bb%e5%8a%a8 aria-label=线程束内环绕移动>线程束内环绕移动</a></li><li><a href=#%e8%b7%a8%e7%ba%bf%e7%a8%8b%e6%9d%9f%e7%9a%84%e8%9d%b4%e8%9d%b6%e4%ba%a4%e6%8d%a2 aria-label=跨线程束的蝴蝶交换>跨线程束的蝴蝶交换</a></li><li><a href=#%e8%b7%a8%e7%ba%bf%e7%a8%8b%e6%9d%9f%e4%ba%a4%e6%8d%a2%e6%95%b0%e7%bb%84%e5%80%bc aria-label=跨线程束交换数组值>跨线程束交换数组值</a></li><li><a href=#%e8%b7%a8%e7%ba%bf%e7%a8%8b%e6%9d%9f%e4%bd%bf%e7%94%a8%e6%95%b0%e7%bb%84%e7%b4%a2%e5%bc%95%e4%ba%a4%e6%8d%a2%e6%95%b0%e5%80%bc aria-label=跨线程束使用数组索引交换数值>跨线程束使用数组索引交换数值</a></li></ul></li><li><a href=#%e4%bd%bf%e7%94%a8%e7%ba%bf%e7%a8%8b%e6%9d%9f%e6%b4%97%e7%89%8c%e6%8c%87%e4%bb%a4%e7%9a%84%e5%b9%b6%e8%a1%8c%e8%a7%84%e7%ba%a6 aria-label=使用线程束洗牌指令的并行规约>使用线程束洗牌指令的并行规约</a></li><li><a href=#%e6%80%bb%e7%bb%93 aria-label=总结>总结</a></li></ul></li></ul></div></details></div><div class=post-content><p><strong>Abstract:</strong> 本文介绍线程束洗牌指令的用法
<strong>Keywords:</strong> 线程束洗牌指令</p><h1 id=线程束洗牌指令>线程束洗牌指令<a hidden class=anchor aria-hidden=true href=#线程束洗牌指令>#</a></h1><p>前面介绍了共享内存，常量内存，只读内存的使用，今天我们来研究一个比较特殊的机制，名字也很特殊，叫做线程束洗牌指令。
支持线程束洗牌指令的设备最低也要3.0以上，
洗牌指令，shuffle instruction作用在线程束内，允许两个线程见相互访问对方的寄存器。这就给线程束内的线程相互交换信息提供了了一种新的渠道，我们知道，核函数内部的变量都在寄存器中，一个线程束可以看做是32个内核并行执行，换句话说这32个核函数中寄存器变量在硬件上其实都是邻居，这样就为相互访问提供了物理基础，线程束内线程相互访问数据不通过共享内存或者全局内存，使得通信效率高很多，线程束洗牌指令传递数据，延迟极低，切不消耗内存
线程束洗牌指令是线程束内线程通讯的极佳方式。
我们先提出一个叫做束内线程的概念，英文名lane，简单的说，就是一个线程束内的索引，所以束内线程的ID在 $【0,31】$ 内，且唯一，唯一是指线程束内唯一，一个线程块可能有很多个束内线程的索引，就像一个网格中有很多相同的threadIdx.x 一样，同时还有一个线程束的ID，可以通过以下方式计算线程在当前线程块内的束内索引，和线程束ID：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>unsigned</span> <span class=kt>int</span> <span class=n>LaneID</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>%</span><span class=mi>32</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=kt>unsigned</span> <span class=kt>int</span> <span class=n>warpID</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>/</span><span class=mi>32</span><span class=p>;</span>
</span></span></code></pre></div><p>根据上面的计算公式，一个线程块内的threadIdx.x=1,33,65等对应的laneID都是1</p><h2 id=线程束洗牌指令的不同形式>线程束洗牌指令的不同形式<a hidden class=anchor aria-hidden=true href=#线程束洗牌指令的不同形式>#</a></h2><p>线程束洗牌指令有两组：一组用于整形变量，另一种用于浮点型变量。一共有四种形式的洗牌指令。
在线程束内交换整形变量，其基本函数如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>int</span> <span class=nf>__shfl</span><span class=p>(</span><span class=kt>int</span> <span class=n>var</span><span class=p>,</span><span class=kt>int</span> <span class=n>srcLane</span><span class=p>,</span><span class=kt>int</span> <span class=n>width</span><span class=o>=</span><span class=n>warpSize</span><span class=p>);</span>
</span></span></code></pre></div><p>这个指令必须好好研究一下，因为这里的输入非常之乱，谁乱？var乱，一个int值，这个变量很明显是当前线程中的一个变量，作为输入，其传递的给函数的并不是这个变量存储的值，而是这个变量名，换句话说，当前线程中有var这个变量，比如我们说1号线程的var值是1，那么2号线程中的var值不一定是1，所以，这个__shfl返回的就是var值，哪个线程var值呢？srcLane这个线程的，srcLane并不是当前线程的束内线程，而是结合with计算出来的相对线程位置，比如我想得到3号线程内存的var值，而且width=16，那么就是，0~15的束内线程接收0+3位置处的var值，也就是3号束内线程的var值，16~32的束内线程接收16+3=19位置处的var变量。
这个是非常重要的，虽然有些困难，但是却相当灵活。width的默认参数是32.srcLane我们后面简单的叫他束内线程，注意我们必须心理明白只有width是默认值的时候，他才是真正的束内线程。
图示如下</p><p><img loading=lazy src=./1-1.png alt=1-1></p><p>接着是另一个指令，其主要特点是从与调用线程相关的线程中复制数据。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>int</span> <span class=nf>__shfl_up</span><span class=p>(</span><span class=kt>int</span> <span class=n>var</span><span class=p>,</span><span class=kt>unsigned</span> <span class=kt>int</span> <span class=n>delta</span><span class=p>,</span><span class=kt>int</span> <span class=n>with</span><span class=o>=</span><span class=n>warpSize</span><span class=p>);</span>
</span></span></code></pre></div><p>这个函数的作用是调用线程得到当前束内线程编号减去delta的编号的线程内的var值，with和__shfl中都一样，默认是32，作用效果如下：</p><p><img loading=lazy src=./1-2.png alt=1-2></p><p>如果是with其他值，我们可以根据前面的讲解，把线程束再分成若干个大小为with的块，进行上图的操作。
最左边两个元素没有前面的delta号线程，所以不做任何操作，保持原值。</p><p>同样下一个指令是上面的反转版本：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>int</span> <span class=nf>__shfl_down</span><span class=p>(</span><span class=kt>int</span> <span class=n>var</span><span class=p>,</span><span class=kt>unsigned</span> <span class=kt>int</span> <span class=n>delta</span><span class=p>,</span><span class=kt>int</span> <span class=n>with</span><span class=o>=</span><span class=n>warpSize</span><span class=p>);</span>
</span></span></code></pre></div><p>作用和参数和up一模一样，图示如下：</p><p><img loading=lazy src=./1-3.png alt=1-3></p><p>最后一个洗牌指令比较夸张，也是很灵活的一个指令</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>int</span> <span class=nf>__shfl_xor</span><span class=p>(</span><span class=kt>int</span> <span class=n>var</span><span class=p>,</span><span class=kt>int</span> <span class=n>laneMask</span><span class=p>,</span><span class=kt>int</span> <span class=n>with</span><span class=o>=</span><span class=n>warpSize</span><span class=p>);</span>
</span></span></code></pre></div><p>xor是异或操作，这个指令如果学过硬件或者c语言学的比较扎实的人可能知道，这是电路里面最最最最最重要的操作，没有之一，什么是异或？逻辑中我们假设只有0，1两种信号，用 “^”表示异或:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=mi>0</span><span class=o>^</span><span class=mi>0</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=mi>1</span><span class=o>^</span><span class=mi>0</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=mi>0</span><span class=o>^</span><span class=mi>1</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=mi>1</span><span class=o>^</span><span class=mi>1</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span>
</span></span></code></pre></div><p>二元操作，只要两个不同就会得到真，否则为假
那么我们的__shfl_xor操作就是包含抑或操作在内的洗牌指令，怎么算呢？
如果我们输入的laneMask是1，其对应的二进制是 $000\cdots001$ ,当前线程的索引是0~31之间的一个数，那么我们用laneMask与当前线程索引进行抑或操作得到的就是目标线程的编号了，这里laneMask是1，那么我们把1与0~31分别抑或就会得到：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=mo>000001</span><span class=o>^</span><span class=mo>000000</span><span class=o>=</span><span class=mo>000001</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=mo>000001</span><span class=o>^</span><span class=mo>000001</span><span class=o>=</span><span class=mo>000000</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=mo>000001</span><span class=o>^</span><span class=mo>000010</span><span class=o>=</span><span class=mo>000011</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=mo>000001</span><span class=o>^</span><span class=mo>000011</span><span class=o>=</span><span class=mo>000010</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=mo>000001</span><span class=o>^</span><span class=mo>000100</span><span class=o>=</span><span class=mo>000101</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=mo>000001</span><span class=o>^</span><span class=mo>000101</span><span class=o>=</span><span class=mo>000100</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>.</span>
</span></span><span class=line><span class=cl><span class=p>.</span>
</span></span><span class=line><span class=cl><span class=p>.</span>
</span></span><span class=line><span class=cl><span class=mo>000001</span><span class=o>^</span><span class=mo>011110</span><span class=o>=</span><span class=mo>011111</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=mo>000001</span><span class=o>^</span><span class=mo>011111</span><span class=o>=</span><span class=mo>011110</span><span class=p>;</span>
</span></span></code></pre></div><p>这就是当前线程的束内线程编号和目标线程束内县城编号之间的对应关系，画成图会非常犀利：</p><p><img loading=lazy src=./1-4.png alt=1-4></p><p>这就是4个线程束洗牌指令对整形的操作了。对应的浮点型不需要该函数名，而是只要把var改成float就行了，函数就会自动重载了。</p><h2 id=线程束内的共享内存数据>线程束内的共享内存数据<a hidden class=anchor aria-hidden=true href=#线程束内的共享内存数据>#</a></h2><p>接下来我们用代码实现以下，看看每一个指令的作用效果，洗牌指令可以用于下面三种整数变量类型中：</p><ul><li>标量变量</li><li>数组</li><li>向量型变量</li></ul><h3 id=跨线程束值的广播>跨线程束值的广播<a hidden class=anchor aria-hidden=true href=#跨线程束值的广播>#</a></h3><p>这个就是 __shfl函数作用结果了，代码如下</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>test_shfl_broadcast</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>in</span><span class=p>,</span><span class=kt>int</span><span class=o>*</span><span class=n>out</span><span class=p>,</span><span class=kt>int</span> <span class=k>const</span> <span class=n>srcLans</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>value</span><span class=o>=</span><span class=n>in</span><span class=p>[</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=n>value</span><span class=o>=</span><span class=n>__shfl</span><span class=p>(</span><span class=n>value</span><span class=p>,</span><span class=n>srcLans</span><span class=p>,</span><span class=n>BDIM</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>out</span><span class=p>[</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>=</span><span class=n>value</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>这里面的过程就不用说了，注意var参数对应value就是我们要找的目标，srcLane这里是2，所以，我们取得了2号书内线程的value值给了当前线程，于是所有束内线程的value都是2了：
计算结果：</p><p><img loading=lazy src=./re-1.png alt=re-1></p><h3 id=线程束内上移>线程束内上移<a hidden class=anchor aria-hidden=true href=#线程束内上移>#</a></h3><p>这里使用__shfl_up指令进行上移。代码如下</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>test_shfl_up</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>in</span><span class=p>,</span><span class=kt>int</span><span class=o>*</span><span class=n>out</span><span class=p>,</span><span class=kt>int</span> <span class=k>const</span> <span class=n>delta</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>value</span><span class=o>=</span><span class=n>in</span><span class=p>[</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=n>value</span><span class=o>=</span><span class=n>__shfl_up</span><span class=p>(</span><span class=n>value</span><span class=p>,</span><span class=n>delta</span><span class=p>,</span><span class=n>BDIM</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>out</span><span class=p>[</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>=</span><span class=n>value</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>运行结果：</p><p><img loading=lazy src=./re-2.png alt=re-2></p><h3 id=线程束内下移>线程束内下移<a hidden class=anchor aria-hidden=true href=#线程束内下移>#</a></h3><p>这里使用__shfl_down指令进行上移。代码如下</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>test_shfl_down</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>in</span><span class=p>,</span><span class=kt>int</span><span class=o>*</span><span class=n>out</span><span class=p>,</span><span class=kt>int</span> <span class=k>const</span> <span class=n>delta</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>value</span><span class=o>=</span><span class=n>in</span><span class=p>[</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=n>value</span><span class=o>=</span><span class=n>__shfl_down</span><span class=p>(</span><span class=n>value</span><span class=p>,</span><span class=n>delta</span><span class=p>,</span><span class=n>BDIM</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>out</span><span class=p>[</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>=</span><span class=n>value</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>运行结果：</p><p><img loading=lazy src=./re-3.png alt=re-3></p><h3 id=线程束内环绕移动>线程束内环绕移动<a hidden class=anchor aria-hidden=true href=#线程束内环绕移动>#</a></h3><p>然后是循环移动，我们修改__shfl中的参数，把静态的目标改成一个动态的目标，如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>test_shfl_wrap</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>in</span><span class=p>,</span><span class=kt>int</span><span class=o>*</span><span class=n>out</span><span class=p>,</span><span class=kt>int</span> <span class=k>const</span> <span class=n>offset</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>value</span><span class=o>=</span><span class=n>in</span><span class=p>[</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=n>value</span><span class=o>=</span><span class=n>__shfl</span><span class=p>(</span><span class=n>value</span><span class=p>,</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=n>offset</span><span class=p>,</span><span class=n>BDIM</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>out</span><span class=p>[</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>=</span><span class=n>value</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>当offset=2的时候，得到结果：</p><p><img loading=lazy src=./re-4.png alt=re-4></p><p>前14个元素的值是可以预料到的，但是14号，15号并没有像__shfl_down那样保持不变，而是获得了0号和1号的值，那么我们有必要相信，__shfl中计算目标线程编号的那步有取余操作，对with取余，我们真正得到的数据来自</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>srcLane</span><span class=o>=</span><span class=n>srcLane</span><span class=o>%</span><span class=n>width</span><span class=p>;</span>
</span></span></code></pre></div><p>这样就说的过去了，同理我们通过将srclane设置成-2的话就能得到对应的向上的环绕移动。</p><h3 id=跨线程束的蝴蝶交换>跨线程束的蝴蝶交换<a hidden class=anchor aria-hidden=true href=#跨线程束的蝴蝶交换>#</a></h3><p>接着我们看看__shfl_xor像我说的这个操作非常之灵活，可以组合出任何你想要的到的变换，我们先来个简单的就是我们上面讲原理的时候得到的结论：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>test_shfl_xor</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>in</span><span class=p>,</span><span class=kt>int</span><span class=o>*</span><span class=n>out</span><span class=p>,</span><span class=kt>int</span> <span class=k>const</span> <span class=n>mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>value</span><span class=o>=</span><span class=n>in</span><span class=p>[</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=n>value</span><span class=o>=</span><span class=n>__shfl_xor</span><span class=p>(</span><span class=n>value</span><span class=p>,</span><span class=n>mask</span><span class=p>,</span><span class=n>BDIM</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>out</span><span class=p>[</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>=</span><span class=n>value</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>mask我们设置成1，然后就能得到下面的结果：</p><p><img loading=lazy src=./re-5.png alt=re-5></p><p>忍不住画了个叉，哈哈
这些都是预料之中的，接着我们看点高级的。也解释下为什么说可以操作数组，好吧我之前也蒙了。</p><h3 id=跨线程束交换数组值>跨线程束交换数组值<a hidden class=anchor aria-hidden=true href=#跨线程束交换数组值>#</a></h3><p>我们要交换数组了，假如线程内有数组，然后我们交换数组的位置，我们可以用下面代码实现一个简单小数组的例子：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>test_shfl_xor_array</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>in</span><span class=p>,</span><span class=kt>int</span><span class=o>*</span><span class=n>out</span><span class=p>,</span><span class=kt>int</span> <span class=k>const</span> <span class=n>mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>//1.
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=n>idx</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>SEGM</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=c1>//2.
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=n>value</span><span class=p>[</span><span class=n>SEGM</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;</span><span class=n>SEGM</span><span class=p>;</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>value</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>=</span><span class=n>in</span><span class=p>[</span><span class=n>idx</span><span class=o>+</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=c1>//3.
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>value</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>=</span><span class=n>__shfl_xor</span><span class=p>(</span><span class=n>value</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span><span class=n>mask</span><span class=p>,</span><span class=n>BDIM</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>value</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>=</span><span class=n>__shfl_xor</span><span class=p>(</span><span class=n>value</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span><span class=n>mask</span><span class=p>,</span><span class=n>BDIM</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>value</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span><span class=o>=</span><span class=n>__shfl_xor</span><span class=p>(</span><span class=n>value</span><span class=p>[</span><span class=mi>2</span><span class=p>],</span><span class=n>mask</span><span class=p>,</span><span class=n>BDIM</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>value</span><span class=p>[</span><span class=mi>3</span><span class=p>]</span><span class=o>=</span><span class=n>__shfl_xor</span><span class=p>(</span><span class=n>value</span><span class=p>[</span><span class=mi>3</span><span class=p>],</span><span class=n>mask</span><span class=p>,</span><span class=n>BDIM</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=c1>//4.
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;</span><span class=n>SEGM</span><span class=p>;</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span><span class=p>[</span><span class=n>idx</span><span class=o>+</span><span class=n>i</span><span class=p>]</span><span class=o>=</span><span class=n>value</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>有逻辑的地方代码就会变得复杂，我们从头看，首先我们定义了一个宏SEGM为4，然后每个线程束包含一个SEGM大小的数组，当然，这些数据数存在寄存器中的，如果数组过大可能会溢出到本地内存中，不用担心，也在片上，这个数组比较小，寄存器足够了。
我们看每一步都做了什么</p><ol><li>计算数组的起始地址，因为我们的输入数据是一维的，每个线程包含其中长度为SEGM的一段数据，所以，这个操作就是计算出当前线程对应的数组的起始位置</li><li>声明数组，在寄存器中开辟地址，这句编译时就会给他们分配地址，然后从全局内存中读数据。</li><li>计算当前线程中数组中的元素，与要交换的目标的线程的之间的抑或，此时mask为1，那么就相当于将多个寄存器变量进行跨线程束的蝴蝶交换</li><li>将寄存器内的交换结果写会到全局内存</li></ol><p>这个看起来有点复杂，但是其实就是把上面的蝴蝶交换重复执行。</p><p><img loading=lazy src=./re-6.png alt=re-6></p><p>大蝴蝶~
跨线程束不是跨越线程束，而是横跨当前线程束的意思，这个标题有点让人迷惑。</p><h3 id=跨线程束使用数组索引交换数值>跨线程束使用数组索引交换数值<a hidden class=anchor aria-hidden=true href=#跨线程束使用数组索引交换数值>#</a></h3><p>接下来这个是个扩展了，交换了两个之间的一对值，并且这里是我们第一次写设备函数，也就是只能被核函数调用的函数：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>__inline__</span> <span class=n>__device__</span>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>swap</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>value</span><span class=p>,</span><span class=kt>int</span> <span class=n>laneIdx</span><span class=p>,</span><span class=kt>int</span> <span class=n>mask</span><span class=p>,</span><span class=kt>int</span> <span class=n>firstIdx</span><span class=p>,</span><span class=kt>int</span> <span class=n>secondIdx</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>bool</span> <span class=n>pred</span><span class=o>=</span><span class=p>((</span><span class=n>laneIdx</span><span class=o>%</span><span class=p>(</span><span class=mi>2</span><span class=p>))</span><span class=o>==</span><span class=mi>0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=kt>int</span> <span class=n>tmp</span><span class=o>=</span><span class=n>value</span><span class=p>[</span><span class=n>firstIdx</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=n>value</span><span class=p>[</span><span class=n>firstIdx</span><span class=p>]</span><span class=o>=</span><span class=n>value</span><span class=p>[</span><span class=n>secondIdx</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=n>value</span><span class=p>[</span><span class=n>secondIdx</span><span class=p>]</span><span class=o>=</span><span class=n>tmp</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>value</span><span class=p>[</span><span class=n>secondIdx</span><span class=p>]</span><span class=o>=</span><span class=n>__shfl_xor</span><span class=p>(</span><span class=n>value</span><span class=p>[</span><span class=n>secondIdx</span><span class=p>],</span><span class=n>mask</span><span class=p>,</span><span class=n>BDIM</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=kt>int</span> <span class=n>tmp</span><span class=o>=</span><span class=n>value</span><span class=p>[</span><span class=n>firstIdx</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=n>value</span><span class=p>[</span><span class=n>firstIdx</span><span class=p>]</span><span class=o>=</span><span class=n>value</span><span class=p>[</span><span class=n>secondIdx</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=n>value</span><span class=p>[</span><span class=n>secondIdx</span><span class=p>]</span><span class=o>=</span><span class=n>tmp</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>test_shfl_swap</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>in</span><span class=p>,</span><span class=kt>int</span><span class=o>*</span> <span class=n>out</span><span class=p>,</span><span class=kt>int</span> <span class=k>const</span> <span class=n>mask</span><span class=p>,</span><span class=kt>int</span> <span class=n>firstIdx</span><span class=p>,</span><span class=kt>int</span> <span class=n>secondIdx</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>//1.
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=n>idx</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>SEGM</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>value</span><span class=p>[</span><span class=n>SEGM</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;</span><span class=n>SEGM</span><span class=p>;</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>value</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>=</span><span class=n>in</span><span class=p>[</span><span class=n>idx</span><span class=o>+</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=c1>//2.
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>swap</span><span class=p>(</span><span class=n>value</span><span class=p>,</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>,</span><span class=n>mask</span><span class=p>,</span><span class=n>firstIdx</span><span class=p>,</span><span class=n>secondIdx</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=c1>//3.
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;</span><span class=n>SEGM</span><span class=p>;</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span><span class=p>[</span><span class=n>idx</span><span class=o>+</span><span class=n>i</span><span class=p>]</span><span class=o>=</span><span class=n>value</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>这个过程有点复杂，这里面每一句指令的意思都很明确，而且与上面数组交换类似</p><ol><li>和上面数组交换类似，不赘述</li><li>交换数组内的first和second，然后xor在second位置的元素，然后再次重新交换first和second的元素</li><li>写入全局变量。</li></ol><p>2的描述看起来简单，但是实际上比较麻烦，我们画个图来表示：</p><p><img loading=lazy src=./1-5.png alt>
对照代码每一步变换的过程都画了绿线，所以看起来还是好理解的，运行结果：</p><p><img loading=lazy src=./re-6.png alt=re-6></p><h2 id=使用线程束洗牌指令的并行规约>使用线程束洗牌指令的并行规约<a hidden class=anchor aria-hidden=true href=#使用线程束洗牌指令的并行规约>#</a></h2><p>前面我们已经很详细的介绍过归约算法了，从线程块之间到线程间的归约我们都进行了研究，包括使用共享内存以及各种展开方式，今天我们使用线程束洗牌指令完成归约，主要目标就是减少线程间数据传递的延迟，达到更快的效率：
我们主要考虑三个层面的归约：</p><ul><li>线程束级归约</li><li>线程块级归约</li><li>网格级归约</li></ul><p>一个线程块有过个线程束，每个执行自己的归约，每个线程束不适用共享内存，而是使用线程束洗牌指令，代码如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>__inline__</span> <span class=n>__device__</span> <span class=kt>int</span> <span class=nf>warpReduce</span><span class=p>(</span><span class=kt>int</span> <span class=n>localSum</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>localSum</span> <span class=o>+=</span> <span class=n>__shfl_xor</span><span class=p>(</span><span class=n>localSum</span><span class=p>,</span> <span class=mi>16</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>localSum</span> <span class=o>+=</span> <span class=n>__shfl_xor</span><span class=p>(</span><span class=n>localSum</span><span class=p>,</span> <span class=mi>8</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>localSum</span> <span class=o>+=</span> <span class=n>__shfl_xor</span><span class=p>(</span><span class=n>localSum</span><span class=p>,</span> <span class=mi>4</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>localSum</span> <span class=o>+=</span> <span class=n>__shfl_xor</span><span class=p>(</span><span class=n>localSum</span><span class=p>,</span> <span class=mi>2</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>localSum</span> <span class=o>+=</span> <span class=n>__shfl_xor</span><span class=p>(</span><span class=n>localSum</span><span class=p>,</span> <span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>localSum</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>reduceShfl</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span> <span class=n>g_idata</span><span class=p>,</span><span class=kt>int</span> <span class=o>*</span> <span class=n>g_odata</span><span class=p>,</span><span class=kt>unsigned</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=c1>//set thread ID
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>__shared__</span> <span class=kt>int</span> <span class=n>smem</span><span class=p>[</span><span class=n>DIM</span><span class=p>];</span>
</span></span><span class=line><span class=cl>	<span class=kt>unsigned</span> <span class=kt>int</span> <span class=n>idx</span> <span class=o>=</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=c1>//convert global data pointer to the
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=c1>//1.
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=kt>int</span> <span class=n>mySum</span><span class=o>=</span><span class=n>g_idata</span><span class=p>[</span><span class=n>idx</span><span class=p>];</span>
</span></span><span class=line><span class=cl>	<span class=kt>int</span> <span class=n>laneIdx</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>%</span><span class=n>warpSize</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=kt>int</span> <span class=n>warpIdx</span><span class=o>=</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>/</span><span class=n>warpSize</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=c1>//2.
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=n>mySum</span><span class=o>=</span><span class=n>warpReduce</span><span class=p>(</span><span class=n>mySum</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=c1>//3.
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=k>if</span><span class=p>(</span><span class=n>laneIdx</span><span class=o>==</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>smem</span><span class=p>[</span><span class=n>warpIdx</span><span class=p>]</span><span class=o>=</span><span class=n>mySum</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=n>__syncthreads</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=c1>//4.
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=n>mySum</span><span class=o>=</span><span class=p>(</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>&lt;</span><span class=n>DIM</span><span class=p>)</span><span class=o>?</span><span class=n>smem</span><span class=p>[</span><span class=n>laneIdx</span><span class=p>]</span><span class=o>:</span><span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>if</span><span class=p>(</span><span class=n>warpIdx</span><span class=o>==</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>mySum</span><span class=o>=</span><span class=n>warpReduce</span><span class=p>(</span><span class=n>mySum</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=c1>//5.
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>if</span><span class=p>(</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=o>==</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>g_odata</span><span class=p>[</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>=</span><span class=n>mySum</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>代码解释:</p><ol><li>从全局内存读取数据，计算线程束ID和当前线程的束内线程ID</li><li>计算当前线程束内的归约结果，使用的xor，这里需要动手计算下每个线程和这些2的幂次计算的结果因为每个线程束只有32个线程，所以二进制最高位就是16，那么xor 16 是计算0+16，1+17，2+18，这些位置的和,计算完成后前16位是结果，16到31是一样结果，重复了一边，同理xor 8是计算0+8，1+9，2+10,&mldr;,前8位结果有效，后面是复制前面的答案，最后就得到当前线程束的归约结果。</li><li>然后把线程束结果存储到共享内存中</li><li>然后继续2中的过程计算3中得到的数据，完整的重复
5.将最后结果存入全局内存</li></ol><p><img loading=lazy src=./re-7.png alt=re-7></p><p>其他几个核函数前面文章都介绍过，我们通过实践可以看出使用线程束洗牌指令进行的归约效率最高。主要原因是使用寄存器进行数据交换而不需要任何位置的内存介入。
本文完整的代码在github:<a href=https://github.com/Tony-Tan/CUDA_Freshman>https://github.com/Tony-Tan/CUDA_Freshman</a>（欢迎随手star😝 ）</p><h2 id=总结>总结<a hidden class=anchor aria-hidden=true href=#总结>#</a></h2><p>本文介绍线程束洗牌指令的一些用法，其吸引人的地方就是不需要通过内存进行线程间数据交换，具有非常高的性能。
至此我们已经完成了第五章的学习，后面我们进入流和事件相关知识的学习。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://go.face2ai.com/tags/%E7%BA%BF%E7%A8%8B%E6%9D%9F%E6%B4%97%E7%89%8C%E6%8C%87%E4%BB%A4/>线程束洗牌指令</a></li></ul><nav class=paginav><a class=prev href=https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-6-0-%E6%B5%81%E5%92%8C%E5%B9%B6%E5%8F%91.zh/><span class=title>« Prev</span><br><span>【CUDA 基础】6.0 流和并发</span></a>
<a class=next href=https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-5-5-%E5%B8%B8%E9%87%8F%E5%86%85%E5%AD%98.zh/><span class=title>Next »</span><br><span>【CUDA 基础】5.5 常量内存</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】5.6 线程束洗牌指令 on twitter" href="https://twitter.com/intent/tweet/?text=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%915.6%20%e7%ba%bf%e7%a8%8b%e6%9d%9f%e6%b4%97%e7%89%8c%e6%8c%87%e4%bb%a4&url=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-5-6-%25E7%25BA%25BF%25E7%25A8%258B%25E6%259D%259F%25E6%25B4%2597%25E7%2589%258C%25E6%258C%2587%25E4%25BB%25A4.zh%2f&hashtags=%e7%ba%bf%e7%a8%8b%e6%9d%9f%e6%b4%97%e7%89%8c%e6%8c%87%e4%bb%a4"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】5.6 线程束洗牌指令 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-5-6-%25E7%25BA%25BF%25E7%25A8%258B%25E6%259D%259F%25E6%25B4%2597%25E7%2589%258C%25E6%258C%2587%25E4%25BB%25A4.zh%2f&title=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%915.6%20%e7%ba%bf%e7%a8%8b%e6%9d%9f%e6%b4%97%e7%89%8c%e6%8c%87%e4%bb%a4&summary=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%915.6%20%e7%ba%bf%e7%a8%8b%e6%9d%9f%e6%b4%97%e7%89%8c%e6%8c%87%e4%bb%a4&source=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-5-6-%25E7%25BA%25BF%25E7%25A8%258B%25E6%259D%259F%25E6%25B4%2597%25E7%2589%258C%25E6%258C%2587%25E4%25BB%25A4.zh%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】5.6 线程束洗牌指令 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-5-6-%25E7%25BA%25BF%25E7%25A8%258B%25E6%259D%259F%25E6%25B4%2597%25E7%2589%258C%25E6%258C%2587%25E4%25BB%25A4.zh%2f&title=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%915.6%20%e7%ba%bf%e7%a8%8b%e6%9d%9f%e6%b4%97%e7%89%8c%e6%8c%87%e4%bb%a4"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】5.6 线程束洗牌指令 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-5-6-%25E7%25BA%25BF%25E7%25A8%258B%25E6%259D%259F%25E6%25B4%2597%25E7%2589%258C%25E6%258C%2587%25E4%25BB%25A4.zh%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】5.6 线程束洗牌指令 on whatsapp" href="https://api.whatsapp.com/send?text=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%915.6%20%e7%ba%bf%e7%a8%8b%e6%9d%9f%e6%b4%97%e7%89%8c%e6%8c%87%e4%bb%a4%20-%20https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-5-6-%25E7%25BA%25BF%25E7%25A8%258B%25E6%259D%259F%25E6%25B4%2597%25E7%2589%258C%25E6%258C%2587%25E4%25BB%25A4.zh%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】5.6 线程束洗牌指令 on telegram" href="https://telegram.me/share/url?text=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%915.6%20%e7%ba%bf%e7%a8%8b%e6%9d%9f%e6%b4%97%e7%89%8c%e6%8c%87%e4%bb%a4&url=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-5-6-%25E7%25BA%25BF%25E7%25A8%258B%25E6%259D%259F%25E6%25B4%2597%25E7%2589%258C%25E6%258C%2587%25E4%25BB%25A4.zh%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://go.face2ai.com>谭升的博客</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerHTML="copy";function s(){e.innerHTML="copied!",setTimeout(()=>{e.innerHTML="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>