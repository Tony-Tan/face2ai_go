<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>【CUDA 基础】4.3 内存访问模式 | 谭升的博客</title><meta name=keywords content="内存访问模式,对齐,合并,缓存,结构体数组,数组结构体"><meta name=description content="Abstract: 本文介绍内存的访问过程，也就是从应用发起请求到硬件实现的完整操作过程，这里是优化内存瓶颈的关键之处，也是CUDA程序优化的基础。
Keywords: 内存访问模式，对齐，合并，缓存，结构体数组，数组结构体"><meta name=author content="谭升"><link rel=canonical href=https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-4-3-%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F.zh/><link crossorigin=anonymous href=../../../assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe+FVUFzPh7U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=../../../assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://go.face2ai.com/logo.png><link rel=icon type=image/png sizes=16x16 href=https://go.face2ai.com/logo.png><link rel=icon type=image/png sizes=32x32 href=https://go.face2ai.com/logo.png><link rel=apple-touch-icon href=https://go.face2ai.com/logo.png><link rel=mask-icon href=https://go.face2ai.com/logo.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-105335860-3","auto"),ga("send","pageview"))</script><meta property="og:title" content="【CUDA 基础】4.3 内存访问模式"><meta property="og:description" content="Abstract: 本文介绍内存的访问过程，也就是从应用发起请求到硬件实现的完整操作过程，这里是优化内存瓶颈的关键之处，也是CUDA程序优化的基础。
Keywords: 内存访问模式，对齐，合并，缓存，结构体数组，数组结构体"><meta property="og:type" content="article"><meta property="og:url" content="https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-4-3-%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F.zh/"><meta property="article:section" content="编程"><meta property="article:published_time" content="2018-05-03T22:08:07+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="【CUDA 基础】4.3 内存访问模式"><meta name=twitter:description content="Abstract: 本文介绍内存的访问过程，也就是从应用发起请求到硬件实现的完整操作过程，这里是优化内存瓶颈的关键之处，也是CUDA程序优化的基础。
Keywords: 内存访问模式，对齐，合并，缓存，结构体数组，数组结构体"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":3,"name":"【CUDA 基础】4.3 内存访问模式","item":"https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-4-3-%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F.zh/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"【CUDA 基础】4.3 内存访问模式","name":"【CUDA 基础】4.3 内存访问模式","description":"Abstract: 本文介绍内存的访问过程，也就是从应用发起请求到硬件实现的完整操作过程，这里是优化内存瓶颈的关键之处，也是CUDA程序优化的基础。 Keywords: 内存访问模式，对齐，合并，缓存，结构体数组，数组结构体\n","keywords":["内存访问模式","对齐","合并","缓存","结构体数组","数组结构体"],"articleBody":"Abstract: 本文介绍内存的访问过程，也就是从应用发起请求到硬件实现的完整操作过程，这里是优化内存瓶颈的关键之处，也是CUDA程序优化的基础。 Keywords: 内存访问模式，对齐，合并，缓存，结构体数组，数组结构体\n内存访问模式  “物有本末，事有终始，知所先后，则近道矣” ——《大学·大学之道章》\n 这句话出自大学，大学非我们现在上的大学，而我不知道我们现在的大学为什么叫大学，是否和《大学》有关系，但是大学第一章，就是讲道，让读书人懂得道：“格物，致知，诚意，正心，修身，齐家，治国，平天下”，但是我们现在似乎所有的课程都不讲这些了——可能是因为时间过去太久了，所以成了糟粕，但是我觉得对我还是有些启发的。 第一句引用的话没有官方解释，我觉得小学时候学的语文，概括中心思想，我觉得都是扯淡，一百个人有一百种想法，但是答案却是统一的，所以，我觉得这种就是培养有流水线上的机器，我只说这句话对我的启发，而且我们就从机器学习这个角度说。 举个例子，忽略时间，单从技术的角度，神经网络算是始还是终？是本还是末？我觉得不是始，也不是终。更不是本。 对于人工智能领域，我们的始是对于智慧的理解和再造，终点就是制造出人类智慧的机器，而神经网络只是我们要探索的深林里面一个大数，当有人认为这是最高峰的时候，那么他会不断地向上爬，直到最顶端，也许发现到达了我们的最终目的，但更大的可能性是周围还有更高的树。所以神经网络不是始也不是终，只是中间的一个过程，必须承认，我们走了三四十年才看到这棵这么大的树，但是如果还没爬到最顶端，就认定这个树就是终点了，似乎缺少一些谨慎。 而整个学科的本，我认为是数学，当如果哪一天证明，数学的整个体系在人工智能面前崩溃了，各种反公理，反定理的事件都在人工智能中发生了，那就证明我错了。但目前，本还是本。 废话有点多，今天我们要学习的也是CUDA中最最最重要的课程之一，当然我不会一口气写完，可能要写两天，但是以一篇的篇幅发表，力求写清楚写明白。用一些简单通俗，但是足够恰当的比喻和一些实例，让大家更容易了解。\n多数GPU程序容易受到内存带宽的限制，所以最大程度的利用全局内存带宽，提高全局加载效率（后面会详细说明），是调控内核函数性能的基本条件。如果不能正确调控全局内存使用，那么优化方案可能收效甚微。 CUDA执行模型告诉我们，CUDA执行的基本单位是线程束，所以，内存访问也是以线程束为基本单位发布和执行的，存储也一致。我们本文研究的就是这一个线程束的内存访问，不同线程的内存请求，其目标位置的不同，可以产生非常多种情况。所以本篇就是研究这些不同情况的，以及如何实现最佳的全局内存访问。 注意：访问可以是加载，也可以是存储。 注意，我们本文使用命令进行编译，省去反复修改CMakelist的麻烦.\n对齐与合并访问 全局内存通过缓存实现加载和存储的过程如下图 全局内存是一个逻辑层面的模型，我们编程的时候有两种模型考虑：一种是逻辑层面的，也就是我们在写程序的时候（包括串行程序和并行程序），写的一维（多维）数组，结构体，定义的变量，这些都是在逻辑层面的；一种是硬件角度，就是一块DRAM上的电信号，以及最底层内存驱动代码所完成数字信号的处理。 L1表示一级缓存，每个SM都有自己L1，但是L2是所有SM公用的，除了L1缓存外，还有只读缓存和常量缓存，这个我们后面会详细介绍。 核函数运行时需要从全局内存（DRAM）中读取数据，只有两种粒度，这个是关键的：\n 128字节 32字节  解释下“粒度”，可以理解为最小单位，也就是核函数运行时每次读内存，哪怕是读一个字节的变量，也要读128字节，或者32字节，而具体是到底是32还是128还是要看访问方式：\n 使用一级缓存 不使用一级缓存  对于CPU来说，一级缓存或者二级缓存是不能被编程的，但是CUDA是支持通过编译指令停用一级缓存的。如果启用一级缓存，那么每次从DRAM上加载数据的粒度是128字节，如果不适用一级缓存，只是用二级缓存，那么粒度是32字节。 还要强调一下CUDA内存模型的内存读写，我们现在讨论的都是单个SM上的情况，多个SM只是下面我们描述的情形的复制：SM执行的基础是线程束，也就是说，当一个SM中正在被执行的某个线程需要访问内存，那么，和它同线程束的其他31个线程也要访问内存，这个基础就表示，即使每个线程只访问一个字节，那么在执行的时候，只要有内存请求，至少是32个字节，所以不使用一级缓存的内存加载，一次粒度是32字节而不是更小。 在优化内存的时候，我们要最关注的是以下两个特性\n 对齐内存访问 合并内存访问  我们把一次内存请求——也就是从内核函数发起请求，到硬件响应返回数据这个过程称为一个内存事务（加载和存储都行）。 当一个内存事务的首个访问地址是缓存粒度（32或128字节）的偶数倍的时候：比如二级缓存32字节的偶数倍64，128字节的偶数倍256的时候，这个时候被称为对齐内存访问，非对齐访问就是除上述的其他情况，非对齐的内存访问会造成带宽浪费。 当一个线程束内的线程访问的内存都在一个内存块里的时候，就会出现合并访问。 对齐合并访问的状态是理想化的，也是最高速的访问方式，当线程束内的所有线程访问的数据在一个内存块，并且数据是从内存块的首地址开始被需要的，那么对齐合并访问出现了。为了最大化全局内存访问的理想状态，尽量将线程束访问内存组织成对齐合并的方式，这样的效率是最高的。下面看一个例子。\n 一个线程束加载数据，使用一级缓存，并且这个事务所请求的所有数据在一个128字节的对齐的地址段上（对齐的地址段是我自己发明的名字，就是首地址是粒度的偶数倍，那么上面这句话的意思是，所有请求的数据在某个首地址是粒度偶数倍的后128个字节里），具体形式如下图，这里请求的数据是连续的，其实可以不连续，但是不要越界就好。 上面蓝色表示全局内存，下面橙色是线程束要的数据，绿色就是我称为对齐的地址段。 如果一个事务加载的数据分布在不一个对齐的地址段上，就会有以下两种情况：  连续的，但是不在一个对齐的段上，比如，请求访问的数据分布在内存地址1~128，那么0~127和128~255这两段数据要传递两次到SM 不连续的，也不在一个对齐的段上，比如，请求访问的数据分布在内存地址0~63和128~191上，明显这也需要两次加载。 上图就是典型的一个线程束，数据分散开了，thread0的请求在128之前，后面还有请求在256之后，所以需要三个内存事务，而利用率，也就是从主存取回来的数据被使用到的比例，只有 $\\frac{128}{128\\times 3}$ 的比例。这个比例低会造成带宽的浪费，最极端的表现，就是如果每个线程的请求都在不同的段，也就是一个128字节的事务只有1个字节是有用的，那么利用率只有 $\\frac{1}{128}$    这里总结一下内存事务的优化关键：用最少的事务次数满足最多的内存请求。事务数量和吞吐量的需求随设备的计算能力变化。\n全局内存读取 注意我们说的都是读取，也就是加载过程，写或者叫做存储是另外一回事！ SM加载数据，根据不同的设备和类型分为三种路径：\n 一级和二级缓存 常量缓存 只读缓存  常规的路径是一级和二级缓存，需要使用常量和只读缓存的需要在代码中显式声明。但是提高性能，主要还是要取决于访问模式。 控制全局加载操作是否通过一级缓存可以通过编译选项来控制，当然比较老的设备可能就没有一级缓存。 编译器禁用一级缓存的选项是：\n-Xptxas -dlcm=cg 编译器启用一级缓存的选项是：\n-Xptxas -dlcm=ca 当一级缓存被禁用的时候，对全局内存的加载请求直接进入二级缓存，如果二级缓存缺失，则由DRAM完成请求。 每次内存事务可由一个两个或者四个部分执行，每个部分有32个字节，也就是32，64或者128字节一次（注意前面我们讲到是否使用一级缓存决定了读取粒度是128还是32字节，这里增加的64并不在此情况，所以需要注意）。 启用一级缓存后，当SM有全局加载请求会首先通过尝试一级缓存，如果一级缓存缺失，则尝试二级缓存，如果二级缓存也没有，那么直接DRAM。 在有些设备上一级缓存不用来缓存全局内存访问，而是只用来存储寄存器溢出的本地数据，比如Kepler 的K10,K20。 内存加载可以分为两类：\n 缓存加载 没有缓存的加载  内存访问有以下特点：\n 是否使用缓存：一级缓存是否介入加载过程 对齐与非对齐的：如果访问的第一个地址是32的倍数（前面说是32或者128的偶数倍，这里似乎产生了矛盾，为什么我现在也很迷惑） 合并与非合并，访问连续数据块则是合并的  缓存加载 下面是使用一级缓存的加载过程，图片表达很清楚，我们只用少量文字进行说明：\n  对齐合并的访问，利用率100%   对齐的，但是不是连续的，每个线程访问的数据都在一个块内，但是位置是交叉的，利用率100%   连续非对齐的，线程束请求一个连续的非对齐的，32个4字节数据，那么会出现，数据横跨两个块，但是没有对齐，当启用一级缓存的时候，就要两个128字节的事务来完成   线程束所有线程请求同一个地址，那么肯定落在一个缓存行范围（缓存行的概念没提到过，就是主存上一个可以被一次读到缓存中的一段数据。），那么如果按照请求的是4字节数据来说，使用一级缓存的利用率是 $\\frac{4}{128}=3.125%$   比较坏的情况，前面提到过最坏的，就是每个线程束内的线程请求的都是不同的缓存行内，这里比较坏的情况就是，所有数据分布在 $N$ 个缓存行上，其中 $1\\leq N\\leq 32$，那么请求32个4字节的数据，就需要 $N$ 个事务来完成，利用率也是 $\\frac{1}{N}$   CPU和GPU的一级缓存有显著的差异，GPU的一级缓存可以通过编译选项等控制，CPU不可以，而且CPU的一级缓存是的替换算法是有使用频率和时间局部性的，GPU则没有。\n没有缓存的加载 没有缓存的加载是指的没有通过一级缓存，二级缓存则是不得不经过的。 当不使用一级缓存的时候，内存事务的粒度变为32字节，更细粒度的好处是提高利用律，这个很好理解，比如你每次喝水只能选择一瓶大瓶500ml的或则一个小瓶的250ml，当你非常渴的时候需要400ml水分，喝大瓶的，比较方便，因为如果喝小瓶的一瓶不够，还需要再喝一瓶，此时大瓶的方便.但如果你需要200ml的水分的时候，小瓶的利用率就高很多。细粒度的访问就是用小瓶喝水，虽然体积小，但是每次的利用率都高了不少，针对上面使用缓存的情况5，可能效果会更好。 继续我们的图解：\n  对齐合并访问128字节，不用说，还是最理想的情况，使用4个段，利用率 $100%$   对齐不连续访问128字节，都在四个段内，且互不相同，这样的利用率也是 $100%$   连续不对齐，一个段32字节，所以，一个连续的128字节的请求，即使不对齐，最多也不会超过五个段，所以利用率是 $\\frac{4}{5}=80%$ ,如果不明白为啥不能超过5个段，请注意前提是连续的，这个时候不可能超过五段   所有线程访问一个4字节的数据，那么此时的利用率是 $\\frac{4}{32}=12.5%$   最欢的情况，所有目标数据分散在内存的各个角落，那么需要 N个内存段， 此时与使用一级缓存的作比较也是有优势的因为 $N\\times 128$ 还是要比 $N\\times 32$ 大不少，这里假设 $N$ 不会因为 $128$ 还是 $32$ 而变的，而实际情况，当使用大粒度的缓存行的时候， $N$ 有可能会减小   非对齐读取示例 下面就非对齐读取进行演示， 代码如下：\n#include #include #include \"freshman.h\" void sumArrays(float * a,float * b,float * res,int offset,const int size) { for(int i=0,k=offset;ksize;i++,k++) { res[i]=a[k]+b[k]; } } __global__ void sumArraysGPU(float*a,float*b,float*res,int offset,int n) { //int i=threadIdx.x;  int i=blockIdx.x*blockDim.x+threadIdx.x; int k=i+offset; if(kn) res[i]=a[k]+b[k]; } int main(int argc,char **argv) { int dev = 0; cudaSetDevice(dev); int nElem=118; int offset=0; if(argc=2) offset=atoi(argv[1]); printf(\"Vector size:%d\\n\",nElem); int nByte=sizeof(float)*nElem; float *a_h=(float*)malloc(nByte); float *b_h=(float*)malloc(nByte); float *res_h=(float*)malloc(nByte); float *res_from_gpu_h=(float*)malloc(nByte); memset(res_h,0,nByte); memset(res_from_gpu_h,0,nByte); float *a_d,*b_d,*res_d; CHECK(cudaMalloc((float**)\u0026a_d,nByte)); CHECK(cudaMalloc((float**)\u0026b_d,nByte)); CHECK(cudaMalloc((float**)\u0026res_d,nByte)); CHECK(cudaMemset(res_d,0,nByte)); initialData(a_h,nElem); initialData(b_h,nElem); CHECK(cudaMemcpy(a_d,a_h,nByte,cudaMemcpyHostToDevice)); CHECK(cudaMemcpy(b_d,b_h,nByte,cudaMemcpyHostToDevice)); dim3 block(1024); dim3 grid(nElem/block.x); double iStart,iElaps; iStart=cpuSecond(); sumArraysGPUgrid,block(a_d,b_d,res_d,offset,nElem); cudaDeviceSynchronize(); iElaps=cpuSecond()-iStart; CHECK(cudaMemcpy(res_from_gpu_h,res_d,nByte,cudaMemcpyDeviceToHost)); printf(\"Execution configuration Time elapsed %f sec --offset:%d \\n\",grid.x,block.x,iElaps,offset); sumArrays(a_h,b_h,res_h,offset,nElem); checkResult(res_h,res_from_gpu_h,nElem); cudaFree(a_d); cudaFree(b_d); cudaFree(res_d); free(a_h); free(b_h); free(res_h); free(res_from_gpu_h); return 0; } 编译指令：\ntony@tony-Lenovo:~/Project/CUDA_Freshman/18_sum_array_offset$ nvcc -O3 -arch=sm_35 -Xptxas -dlcm=cg -I ../include/ sum_array_offset.cu -o sum_array_offset 运行结果\n编译指令，启用一级缓存：\ntony@tony-Lenovo:~/Project/CUDA_Freshman/18_sum_array_offset$ nvcc -O3 -arch=sm_35 -Xptxas -dlcm=ca -I ../include/ sum_array_offset.cu -o sum_array_offset 这里我们使用的指标是： $$ 全局加载效率=\\frac{请求的全局内存加载吞吐量}{所需的全局内存加载吞吐量} $$\n只读缓存 只读缓存最初是留给纹理内存加载用的，在3.5以上的设备，只读缓存也支持使用全局内存加载代替一级缓存。也就是说3.5以后的设备，可以通过只读缓存从全局内存中读数据了。 只读缓存粒度32字节，对于分散读取，细粒度优于一级缓存 有两种方法指导内存从只读缓存读取：\n 使用函数 _ldg 在间接引用的指针上使用修饰符  代码：\n__global__ void copyKernel(float * in,float* out) { int idx=blockDim*blockIdx.x+threadIdx.x; out[idx]=__ldg(\u0026in[idx]); } 注意函数参数，然后就能强制使用只读缓存了。\n全局内存写入 内存的写入和读取（或者叫做加载）是完全不同的，并且写入相对简单很多。一级缓存不能用在 Fermi 和 Kepler GPU上进行存储操作，发送到设备前，只经过二级缓存，存储操作在32个字节的粒度上执行，内存事物也被分为一段两端或者四段，如果两个地址在一个128字节的段内但不在64字节范围内，则会产生一个四段的事务，其他情况以此类推。 我们将内存写入也参考前面的加载分为下面这些情况：\n  对齐的，访问一个连续的128字节范围。存储操作使用一个4段事务完成：   分散在一个192字节的范围内，不连续，使用3个一段事务来搞定   对齐的，在一个64字节的范围内，使用一个两段事务完成。   非对齐写入示例 与读取情况类似，且更简单，因为始终不经过一级缓存，所以略过此实验。\n结构体数组与数组结构体 写过C语言的人对结构体都应该非常了解，结构体说白了就是基础数据类型组合出来的新的数据类型，这个新的数据类型在内存中表现是：结构中的成员在内存里对齐的依次排开，然后我们我们就有了接下来的话题，数组的结构体，和结构体的数组。 数组结构体（AoS）就是一个数组，每个元素都是一个结构体，而结构体数组（SoA）就是结构体中的成员是数组用代码表示： AoS\nstruct A a[N]; SoA\nstruct A{ int a[N]; int b[N] }a; 如果你分不清这两个名字，没关系，我也分不清，记住AoS是数组就行了，CUDA对细粒度数组是非常友好的，但是对粗粒度如结构体组成的数组就不太友好了，具体表现在，内存访问利用率低。比如当一个线程要访问结构体中的某个成员的时候，当三十二个线程同时访问的时候，SoA的访问就是连续的，而AoS则是不连续： 这样看来AoS访问效率只有 $50%$ 对比AoS和SoA的内存布局，我们能得到下面结论。\n 并行编程范式，尤其是SIMD（单指令多数据）对SoA更友好。CUDA中普遍倾向于SoA因为这种内存访问可以有效地合并。  AoS数据布局的简单数学运算 我们看一下AoS的例子\n#include #include #include \"freshman.h\" struct naiveStruct{ float a; float b; }; void sumArrays(float * a,float * b,float * res,const int size) { for(int i=0;isize;i++) { res[i]=a[i]+b[i]; } } __global__ void sumArraysGPU(float*a,float*b,struct naiveStruct* res,int n) { //int i=threadIdx.x;  int i=blockIdx.x*blockDim.x+threadIdx.x; if(in) res[i].a=a[i]+b[i]; } void checkResult_struct(float* res_h,struct naiveStruct*res_from_gpu_h,int nElem) { for(int i=0;inElem;i++) if (res_h[i]!=res_from_gpu_h[i].a) { printf(\"check fail!\\n\"); exit(0); } printf(\"result check success!\\n\"); } int main(int argc,char **argv) { int dev = 0; cudaSetDevice(dev); int nElem=118; int offset=0; if(argc=2) offset=atoi(argv[1]); printf(\"Vector size:%d\\n\",nElem); int nByte=sizeof(float)*nElem; int nByte_struct=sizeof(struct naiveStruct)*nElem; float *a_h=(float*)malloc(nByte); float *b_h=(float*)malloc(nByte); float *res_h=(float*)malloc(nByte_struct); struct naiveStruct *res_from_gpu_h=(struct naiveStruct*)malloc(nByte_struct); memset(res_h,0,nByte); memset(res_from_gpu_h,0,nByte); float *a_d,*b_d; struct naiveStruct* res_d; CHECK(cudaMalloc((float**)\u0026a_d,nByte)); CHECK(cudaMalloc((float**)\u0026b_d,nByte)); CHECK(cudaMalloc((struct naiveStruct**)\u0026res_d,nByte_struct)); CHECK(cudaMemset(res_d,0,nByte_struct)); initialData(a_h,nElem); initialData(b_h,nElem); CHECK(cudaMemcpy(a_d,a_h,nByte,cudaMemcpyHostToDevice)); CHECK(cudaMemcpy(b_d,b_h,nByte,cudaMemcpyHostToDevice)); dim3 block(1024); dim3 grid(nElem/block.x); double iStart,iElaps; iStart=cpuSecond(); sumArraysGPUgrid,block(a_d,b_d,res_d,nElem); cudaDeviceSynchronize(); iElaps=cpuSecond()-iStart; CHECK(cudaMemcpy(res_from_gpu_h,res_d,nByte_struct,cudaMemcpyDeviceToHost)); printf(\"Execution configuration Time elapsed %f sec\\n\",grid.x,block.x,iElaps); sumArrays(a_h,b_h,res_h,nElem); checkResult_struct(res_h,res_from_gpu_h,nElem); cudaFree(a_d); cudaFree(b_d); cudaFree(res_d); free(a_h); free(b_h); free(res_h); free(res_from_gpu_h); return 0; } nvcc -O3 -arch=sm_35 -Xptxas -dlcm=ca -I ../include/ AoS.cu -o AoS nvcc -O3 -arch=sm_35 -Xptxas -dlcm=cg -I ../include/ AoS.cu -o AoS SoA数据布局的简单数学运算 然后看SoA的例子\n#include #include #include \"freshman.h\" void sumArrays(float * a,float * b,float * res,int offset,const int size) { for(int i=0,k=offset;ksize;i++,k++) { res[i]=a[k]+b[k]; } } __global__ void sumArraysGPU(float*a,float*b,float*res,int offset,int n) { //int i=threadIdx.x;  int i=blockIdx.x*blockDim.x*4+threadIdx.x; int k=i+offset; if(k+3*blockDim.xn) { res[i]=a[k]+b[k]; res[i+blockDim.x]=a[k+blockDim.x]+b[k+blockDim.x]; res[i+blockDim.x*2]=a[k+blockDim.x*2]+b[k+blockDim.x*2]; res[i+blockDim.x*3]=a[k+blockDim.x*3]+b[k+blockDim.x*3]; } } int main(int argc,char **argv) { int dev = 0; cudaSetDevice(dev); int block_x=512; int nElem=118; int offset=0; if(argc==2) offset=atoi(argv[1]); else if(argc==3) { offset=atoi(argv[1]); block_x=atoi(argv[2]); } printf(\"Vector size:%d\\n\",nElem); int nByte=sizeof(float)*nElem; float *a_h=(float*)malloc(nByte); float *b_h=(float*)malloc(nByte); float *res_h=(float*)malloc(nByte); float *res_from_gpu_h=(float*)malloc(nByte); memset(res_h,0,nByte); memset(res_from_gpu_h,0,nByte); float *a_d,*b_d,*res_d; CHECK(cudaMalloc((float**)\u0026a_d,nByte)); CHECK(cudaMalloc((float**)\u0026b_d,nByte)); CHECK(cudaMalloc((float**)\u0026res_d,nByte)); CHECK(cudaMemset(res_d,0,nByte)); initialData(a_h,nElem); initialData(b_h,nElem); CHECK(cudaMemcpy(a_d,a_h,nByte,cudaMemcpyHostToDevice)); CHECK(cudaMemcpy(b_d,b_h,nByte,cudaMemcpyHostToDevice)); dim3 block(block_x); dim3 grid(nElem/block.x); double iStart,iElaps; iStart=cpuSecond(); sumArraysGPUgrid,block(a_d,b_d,res_d,offset,nElem); cudaDeviceSynchronize(); iElaps=cpuSecond()-iStart; printf(\"warmup Time elapsed %f sec\\n\",iElaps); iStart=cpuSecond(); sumArraysGPUgrid,block(a_d,b_d,res_d,offset,nElem); cudaDeviceSynchronize(); iElaps=cpuSecond()-iStart; CHECK(cudaMemcpy(res_from_gpu_h,res_d,nByte,cudaMemcpyDeviceToHost)); printf(\"Execution configuration Time elapsed %f sec --offset:%d \\n\",grid.x,block.x,iElaps,offset); sumArrays(a_h,b_h,res_h,offset,nElem); checkResult(res_h,res_from_gpu_h,nElem-4*block_x); cudaFree(a_d); cudaFree(b_d); cudaFree(res_d); free(a_h); free(b_h); free(res_h); free(res_from_gpu_h); return 0; } nvcc -O3 -arch=sm_35 -Xptxas -dlcm=ca -I ../include/ SoA.cu -o SoA nvcc -O3 -arch=sm_35 -Xptxas -dlcm=cg -I ../include/ SoA.cu -o SoA 性能调整 优化设备内存带宽利用率有两个目标：\n 对齐合并内存访问，以减少带宽的浪费 足够的并发内存操作，以隐藏内存延迟  第三章我们讲过优化指令吞吐量的核函数，实现并发内存访问量最大化是通过以下方式得到的：\n 增加每个线程中执行独立内存操作的数量 对核函数启动的执行配置进行试验，已充分体现每个SM的并行性  接下来我们就按照这个思路对程序进行优化试验：展开技术和增大并行性。\n展开技术 把前面讲到的展开技术用到向量加法上，我们来看看其对内存效率的影响： 代码\n#include #include #include \"freshman.h\" void sumArrays(float * a,float * b,float * res,int offset,const int size) { for(int i=0,k=offset;ksize;i++,k++) { res[i]=a[k]+b[k]; } } __global__ void sumArraysGPU(float*a,float*b,float*res,int offset,int n) { //int i=threadIdx.x;  int i=blockIdx.x*blockDim.x*4+threadIdx.x; int k=i+offset; if(k+3*blockDim.xn) { res[i]=a[k]+b[k]; res[i+blockDim.x]=a[k+blockDim.x]+b[k+blockDim.x]; res[i+blockDim.x*2]=a[k+blockDim.x*2]+b[k+blockDim.x*2]; res[i+blockDim.x*3]=a[k+blockDim.x*3]+b[k+blockDim.x*3]; } } int main(int argc,char **argv) { int dev = 0; cudaSetDevice(dev); int block_x=512; int nElem=118; int offset=0; if(argc==2) offset=atoi(argv[1]); else if(argc==3) { offset=atoi(argv[1]); block_x=atoi(argv[2]); } printf(\"Vector size:%d\\n\",nElem); int nByte=sizeof(float)*nElem; float *a_h=(float*)malloc(nByte); float *b_h=(float*)malloc(nByte); float *res_h=(float*)malloc(nByte); float *res_from_gpu_h=(float*)malloc(nByte); memset(res_h,0,nByte); memset(res_from_gpu_h,0,nByte); float *a_d,*b_d,*res_d; CHECK(cudaMalloc((float**)\u0026a_d,nByte)); CHECK(cudaMalloc((float**)\u0026b_d,nByte)); CHECK(cudaMalloc((float**)\u0026res_d,nByte)); CHECK(cudaMemset(res_d,0,nByte)); initialData(a_h,nElem); initialData(b_h,nElem); CHECK(cudaMemcpy(a_d,a_h,nByte,cudaMemcpyHostToDevice)); CHECK(cudaMemcpy(b_d,b_h,nByte,cudaMemcpyHostToDevice)); dim3 block(block_x); dim3 grid(nElem/block.x); double iStart,iElaps; iStart=cpuSecond(); sumArraysGPUgrid,block(a_d,b_d,res_d,offset,nElem); cudaDeviceSynchronize(); iElaps=cpuSecond()-iStart; printf(\"warmup Time elapsed %f sec\\n\",iElaps); iStart=cpuSecond(); sumArraysGPUgrid,block(a_d,b_d,res_d,offset,nElem); cudaDeviceSynchronize(); iElaps=cpuSecond()-iStart; CHECK(cudaMemcpy(res_from_gpu_h,res_d,nByte,cudaMemcpyDeviceToHost)); printf(\"Execution configuration Time elapsed %f sec --offset:%d \\n\",grid.x,block.x,iElaps,offset); sumArrays(a_h,b_h,res_h,offset,nElem); checkResult(res_h,res_from_gpu_h,nElem-4*block_x); cudaFree(a_d); cudaFree(b_d); cudaFree(res_d); free(a_h); free(b_h); free(res_h); free(res_from_gpu_h); return 0; } 编译指令。\nnvcc -O3 sum_array_offset_unrolling.cu -o sum_array_offset_unrolling -arch=sm_35 -Xptxas -dlcm=cg -I ../include/ nvprof 内存效率\n增大并行性 通过调整块的大小来实现并行性调整，也是前面讲过的套路，我们关注的还是内存利用效率 代码同上面的展开技术。 offset=11的时候\n由于数据量少，所以时间差距不大，512有最佳速度，不仅因为内存，还有并行性等多方面因素，这个前面我们也曾提到过。要看综合能力。\n本文全部代码都在Github上有完整版，请访问：https://github.com/Tony-Tan/CUDA_Freshman\n总结 这是我今年写作时间最长的一篇博客，写了三天，主要是代码比较多，结果也比较多 这里我们没用Cmake，而是用的指令，原因是方便修改编译选项，试验时间结果不明显的原因是数据量小，部分结果和书上不一致，主要是书的时间比较久了，GPU换代太快。 全局内存本篇算是比较完整了，后面还有其他内存知识，我们继续。\n","wordCount":"789","inLanguage":"en","datePublished":"2018-05-03T22:08:07Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"谭升"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-4-3-%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F.zh/"},"publisher":{"@type":"Organization","name":"谭升的博客","logo":{"@type":"ImageObject","url":"https://go.face2ai.com/logo.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://go.face2ai.com accesskey=h title="谭升的博客 (Alt + H)">谭升的博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://go.face2ai.com/math/ title=数学><span>数学</span></a></li><li><a href=https://go.face2ai.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://go.face2ai.com/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://go.face2ai.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://go.face2ai.com/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://go.face2ai.com>Home</a></div><h1 class=post-title>【CUDA 基础】4.3 内存访问模式</h1><div class=post-meta><span title="2018-05-03 22:08:07 +0000 UTC">May 3, 2018</span>&nbsp;·&nbsp;谭升</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e5%86%85%e5%ad%98%e8%ae%bf%e9%97%ae%e6%a8%a1%e5%bc%8f aria-label=内存访问模式>内存访问模式</a><ul><li><a href=#%e5%af%b9%e9%bd%90%e4%b8%8e%e5%90%88%e5%b9%b6%e8%ae%bf%e9%97%ae aria-label=对齐与合并访问>对齐与合并访问</a></li><li><a href=#%e5%85%a8%e5%b1%80%e5%86%85%e5%ad%98%e8%af%bb%e5%8f%96 aria-label=全局内存读取>全局内存读取</a><ul><li><a href=#%e7%bc%93%e5%ad%98%e5%8a%a0%e8%bd%bd aria-label=缓存加载>缓存加载</a></li><li><a href=#%e6%b2%a1%e6%9c%89%e7%bc%93%e5%ad%98%e7%9a%84%e5%8a%a0%e8%bd%bd aria-label=没有缓存的加载>没有缓存的加载</a></li><li><a href=#%e9%9d%9e%e5%af%b9%e9%bd%90%e8%af%bb%e5%8f%96%e7%a4%ba%e4%be%8b aria-label=非对齐读取示例>非对齐读取示例</a></li><li><a href=#%e5%8f%aa%e8%af%bb%e7%bc%93%e5%ad%98 aria-label=只读缓存>只读缓存</a></li></ul></li><li><a href=#%e5%85%a8%e5%b1%80%e5%86%85%e5%ad%98%e5%86%99%e5%85%a5 aria-label=全局内存写入>全局内存写入</a><ul><li><a href=#%e9%9d%9e%e5%af%b9%e9%bd%90%e5%86%99%e5%85%a5%e7%a4%ba%e4%be%8b aria-label=非对齐写入示例>非对齐写入示例</a></li></ul></li><li><a href=#%e7%bb%93%e6%9e%84%e4%bd%93%e6%95%b0%e7%bb%84%e4%b8%8e%e6%95%b0%e7%bb%84%e7%bb%93%e6%9e%84%e4%bd%93 aria-label=结构体数组与数组结构体>结构体数组与数组结构体</a><ul><li><a href=#aos%e6%95%b0%e6%8d%ae%e5%b8%83%e5%b1%80%e7%9a%84%e7%ae%80%e5%8d%95%e6%95%b0%e5%ad%a6%e8%bf%90%e7%ae%97 aria-label=AoS数据布局的简单数学运算>AoS数据布局的简单数学运算</a></li><li><a href=#soa%e6%95%b0%e6%8d%ae%e5%b8%83%e5%b1%80%e7%9a%84%e7%ae%80%e5%8d%95%e6%95%b0%e5%ad%a6%e8%bf%90%e7%ae%97 aria-label=SoA数据布局的简单数学运算>SoA数据布局的简单数学运算</a></li></ul></li><li><a href=#%e6%80%a7%e8%83%bd%e8%b0%83%e6%95%b4 aria-label=性能调整>性能调整</a><ul><li><a href=#%e5%b1%95%e5%bc%80%e6%8a%80%e6%9c%af aria-label=展开技术>展开技术</a></li><li><a href=#%e5%a2%9e%e5%a4%a7%e5%b9%b6%e8%a1%8c%e6%80%a7 aria-label=增大并行性>增大并行性</a></li></ul></li><li><a href=#%e6%80%bb%e7%bb%93 aria-label=总结>总结</a></li></ul></li></ul></div></details></div><div class=post-content><p><strong>Abstract:</strong> 本文介绍内存的访问过程，也就是从应用发起请求到硬件实现的完整操作过程，这里是优化内存瓶颈的关键之处，也是CUDA程序优化的基础。
<strong>Keywords:</strong> 内存访问模式，对齐，合并，缓存，结构体数组，数组结构体</p><h1 id=内存访问模式>内存访问模式<a hidden class=anchor aria-hidden=true href=#内存访问模式>#</a></h1><blockquote><p>&ldquo;物有本末，事有终始，知所先后，则近道矣&rdquo;
——《大学·大学之道章》</p></blockquote><p>这句话出自大学，大学非我们现在上的大学，而我不知道我们现在的大学为什么叫大学，是否和《大学》有关系，但是大学第一章，就是讲道，让读书人懂得道：&ldquo;格物，致知，诚意，正心，修身，齐家，治国，平天下&rdquo;，但是我们现在似乎所有的课程都不讲这些了——可能是因为时间过去太久了，所以成了糟粕，但是我觉得对我还是有些启发的。
第一句引用的话没有官方解释，我觉得小学时候学的语文，概括中心思想，我觉得都是扯淡，一百个人有一百种想法，但是答案却是统一的，所以，我觉得这种就是培养有流水线上的机器，我只说这句话对我的启发，而且我们就从机器学习这个角度说。
举个例子，忽略时间，单从技术的角度，神经网络算是始还是终？是本还是末？我觉得不是始，也不是终。更不是本。
对于人工智能领域，我们的始是对于智慧的理解和再造，终点就是制造出人类智慧的机器，而神经网络只是我们要探索的深林里面一个大数，当有人认为这是最高峰的时候，那么他会不断地向上爬，直到最顶端，也许发现到达了我们的最终目的，但更大的可能性是周围还有更高的树。所以神经网络不是始也不是终，只是中间的一个过程，必须承认，我们走了三四十年才看到这棵这么大的树，但是如果还没爬到最顶端，就认定这个树就是终点了，似乎缺少一些谨慎。
而整个学科的本，我认为是数学，当如果哪一天证明，数学的整个体系在人工智能面前崩溃了，各种反公理，反定理的事件都在人工智能中发生了，那就证明我错了。但目前，本还是本。
废话有点多，今天我们要学习的也是CUDA中最最最重要的课程之一，当然我不会一口气写完，可能要写两天，但是以一篇的篇幅发表，力求写清楚写明白。用一些简单通俗，但是足够恰当的比喻和一些实例，让大家更容易了解。</p><p>多数GPU程序容易受到内存带宽的限制，所以最大程度的利用全局内存带宽，提高全局加载效率（后面会详细说明），是调控内核函数性能的基本条件。如果不能正确调控全局内存使用，那么优化方案可能收效甚微。
CUDA执行模型告诉我们，CUDA执行的基本单位是线程束，所以，内存访问也是以线程束为基本单位发布和执行的，存储也一致。我们本文研究的就是这一个线程束的内存访问，不同线程的内存请求，其目标位置的不同，可以产生非常多种情况。所以本篇就是研究这些不同情况的，以及如何实现最佳的全局内存访问。
注意：访问可以是加载，也可以是存储。
注意，我们本文使用命令进行编译，省去反复修改CMakelist的麻烦.</p><h2 id=对齐与合并访问>对齐与合并访问<a hidden class=anchor aria-hidden=true href=#对齐与合并访问>#</a></h2><p>全局内存通过缓存实现加载和存储的过程如下图
<img loading=lazy src=./1-1.png alt=1-1>
全局内存是一个逻辑层面的模型，我们编程的时候有两种模型考虑：一种是逻辑层面的，也就是我们在写程序的时候（包括串行程序和并行程序），写的一维（多维）数组，结构体，定义的变量，这些都是在逻辑层面的；一种是硬件角度，就是一块DRAM上的电信号，以及最底层内存驱动代码所完成数字信号的处理。
L1表示一级缓存，每个SM都有自己L1，但是L2是所有SM公用的，除了L1缓存外，还有只读缓存和常量缓存，这个我们后面会详细介绍。
核函数运行时需要从全局内存（DRAM）中读取数据，只有两种粒度，这个是关键的：</p><ul><li>128字节</li><li>32字节</li></ul><p>解释下“粒度”，可以理解为最小单位，也就是核函数运行时每次读内存，哪怕是读一个字节的变量，也要读128字节，或者32字节，而具体是到底是32还是128还是要看访问方式：</p><ul><li>使用一级缓存</li><li>不使用一级缓存</li></ul><p>对于CPU来说，一级缓存或者二级缓存是不能被编程的，但是CUDA是支持通过编译指令停用一级缓存的。如果启用一级缓存，那么每次从DRAM上加载数据的粒度是128字节，如果不适用一级缓存，只是用二级缓存，那么粒度是32字节。
还要强调一下CUDA内存模型的内存读写，我们现在讨论的都是单个SM上的情况，多个SM只是下面我们描述的情形的复制：SM执行的基础是线程束，也就是说，当一个SM中正在被执行的某个线程需要访问内存，那么，和它同线程束的其他31个线程也要访问内存，这个基础就表示，即使每个线程只访问一个字节，那么在执行的时候，只要有内存请求，至少是32个字节，所以不使用一级缓存的内存加载，一次粒度是32字节而不是更小。
在优化内存的时候，我们要最关注的是以下两个特性</p><ul><li>对齐内存访问</li><li>合并内存访问</li></ul><p>我们把一次内存请求——也就是从内核函数发起请求，到硬件响应返回数据这个过程称为一个内存事务（加载和存储都行）。
当一个内存事务的首个访问地址是缓存粒度（32或128字节）的偶数倍的时候：比如二级缓存32字节的偶数倍64，128字节的偶数倍256的时候，这个时候被称为对齐内存访问，非对齐访问就是除上述的其他情况，非对齐的内存访问会造成带宽浪费。
当一个线程束内的线程访问的内存都在一个内存块里的时候，就会出现合并访问。
对齐合并访问的状态是理想化的，也是最高速的访问方式，当线程束内的所有线程访问的数据在一个内存块，并且数据是从内存块的首地址开始被需要的，那么对齐合并访问出现了。为了最大化全局内存访问的理想状态，尽量将线程束访问内存组织成对齐合并的方式，这样的效率是最高的。下面看一个例子。</p><ul><li>一个线程束加载数据，使用一级缓存，并且这个事务所请求的所有数据在一个128字节的对齐的地址段上（对齐的地址段是我自己发明的名字，就是首地址是粒度的偶数倍，那么上面这句话的意思是，所有请求的数据在某个首地址是粒度偶数倍的后128个字节里），具体形式如下图，这里请求的数据是连续的，其实可以不连续，但是不要越界就好。
<img loading=lazy src=./4-6.png alt=4-6>
上面蓝色表示全局内存，下面橙色是线程束要的数据，绿色就是我称为对齐的地址段。</li><li>如果一个事务加载的数据分布在不一个对齐的地址段上，就会有以下两种情况：<ol><li>连续的，但是不在一个对齐的段上，比如，请求访问的数据分布在内存地址1~128，那么0~127和128~255这两段数据要传递两次到SM</li><li>不连续的，也不在一个对齐的段上，比如，请求访问的数据分布在内存地址0~63和128~191上，明显这也需要两次加载。
<img loading=lazy src=./4-8.png alt=4-8>
上图就是典型的一个线程束，数据分散开了，thread0的请求在128之前，后面还有请求在256之后，所以需要三个内存事务，而利用率，也就是从主存取回来的数据被使用到的比例，只有 $\frac{128}{128\times 3}$ 的比例。这个比例低会造成带宽的浪费，最极端的表现，就是如果每个线程的请求都在不同的段，也就是一个128字节的事务只有1个字节是有用的，那么利用率只有 $\frac{1}{128}$</li></ol></li></ul><p>这里总结一下内存事务的优化关键：用最少的事务次数满足最多的内存请求。事务数量和吞吐量的需求随设备的计算能力变化。</p><h2 id=全局内存读取>全局内存读取<a hidden class=anchor aria-hidden=true href=#全局内存读取>#</a></h2><p>注意我们说的都是读取，也就是加载过程，写或者叫做存储是另外一回事！
SM加载数据，根据不同的设备和类型分为三种路径：</p><ol><li>一级和二级缓存</li><li>常量缓存</li><li>只读缓存</li></ol><p>常规的路径是一级和二级缓存，需要使用常量和只读缓存的需要在代码中显式声明。但是提高性能，主要还是要取决于访问模式。
控制全局加载操作是否通过一级缓存可以通过编译选项来控制，当然比较老的设备可能就没有一级缓存。
编译器禁用一级缓存的选项是：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>-Xptxas -dlcm<span class=o>=</span>cg
</span></span></code></pre></div><p>编译器启用一级缓存的选项是：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>-Xptxas -dlcm<span class=o>=</span>ca
</span></span></code></pre></div><p>当一级缓存被禁用的时候，对全局内存的加载请求直接进入二级缓存，如果二级缓存缺失，则由DRAM完成请求。
每次内存事务可由一个两个或者四个部分执行，每个部分有32个字节，也就是32，64或者128字节一次（注意前面我们讲到是否使用一级缓存决定了读取粒度是128还是32字节，这里增加的64并不在此情况，所以需要注意）。
启用一级缓存后，当SM有全局加载请求会首先通过尝试一级缓存，如果一级缓存缺失，则尝试二级缓存，如果二级缓存也没有，那么直接DRAM。
在有些设备上一级缓存不用来缓存全局内存访问，而是只用来存储寄存器溢出的本地数据，比如Kepler 的K10,K20。
内存加载可以分为两类：</p><ul><li>缓存加载</li><li>没有缓存的加载</li></ul><p>内存访问有以下特点：</p><ul><li>是否使用缓存：一级缓存是否介入加载过程</li><li>对齐与非对齐的：如果访问的第一个地址是32的倍数（<font color=ff0000>前面说是32或者128的偶数倍，这里似乎产生了矛盾，为什么我现在也很迷惑</font>）</li><li>合并与非合并，访问连续数据块则是合并的</li></ul><h3 id=缓存加载>缓存加载<a hidden class=anchor aria-hidden=true href=#缓存加载>#</a></h3><p>下面是使用一级缓存的加载过程，图片表达很清楚，我们只用少量文字进行说明：</p><ol><li><p>对齐合并的访问，利用率100%
<img loading=lazy src=./4-9.png alt=4-9></p></li><li><p>对齐的，但是不是连续的，每个线程访问的数据都在一个块内，但是位置是交叉的，利用率100%
<img loading=lazy src=./4-10.png alt=4-10></p></li><li><p>连续非对齐的，线程束请求一个连续的非对齐的，32个4字节数据，那么会出现，数据横跨两个块，但是没有对齐，当启用一级缓存的时候，就要两个128字节的事务来完成
<img loading=lazy src=./4-11.png alt=4-11></p></li><li><p>线程束所有线程请求同一个地址，那么肯定落在一个缓存行范围（缓存行的概念没提到过，就是主存上一个可以被一次读到缓存中的一段数据。），那么如果按照请求的是4字节数据来说，使用一级缓存的利用率是 $\frac{4}{128}=3.125%$
<img loading=lazy src=./4-12.png alt=4-12></p></li><li><p>比较坏的情况，前面提到过最坏的，就是每个线程束内的线程请求的都是不同的缓存行内，这里比较坏的情况就是，所有数据分布在 $N$ 个缓存行上，其中 $1\leq N\leq 32$，那么请求32个4字节的数据，就需要 $N$ 个事务来完成，利用率也是 $\frac{1}{N}$
<img loading=lazy src=./4-13.png alt=4-13></p></li></ol><p>CPU和GPU的一级缓存有显著的差异，GPU的一级缓存可以通过编译选项等控制，CPU不可以，而且CPU的一级缓存是的替换算法是有使用频率和时间局部性的，GPU则没有。</p><h3 id=没有缓存的加载>没有缓存的加载<a hidden class=anchor aria-hidden=true href=#没有缓存的加载>#</a></h3><p>没有缓存的加载是指的没有通过一级缓存，二级缓存则是不得不经过的。
当不使用一级缓存的时候，内存事务的粒度变为32字节，更细粒度的好处是提高利用律，这个很好理解，比如你每次喝水只能选择一瓶大瓶500ml的或则一个小瓶的250ml，当你非常渴的时候需要400ml水分，喝大瓶的，比较方便，因为如果喝小瓶的一瓶不够，还需要再喝一瓶，此时大瓶的方便.但如果你需要200ml的水分的时候，小瓶的利用率就高很多。细粒度的访问就是用小瓶喝水，虽然体积小，但是每次的利用率都高了不少，针对上面使用缓存的情况5，可能效果会更好。
继续我们的图解：</p><ol><li><p>对齐合并访问128字节，不用说，还是最理想的情况，使用4个段，利用率 $100%$
<img loading=lazy src=./4-14.png alt=4-14></p></li><li><p>对齐不连续访问128字节，都在四个段内，且互不相同，这样的利用率也是 $100%$
<img loading=lazy src=./4-15.png alt=4-15></p></li><li><p>连续不对齐，一个段32字节，所以，一个连续的128字节的请求，即使不对齐，最多也不会超过五个段，所以利用率是 $\frac{4}{5}=80%$ ,如果不明白为啥不能超过5个段，请注意前提是连续的，这个时候不可能超过五段
<img loading=lazy src=./4-16.png alt=4-16></p></li><li><p>所有线程访问一个4字节的数据，那么此时的利用率是 $\frac{4}{32}=12.5%$
<img loading=lazy src=./4-17.png alt=4-17></p></li><li><p>最欢的情况，所有目标数据分散在内存的各个角落，那么需要 N个内存段， 此时与使用一级缓存的作比较也是有优势的因为 $N\times 128$ 还是要比 $N\times 32$ 大不少，这里假设 $N$ 不会因为 $128$ 还是 $32$ 而变的，而实际情况，当使用大粒度的缓存行的时候， $N$ 有可能会减小
<img loading=lazy src=./4-18.png alt=4-18></p></li></ol><h3 id=非对齐读取示例>非对齐读取示例<a hidden class=anchor aria-hidden=true href=#非对齐读取示例>#</a></h3><p>下面就非对齐读取进行演示，
代码如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;cuda_runtime.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;stdio.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&#34;freshman.h&#34;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>sumArrays</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span> <span class=n>a</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>b</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>res</span><span class=p>,</span><span class=kt>int</span> <span class=n>offset</span><span class=p>,</span><span class=k>const</span> <span class=kt>int</span> <span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span><span class=n>k</span><span class=o>=</span><span class=n>offset</span><span class=p>;</span><span class=n>k</span><span class=o>&lt;</span><span class=n>size</span><span class=p>;</span><span class=n>i</span><span class=o>++</span><span class=p>,</span><span class=n>k</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>res</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>=</span><span class=n>a</span><span class=p>[</span><span class=n>k</span><span class=p>]</span><span class=o>+</span><span class=n>b</span><span class=p>[</span><span class=n>k</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>sumArraysGPU</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=n>a</span><span class=p>,</span><span class=kt>float</span><span class=o>*</span><span class=n>b</span><span class=p>,</span><span class=kt>float</span><span class=o>*</span><span class=n>res</span><span class=p>,</span><span class=kt>int</span> <span class=n>offset</span><span class=p>,</span><span class=kt>int</span> <span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=c1>//int i=threadIdx.x;
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=kt>int</span> <span class=n>i</span><span class=o>=</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>k</span><span class=o>=</span><span class=n>i</span><span class=o>+</span><span class=n>offset</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span><span class=p>(</span><span class=n>k</span><span class=o>&lt;</span><span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>res</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>=</span><span class=n>a</span><span class=p>[</span><span class=n>k</span><span class=p>]</span><span class=o>+</span><span class=n>b</span><span class=p>[</span><span class=n>k</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>(</span><span class=kt>int</span> <span class=n>argc</span><span class=p>,</span><span class=kt>char</span> <span class=o>**</span><span class=n>argv</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>dev</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaSetDevice</span><span class=p>(</span><span class=n>dev</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>nElem</span><span class=o>=</span><span class=mi>1</span><span class=o>&lt;&lt;</span><span class=mi>18</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>offset</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span><span class=p>(</span><span class=n>argc</span><span class=o>&gt;=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>offset</span><span class=o>=</span><span class=n>atoi</span><span class=p>(</span><span class=n>argv</span><span class=p>[</span><span class=mi>1</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>  <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Vector size:%d</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>nByte</span><span class=o>=</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)</span><span class=o>*</span><span class=n>nElem</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>a_h</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>b_h</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>res_h</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>res_from_gpu_h</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>memset</span><span class=p>(</span><span class=n>res_h</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>memset</span><span class=p>(</span><span class=n>res_from_gpu_h</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>a_d</span><span class=p>,</span><span class=o>*</span><span class=n>b_d</span><span class=p>,</span><span class=o>*</span><span class=n>res_d</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>float</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>a_d</span><span class=p>,</span><span class=n>nByte</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>float</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>b_d</span><span class=p>,</span><span class=n>nByte</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>float</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>res_d</span><span class=p>,</span><span class=n>nByte</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemset</span><span class=p>(</span><span class=n>res_d</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=n>nByte</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>initialData</span><span class=p>(</span><span class=n>a_h</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>initialData</span><span class=p>(</span><span class=n>b_h</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>a_d</span><span class=p>,</span><span class=n>a_h</span><span class=p>,</span><span class=n>nByte</span><span class=p>,</span><span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>b_d</span><span class=p>,</span><span class=n>b_h</span><span class=p>,</span><span class=n>nByte</span><span class=p>,</span><span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>dim3</span> <span class=n>block</span><span class=p>(</span><span class=mi>1024</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>dim3</span> <span class=n>grid</span><span class=p>(</span><span class=n>nElem</span><span class=o>/</span><span class=n>block</span><span class=p>.</span><span class=n>x</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>double</span> <span class=n>iStart</span><span class=p>,</span><span class=n>iElaps</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>iStart</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=n>sumArraysGPU</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid</span><span class=p>,</span><span class=n>block</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>a_d</span><span class=p>,</span><span class=n>b_d</span><span class=p>,</span><span class=n>res_d</span><span class=p>,</span><span class=n>offset</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaDeviceSynchronize</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=n>iElaps</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>()</span><span class=o>-</span><span class=n>iStart</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>res_from_gpu_h</span><span class=p>,</span><span class=n>res_d</span><span class=p>,</span><span class=n>nByte</span><span class=p>,</span><span class=n>cudaMemcpyDeviceToHost</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Execution configuration&lt;&lt;&lt;%d,%d&gt;&gt;&gt; Time elapsed %f sec --offset:%d </span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>grid</span><span class=p>.</span><span class=n>x</span><span class=p>,</span><span class=n>block</span><span class=p>.</span><span class=n>x</span><span class=p>,</span><span class=n>iElaps</span><span class=p>,</span><span class=n>offset</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>sumArrays</span><span class=p>(</span><span class=n>a_h</span><span class=p>,</span><span class=n>b_h</span><span class=p>,</span><span class=n>res_h</span><span class=p>,</span><span class=n>offset</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>checkResult</span><span class=p>(</span><span class=n>res_h</span><span class=p>,</span><span class=n>res_from_gpu_h</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>a_d</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>b_d</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>res_d</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>a_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>b_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>res_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>res_from_gpu_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>编译指令：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>tony@tony-Lenovo:~/Project/CUDA_Freshman/18_sum_array_offset$ nvcc -O3 -arch<span class=o>=</span>sm_35 -Xptxas -dlcm<span class=o>=</span>cg -I ../include/ sum_array_offset.cu -o sum_array_offset
</span></span></code></pre></div><p>运行结果</p><p><img loading=lazy src=./res-1.png alt=res-1></p><p><img loading=lazy src=./res-cg_nvprof.png alt=res-cg_nvprof></p><p>编译指令，启用一级缓存：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>tony@tony-Lenovo:~/Project/CUDA_Freshman/18_sum_array_offset$ nvcc -O3 -arch<span class=o>=</span>sm_35 -Xptxas -dlcm<span class=o>=</span>ca -I ../include/ sum_array_offset.cu -o sum_array_offset
</span></span></code></pre></div><p><img loading=lazy src=./res-2.png alt=res-2></p><p><img loading=lazy src=./res-ca_nvprof.png alt=res-ca_nvprof></p><p>这里我们使用的指标是：
$$
全局加载效率=\frac{请求的全局内存加载吞吐量}{所需的全局内存加载吞吐量}
$$</p><h3 id=只读缓存>只读缓存<a hidden class=anchor aria-hidden=true href=#只读缓存>#</a></h3><p>只读缓存最初是留给纹理内存加载用的，在3.5以上的设备，只读缓存也支持使用全局内存加载代替一级缓存。也就是说3.5以后的设备，可以通过只读缓存从全局内存中读数据了。
只读缓存粒度32字节，对于分散读取，细粒度优于一级缓存
有两种方法指导内存从只读缓存读取：</p><ol><li>使用函数 _ldg</li><li>在间接引用的指针上使用修饰符</li></ol><p>代码：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>copyKernel</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span> <span class=n>in</span><span class=p>,</span><span class=kt>float</span><span class=o>*</span> <span class=n>out</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx</span><span class=o>=</span><span class=n>blockDim</span><span class=o>*</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>out</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=o>=</span><span class=n>__ldg</span><span class=p>(</span><span class=o>&amp;</span><span class=n>in</span><span class=p>[</span><span class=n>idx</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>注意函数参数，然后就能强制使用只读缓存了。</p><h2 id=全局内存写入>全局内存写入<a hidden class=anchor aria-hidden=true href=#全局内存写入>#</a></h2><p>内存的写入和读取（或者叫做加载）是完全不同的，并且写入相对简单很多。一级缓存不能用在 Fermi 和 Kepler GPU上进行存储操作，发送到设备前，只经过二级缓存，存储操作在32个字节的粒度上执行，内存事物也被分为一段两端或者四段，如果两个地址在一个128字节的段内但不在64字节范围内，则会产生一个四段的事务，其他情况以此类推。
我们将内存写入也参考前面的加载分为下面这些情况：</p><ol><li><p>对齐的，访问一个连续的128字节范围。存储操作使用一个4段事务完成：
<img loading=lazy src=./4-19.png alt=4-19></p></li><li><p>分散在一个192字节的范围内，不连续，使用3个一段事务来搞定
<img loading=lazy src=./4-20.png alt=4-20></p></li><li><p>对齐的，在一个64字节的范围内，使用一个两段事务完成。
<img loading=lazy src=./4-21.png alt=4-21></p></li></ol><h3 id=非对齐写入示例>非对齐写入示例<a hidden class=anchor aria-hidden=true href=#非对齐写入示例>#</a></h3><p>与读取情况类似，且更简单，因为始终不经过一级缓存，所以略过此实验。</p><h2 id=结构体数组与数组结构体>结构体数组与数组结构体<a hidden class=anchor aria-hidden=true href=#结构体数组与数组结构体>#</a></h2><p>写过C语言的人对结构体都应该非常了解，结构体说白了就是基础数据类型组合出来的新的数据类型，这个新的数据类型在内存中表现是：结构中的成员在内存里对齐的依次排开，然后我们我们就有了接下来的话题，数组的结构体，和结构体的数组。
数组结构体（AoS）就是一个数组，每个元素都是一个结构体，而结构体数组（SoA）就是结构体中的成员是数组用代码表示：
AoS</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>struct</span> <span class=nc>A</span> <span class=n>a</span><span class=p>[</span><span class=n>N</span><span class=p>];</span>
</span></span></code></pre></div><p>SoA</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>struct</span> <span class=nc>A</span><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>a</span><span class=p>[</span><span class=n>N</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>b</span><span class=p>[</span><span class=n>N</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span><span class=n>a</span><span class=p>;</span>
</span></span></code></pre></div><p>如果你分不清这两个名字，没关系，我也分不清，记住AoS是数组就行了，CUDA对细粒度数组是非常友好的，但是对粗粒度如结构体组成的数组就不太友好了，具体表现在，内存访问利用率低。比如当一个线程要访问结构体中的某个成员的时候，当三十二个线程同时访问的时候，SoA的访问就是连续的，而AoS则是不连续：
<img loading=lazy src=./4-22.png alt=4-22>
这样看来AoS访问效率只有 $50%$
对比AoS和SoA的内存布局，我们能得到下面结论。</p><ul><li>并行编程范式，尤其是SIMD（单指令多数据）对SoA更友好。CUDA中普遍倾向于SoA因为这种内存访问可以有效地合并。</li></ul><h3 id=aos数据布局的简单数学运算>AoS数据布局的简单数学运算<a hidden class=anchor aria-hidden=true href=#aos数据布局的简单数学运算>#</a></h3><p>我们看一下AoS的例子</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;cuda_runtime.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;stdio.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&#34;freshman.h&#34;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=k>struct</span> <span class=nc>naiveStruct</span><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>a</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>b</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>};</span>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>sumArrays</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span> <span class=n>a</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>b</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>res</span><span class=p>,</span><span class=k>const</span> <span class=kt>int</span> <span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;</span><span class=n>size</span><span class=p>;</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>res</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>=</span><span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>+</span><span class=n>b</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>sumArraysGPU</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=n>a</span><span class=p>,</span><span class=kt>float</span><span class=o>*</span><span class=n>b</span><span class=p>,</span><span class=k>struct</span> <span class=nc>naiveStruct</span><span class=o>*</span> <span class=n>res</span><span class=p>,</span><span class=kt>int</span> <span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=c1>//int i=threadIdx.x;
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=kt>int</span> <span class=n>i</span><span class=o>=</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>+</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span><span class=p>(</span><span class=n>i</span><span class=o>&lt;</span><span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>res</span><span class=p>[</span><span class=n>i</span><span class=p>].</span><span class=n>a</span><span class=o>=</span><span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>+</span><span class=n>b</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>checkResult_struct</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span> <span class=n>res_h</span><span class=p>,</span><span class=k>struct</span> <span class=nc>naiveStruct</span><span class=o>*</span><span class=n>res_from_gpu_h</span><span class=p>,</span><span class=kt>int</span> <span class=n>nElem</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;</span><span class=n>nElem</span><span class=p>;</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>res_h</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>!=</span><span class=n>res_from_gpu_h</span><span class=p>[</span><span class=n>i</span><span class=p>].</span><span class=n>a</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;check fail!</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=n>exit</span><span class=p>(</span><span class=mi>0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;result check success!</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>(</span><span class=kt>int</span> <span class=n>argc</span><span class=p>,</span><span class=kt>char</span> <span class=o>**</span><span class=n>argv</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>dev</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaSetDevice</span><span class=p>(</span><span class=n>dev</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>nElem</span><span class=o>=</span><span class=mi>1</span><span class=o>&lt;&lt;</span><span class=mi>18</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>offset</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span><span class=p>(</span><span class=n>argc</span><span class=o>&gt;=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>offset</span><span class=o>=</span><span class=n>atoi</span><span class=p>(</span><span class=n>argv</span><span class=p>[</span><span class=mi>1</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>  <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Vector size:%d</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>nByte</span><span class=o>=</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)</span><span class=o>*</span><span class=n>nElem</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>nByte_struct</span><span class=o>=</span><span class=k>sizeof</span><span class=p>(</span><span class=k>struct</span> <span class=nc>naiveStruct</span><span class=p>)</span><span class=o>*</span><span class=n>nElem</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>a_h</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>b_h</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>res_h</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte_struct</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=k>struct</span> <span class=nc>naiveStruct</span> <span class=o>*</span><span class=n>res_from_gpu_h</span><span class=o>=</span><span class=p>(</span><span class=k>struct</span> <span class=nc>naiveStruct</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte_struct</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>memset</span><span class=p>(</span><span class=n>res_h</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>memset</span><span class=p>(</span><span class=n>res_from_gpu_h</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>a_d</span><span class=p>,</span><span class=o>*</span><span class=n>b_d</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>struct</span> <span class=nc>naiveStruct</span><span class=o>*</span> <span class=n>res_d</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>float</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>a_d</span><span class=p>,</span><span class=n>nByte</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>float</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>b_d</span><span class=p>,</span><span class=n>nByte</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMalloc</span><span class=p>((</span><span class=k>struct</span> <span class=nc>naiveStruct</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>res_d</span><span class=p>,</span><span class=n>nByte_struct</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemset</span><span class=p>(</span><span class=n>res_d</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=n>nByte_struct</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>initialData</span><span class=p>(</span><span class=n>a_h</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>initialData</span><span class=p>(</span><span class=n>b_h</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>a_d</span><span class=p>,</span><span class=n>a_h</span><span class=p>,</span><span class=n>nByte</span><span class=p>,</span><span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>b_d</span><span class=p>,</span><span class=n>b_h</span><span class=p>,</span><span class=n>nByte</span><span class=p>,</span><span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>dim3</span> <span class=n>block</span><span class=p>(</span><span class=mi>1024</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>dim3</span> <span class=n>grid</span><span class=p>(</span><span class=n>nElem</span><span class=o>/</span><span class=n>block</span><span class=p>.</span><span class=n>x</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>double</span> <span class=n>iStart</span><span class=p>,</span><span class=n>iElaps</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>iStart</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=n>sumArraysGPU</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid</span><span class=p>,</span><span class=n>block</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>a_d</span><span class=p>,</span><span class=n>b_d</span><span class=p>,</span><span class=n>res_d</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaDeviceSynchronize</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=n>iElaps</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>()</span><span class=o>-</span><span class=n>iStart</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>res_from_gpu_h</span><span class=p>,</span><span class=n>res_d</span><span class=p>,</span><span class=n>nByte_struct</span><span class=p>,</span><span class=n>cudaMemcpyDeviceToHost</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Execution configuration&lt;&lt;&lt;%d,%d&gt;&gt;&gt; Time elapsed %f sec</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>grid</span><span class=p>.</span><span class=n>x</span><span class=p>,</span><span class=n>block</span><span class=p>.</span><span class=n>x</span><span class=p>,</span><span class=n>iElaps</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>sumArrays</span><span class=p>(</span><span class=n>a_h</span><span class=p>,</span><span class=n>b_h</span><span class=p>,</span><span class=n>res_h</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>checkResult_struct</span><span class=p>(</span><span class=n>res_h</span><span class=p>,</span><span class=n>res_from_gpu_h</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>a_d</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>b_d</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>res_d</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>a_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>b_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>res_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>res_from_gpu_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>nvcc -O3 -arch<span class=o>=</span>sm_35 -Xptxas -dlcm<span class=o>=</span>ca -I ../include/ AoS.cu -o  AoS
</span></span></code></pre></div><p><img loading=lazy src=./aos.png alt=AoS></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>nvcc -O3 -arch<span class=o>=</span>sm_35 -Xptxas -dlcm<span class=o>=</span>cg -I ../include/ AoS.cu -o  AoS
</span></span></code></pre></div><p><img loading=lazy src=./aos2.png alt=AoS2></p><h3 id=soa数据布局的简单数学运算>SoA数据布局的简单数学运算<a hidden class=anchor aria-hidden=true href=#soa数据布局的简单数学运算>#</a></h3><p>然后看SoA的例子</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;cuda_runtime.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;stdio.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&#34;freshman.h&#34;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>sumArrays</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span> <span class=n>a</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>b</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>res</span><span class=p>,</span><span class=kt>int</span> <span class=n>offset</span><span class=p>,</span><span class=k>const</span> <span class=kt>int</span> <span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span><span class=n>k</span><span class=o>=</span><span class=n>offset</span><span class=p>;</span><span class=n>k</span><span class=o>&lt;</span><span class=n>size</span><span class=p>;</span><span class=n>i</span><span class=o>++</span><span class=p>,</span><span class=n>k</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>res</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>=</span><span class=n>a</span><span class=p>[</span><span class=n>k</span><span class=p>]</span><span class=o>+</span><span class=n>b</span><span class=p>[</span><span class=n>k</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>sumArraysGPU</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=n>a</span><span class=p>,</span><span class=kt>float</span><span class=o>*</span><span class=n>b</span><span class=p>,</span><span class=kt>float</span><span class=o>*</span><span class=n>res</span><span class=p>,</span><span class=kt>int</span> <span class=n>offset</span><span class=p>,</span><span class=kt>int</span> <span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=c1>//int i=threadIdx.x;
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=kt>int</span> <span class=n>i</span><span class=o>=</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>4</span><span class=o>+</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>k</span><span class=o>=</span><span class=n>i</span><span class=o>+</span><span class=n>offset</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span><span class=p>(</span><span class=n>k</span><span class=o>+</span><span class=mi>3</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>&lt;</span><span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=n>res</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>=</span><span class=n>a</span><span class=p>[</span><span class=n>k</span><span class=p>]</span><span class=o>+</span><span class=n>b</span><span class=p>[</span><span class=n>k</span><span class=p>];</span>
</span></span><span class=line><span class=cl>      <span class=n>res</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>=</span><span class=n>a</span><span class=p>[</span><span class=n>k</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>+</span><span class=n>b</span><span class=p>[</span><span class=n>k</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>];</span>
</span></span><span class=line><span class=cl>      <span class=n>res</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>2</span><span class=p>]</span><span class=o>=</span><span class=n>a</span><span class=p>[</span><span class=n>k</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>2</span><span class=p>]</span><span class=o>+</span><span class=n>b</span><span class=p>[</span><span class=n>k</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>2</span><span class=p>];</span>
</span></span><span class=line><span class=cl>      <span class=n>res</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>3</span><span class=p>]</span><span class=o>=</span><span class=n>a</span><span class=p>[</span><span class=n>k</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>3</span><span class=p>]</span><span class=o>+</span><span class=n>b</span><span class=p>[</span><span class=n>k</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>3</span><span class=p>];</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>(</span><span class=kt>int</span> <span class=n>argc</span><span class=p>,</span><span class=kt>char</span> <span class=o>**</span><span class=n>argv</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>dev</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaSetDevice</span><span class=p>(</span><span class=n>dev</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>block_x</span><span class=o>=</span><span class=mi>512</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>nElem</span><span class=o>=</span><span class=mi>1</span><span class=o>&lt;&lt;</span><span class=mi>18</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>offset</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span><span class=p>(</span><span class=n>argc</span><span class=o>==</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>offset</span><span class=o>=</span><span class=n>atoi</span><span class=p>(</span><span class=n>argv</span><span class=p>[</span><span class=mi>1</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>  <span class=k>else</span> <span class=k>if</span><span class=p>(</span><span class=n>argc</span><span class=o>==</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>offset</span><span class=o>=</span><span class=n>atoi</span><span class=p>(</span><span class=n>argv</span><span class=p>[</span><span class=mi>1</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>        <span class=n>block_x</span><span class=o>=</span><span class=n>atoi</span><span class=p>(</span><span class=n>argv</span><span class=p>[</span><span class=mi>2</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Vector size:%d</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>nByte</span><span class=o>=</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)</span><span class=o>*</span><span class=n>nElem</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>a_h</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>b_h</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>res_h</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>res_from_gpu_h</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>memset</span><span class=p>(</span><span class=n>res_h</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>memset</span><span class=p>(</span><span class=n>res_from_gpu_h</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>a_d</span><span class=p>,</span><span class=o>*</span><span class=n>b_d</span><span class=p>,</span><span class=o>*</span><span class=n>res_d</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>float</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>a_d</span><span class=p>,</span><span class=n>nByte</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>float</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>b_d</span><span class=p>,</span><span class=n>nByte</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>float</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>res_d</span><span class=p>,</span><span class=n>nByte</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemset</span><span class=p>(</span><span class=n>res_d</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=n>nByte</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>initialData</span><span class=p>(</span><span class=n>a_h</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>initialData</span><span class=p>(</span><span class=n>b_h</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>a_d</span><span class=p>,</span><span class=n>a_h</span><span class=p>,</span><span class=n>nByte</span><span class=p>,</span><span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>b_d</span><span class=p>,</span><span class=n>b_h</span><span class=p>,</span><span class=n>nByte</span><span class=p>,</span><span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>dim3</span> <span class=n>block</span><span class=p>(</span><span class=n>block_x</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>dim3</span> <span class=n>grid</span><span class=p>(</span><span class=n>nElem</span><span class=o>/</span><span class=n>block</span><span class=p>.</span><span class=n>x</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>double</span> <span class=n>iStart</span><span class=p>,</span><span class=n>iElaps</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>iStart</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=n>sumArraysGPU</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid</span><span class=p>,</span><span class=n>block</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>a_d</span><span class=p>,</span><span class=n>b_d</span><span class=p>,</span><span class=n>res_d</span><span class=p>,</span><span class=n>offset</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaDeviceSynchronize</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=n>iElaps</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>()</span><span class=o>-</span><span class=n>iStart</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>printf</span><span class=p>(</span><span class=s>&#34;warmup Time elapsed %f sec</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>iElaps</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>iStart</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=n>sumArraysGPU</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid</span><span class=p>,</span><span class=n>block</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>a_d</span><span class=p>,</span><span class=n>b_d</span><span class=p>,</span><span class=n>res_d</span><span class=p>,</span><span class=n>offset</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaDeviceSynchronize</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=n>iElaps</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>()</span><span class=o>-</span><span class=n>iStart</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>res_from_gpu_h</span><span class=p>,</span><span class=n>res_d</span><span class=p>,</span><span class=n>nByte</span><span class=p>,</span><span class=n>cudaMemcpyDeviceToHost</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Execution configuration&lt;&lt;&lt;%d,%d&gt;&gt;&gt; Time elapsed %f sec --offset:%d </span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>grid</span><span class=p>.</span><span class=n>x</span><span class=p>,</span><span class=n>block</span><span class=p>.</span><span class=n>x</span><span class=p>,</span><span class=n>iElaps</span><span class=p>,</span><span class=n>offset</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>sumArrays</span><span class=p>(</span><span class=n>a_h</span><span class=p>,</span><span class=n>b_h</span><span class=p>,</span><span class=n>res_h</span><span class=p>,</span><span class=n>offset</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>checkResult</span><span class=p>(</span><span class=n>res_h</span><span class=p>,</span><span class=n>res_from_gpu_h</span><span class=p>,</span><span class=n>nElem</span><span class=o>-</span><span class=mi>4</span><span class=o>*</span><span class=n>block_x</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>a_d</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>b_d</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>res_d</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>a_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>b_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>res_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>res_from_gpu_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>nvcc -O3 -arch<span class=o>=</span>sm_35 -Xptxas -dlcm<span class=o>=</span>ca -I ../include/ SoA.cu -o SoA
</span></span></code></pre></div><p><img loading=lazy src=./soa-ca.png alt=SoA-ca></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>nvcc -O3 -arch<span class=o>=</span>sm_35 -Xptxas -dlcm<span class=o>=</span>cg -I ../include/ SoA.cu -o SoA
</span></span></code></pre></div><p><img loading=lazy src=./soa-cg.png alt=SoA-cg></p><h2 id=性能调整>性能调整<a hidden class=anchor aria-hidden=true href=#性能调整>#</a></h2><p>优化设备内存带宽利用率有两个目标：</p><ol><li>对齐合并内存访问，以减少带宽的浪费</li><li>足够的并发内存操作，以隐藏内存延迟</li></ol><p>第三章我们讲过优化指令吞吐量的核函数，实现并发内存访问量最大化是通过以下方式得到的：</p><ol><li>增加每个线程中执行独立内存操作的数量</li><li>对核函数启动的执行配置进行试验，已充分体现每个SM的并行性</li></ol><p>接下来我们就按照这个思路对程序进行优化试验：展开技术和增大并行性。</p><h3 id=展开技术>展开技术<a hidden class=anchor aria-hidden=true href=#展开技术>#</a></h3><p>把前面讲到的展开技术用到向量加法上，我们来看看其对内存效率的影响：
代码</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;cuda_runtime.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;stdio.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&#34;freshman.h&#34;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>sumArrays</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span> <span class=n>a</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>b</span><span class=p>,</span><span class=kt>float</span> <span class=o>*</span> <span class=n>res</span><span class=p>,</span><span class=kt>int</span> <span class=n>offset</span><span class=p>,</span><span class=k>const</span> <span class=kt>int</span> <span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span><span class=n>k</span><span class=o>=</span><span class=n>offset</span><span class=p>;</span><span class=n>k</span><span class=o>&lt;</span><span class=n>size</span><span class=p>;</span><span class=n>i</span><span class=o>++</span><span class=p>,</span><span class=n>k</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>res</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>=</span><span class=n>a</span><span class=p>[</span><span class=n>k</span><span class=p>]</span><span class=o>+</span><span class=n>b</span><span class=p>[</span><span class=n>k</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>sumArraysGPU</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=n>a</span><span class=p>,</span><span class=kt>float</span><span class=o>*</span><span class=n>b</span><span class=p>,</span><span class=kt>float</span><span class=o>*</span><span class=n>res</span><span class=p>,</span><span class=kt>int</span> <span class=n>offset</span><span class=p>,</span><span class=kt>int</span> <span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=c1>//int i=threadIdx.x;
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=kt>int</span> <span class=n>i</span><span class=o>=</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>4</span><span class=o>+</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>k</span><span class=o>=</span><span class=n>i</span><span class=o>+</span><span class=n>offset</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span><span class=p>(</span><span class=n>k</span><span class=o>+</span><span class=mi>3</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>&lt;</span><span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=n>res</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>=</span><span class=n>a</span><span class=p>[</span><span class=n>k</span><span class=p>]</span><span class=o>+</span><span class=n>b</span><span class=p>[</span><span class=n>k</span><span class=p>];</span>
</span></span><span class=line><span class=cl>      <span class=n>res</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>=</span><span class=n>a</span><span class=p>[</span><span class=n>k</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>]</span><span class=o>+</span><span class=n>b</span><span class=p>[</span><span class=n>k</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>];</span>
</span></span><span class=line><span class=cl>      <span class=n>res</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>2</span><span class=p>]</span><span class=o>=</span><span class=n>a</span><span class=p>[</span><span class=n>k</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>2</span><span class=p>]</span><span class=o>+</span><span class=n>b</span><span class=p>[</span><span class=n>k</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>2</span><span class=p>];</span>
</span></span><span class=line><span class=cl>      <span class=n>res</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>3</span><span class=p>]</span><span class=o>=</span><span class=n>a</span><span class=p>[</span><span class=n>k</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>3</span><span class=p>]</span><span class=o>+</span><span class=n>b</span><span class=p>[</span><span class=n>k</span><span class=o>+</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=mi>3</span><span class=p>];</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>(</span><span class=kt>int</span> <span class=n>argc</span><span class=p>,</span><span class=kt>char</span> <span class=o>**</span><span class=n>argv</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>dev</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaSetDevice</span><span class=p>(</span><span class=n>dev</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>block_x</span><span class=o>=</span><span class=mi>512</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>nElem</span><span class=o>=</span><span class=mi>1</span><span class=o>&lt;&lt;</span><span class=mi>18</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>offset</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span><span class=p>(</span><span class=n>argc</span><span class=o>==</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>offset</span><span class=o>=</span><span class=n>atoi</span><span class=p>(</span><span class=n>argv</span><span class=p>[</span><span class=mi>1</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>  <span class=k>else</span> <span class=k>if</span><span class=p>(</span><span class=n>argc</span><span class=o>==</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>offset</span><span class=o>=</span><span class=n>atoi</span><span class=p>(</span><span class=n>argv</span><span class=p>[</span><span class=mi>1</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>        <span class=n>block_x</span><span class=o>=</span><span class=n>atoi</span><span class=p>(</span><span class=n>argv</span><span class=p>[</span><span class=mi>2</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Vector size:%d</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>nByte</span><span class=o>=</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)</span><span class=o>*</span><span class=n>nElem</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>a_h</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>b_h</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>res_h</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>res_from_gpu_h</span><span class=o>=</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>malloc</span><span class=p>(</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>memset</span><span class=p>(</span><span class=n>res_h</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>memset</span><span class=p>(</span><span class=n>res_from_gpu_h</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=n>nByte</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=kt>float</span> <span class=o>*</span><span class=n>a_d</span><span class=p>,</span><span class=o>*</span><span class=n>b_d</span><span class=p>,</span><span class=o>*</span><span class=n>res_d</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>float</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>a_d</span><span class=p>,</span><span class=n>nByte</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>float</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>b_d</span><span class=p>,</span><span class=n>nByte</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMalloc</span><span class=p>((</span><span class=kt>float</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>res_d</span><span class=p>,</span><span class=n>nByte</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemset</span><span class=p>(</span><span class=n>res_d</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=n>nByte</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>initialData</span><span class=p>(</span><span class=n>a_h</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>initialData</span><span class=p>(</span><span class=n>b_h</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>a_d</span><span class=p>,</span><span class=n>a_h</span><span class=p>,</span><span class=n>nByte</span><span class=p>,</span><span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>b_d</span><span class=p>,</span><span class=n>b_h</span><span class=p>,</span><span class=n>nByte</span><span class=p>,</span><span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>dim3</span> <span class=n>block</span><span class=p>(</span><span class=n>block_x</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>dim3</span> <span class=n>grid</span><span class=p>(</span><span class=n>nElem</span><span class=o>/</span><span class=n>block</span><span class=p>.</span><span class=n>x</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>double</span> <span class=n>iStart</span><span class=p>,</span><span class=n>iElaps</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>iStart</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=n>sumArraysGPU</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid</span><span class=p>,</span><span class=n>block</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>a_d</span><span class=p>,</span><span class=n>b_d</span><span class=p>,</span><span class=n>res_d</span><span class=p>,</span><span class=n>offset</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaDeviceSynchronize</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=n>iElaps</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>()</span><span class=o>-</span><span class=n>iStart</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>printf</span><span class=p>(</span><span class=s>&#34;warmup Time elapsed %f sec</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>iElaps</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>iStart</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=n>sumArraysGPU</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid</span><span class=p>,</span><span class=n>block</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>a_d</span><span class=p>,</span><span class=n>b_d</span><span class=p>,</span><span class=n>res_d</span><span class=p>,</span><span class=n>offset</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaDeviceSynchronize</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=n>iElaps</span><span class=o>=</span><span class=n>cpuSecond</span><span class=p>()</span><span class=o>-</span><span class=n>iStart</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>CHECK</span><span class=p>(</span><span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>res_from_gpu_h</span><span class=p>,</span><span class=n>res_d</span><span class=p>,</span><span class=n>nByte</span><span class=p>,</span><span class=n>cudaMemcpyDeviceToHost</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Execution configuration&lt;&lt;&lt;%d,%d&gt;&gt;&gt; Time elapsed %f sec --offset:%d </span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>grid</span><span class=p>.</span><span class=n>x</span><span class=p>,</span><span class=n>block</span><span class=p>.</span><span class=n>x</span><span class=p>,</span><span class=n>iElaps</span><span class=p>,</span><span class=n>offset</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>sumArrays</span><span class=p>(</span><span class=n>a_h</span><span class=p>,</span><span class=n>b_h</span><span class=p>,</span><span class=n>res_h</span><span class=p>,</span><span class=n>offset</span><span class=p>,</span><span class=n>nElem</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>checkResult</span><span class=p>(</span><span class=n>res_h</span><span class=p>,</span><span class=n>res_from_gpu_h</span><span class=p>,</span><span class=n>nElem</span><span class=o>-</span><span class=mi>4</span><span class=o>*</span><span class=n>block_x</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>a_d</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>b_d</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>res_d</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>a_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>b_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>res_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>free</span><span class=p>(</span><span class=n>res_from_gpu_h</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>编译指令。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>nvcc -O3 sum_array_offset_unrolling.cu -o sum_array_offset_unrolling -arch<span class=o>=</span>sm_35 -Xptxas -dlcm<span class=o>=</span>cg -I ../include/
</span></span></code></pre></div><p><img loading=lazy src=./unrolling-1.png alt=unrolling-1></p><p>nvprof 内存效率</p><p><img loading=lazy src=./unrolling-nv.png alt=unrolling-nv></p><h3 id=增大并行性>增大并行性<a hidden class=anchor aria-hidden=true href=#增大并行性>#</a></h3><p>通过调整块的大小来实现并行性调整，也是前面讲过的套路，我们关注的还是内存利用效率
代码同上面的展开技术。
<img loading=lazy src=./res-block.png alt=res-block></p><p>offset=11的时候</p><p><img loading=lazy src=./res-off-set-11.png alt=res-off-set-11></p><p>由于数据量少，所以时间差距不大，512有最佳速度，不仅因为内存，还有并行性等多方面因素，这个前面我们也曾提到过。要看综合能力。</p><p>本文全部代码都在Github上有完整版，请访问：<a href=https://github.com/Tony-Tan/CUDA_Freshman>https://github.com/Tony-Tan/CUDA_Freshman</a></p><h2 id=总结>总结<a hidden class=anchor aria-hidden=true href=#总结>#</a></h2><p>这是我今年写作时间最长的一篇博客，写了三天，主要是代码比较多，结果也比较多
这里我们没用Cmake，而是用的指令，原因是方便修改编译选项，试验时间结果不明显的原因是数据量小，部分结果和书上不一致，主要是书的时间比较久了，GPU换代太快。
全局内存本篇算是比较完整了，后面还有其他内存知识，我们继续。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://go.face2ai.com/tags/%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/>内存访问模式</a></li><li><a href=https://go.face2ai.com/tags/%E5%AF%B9%E9%BD%90/>对齐</a></li><li><a href=https://go.face2ai.com/tags/%E5%90%88%E5%B9%B6/>合并</a></li><li><a href=https://go.face2ai.com/tags/%E7%BC%93%E5%AD%98/>缓存</a></li><li><a href=https://go.face2ai.com/tags/%E7%BB%93%E6%9E%84%E4%BD%93%E6%95%B0%E7%BB%84/>结构体数组</a></li><li><a href=https://go.face2ai.com/tags/%E6%95%B0%E7%BB%84%E7%BB%93%E6%9E%84%E4%BD%93/>数组结构体</a></li></ul><nav class=paginav><a class=prev href=https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-4-4-%E6%A0%B8%E5%87%BD%E6%95%B0%E5%8F%AF%E8%BE%BE%E5%88%B0%E7%9A%84%E5%B8%A6%E5%AE%BD.zh/><span class=title>« Prev</span><br><span>【CUDA 基础】4.4 核函数可达到的带宽</span></a>
<a class=next href=https://go.face2ai.com/%E7%BC%96%E7%A8%8B/cuda/cuda-f-4-2-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86.zh/><span class=title>Next »</span><br><span>【CUDA 基础】4.2 内存管理</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】4.3 内存访问模式 on twitter" href="https://twitter.com/intent/tweet/?text=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%914.3%20%e5%86%85%e5%ad%98%e8%ae%bf%e9%97%ae%e6%a8%a1%e5%bc%8f&url=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-4-3-%25E5%2586%2585%25E5%25AD%2598%25E8%25AE%25BF%25E9%2597%25AE%25E6%25A8%25A1%25E5%25BC%258F.zh%2f&hashtags=%e5%86%85%e5%ad%98%e8%ae%bf%e9%97%ae%e6%a8%a1%e5%bc%8f%2c%e5%af%b9%e9%bd%90%2c%e5%90%88%e5%b9%b6%2c%e7%bc%93%e5%ad%98%2c%e7%bb%93%e6%9e%84%e4%bd%93%e6%95%b0%e7%bb%84%2c%e6%95%b0%e7%bb%84%e7%bb%93%e6%9e%84%e4%bd%93"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】4.3 内存访问模式 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-4-3-%25E5%2586%2585%25E5%25AD%2598%25E8%25AE%25BF%25E9%2597%25AE%25E6%25A8%25A1%25E5%25BC%258F.zh%2f&title=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%914.3%20%e5%86%85%e5%ad%98%e8%ae%bf%e9%97%ae%e6%a8%a1%e5%bc%8f&summary=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%914.3%20%e5%86%85%e5%ad%98%e8%ae%bf%e9%97%ae%e6%a8%a1%e5%bc%8f&source=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-4-3-%25E5%2586%2585%25E5%25AD%2598%25E8%25AE%25BF%25E9%2597%25AE%25E6%25A8%25A1%25E5%25BC%258F.zh%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】4.3 内存访问模式 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-4-3-%25E5%2586%2585%25E5%25AD%2598%25E8%25AE%25BF%25E9%2597%25AE%25E6%25A8%25A1%25E5%25BC%258F.zh%2f&title=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%914.3%20%e5%86%85%e5%ad%98%e8%ae%bf%e9%97%ae%e6%a8%a1%e5%bc%8f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】4.3 内存访问模式 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-4-3-%25E5%2586%2585%25E5%25AD%2598%25E8%25AE%25BF%25E9%2597%25AE%25E6%25A8%25A1%25E5%25BC%258F.zh%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】4.3 内存访问模式 on whatsapp" href="https://api.whatsapp.com/send?text=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%914.3%20%e5%86%85%e5%ad%98%e8%ae%bf%e9%97%ae%e6%a8%a1%e5%bc%8f%20-%20https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-4-3-%25E5%2586%2585%25E5%25AD%2598%25E8%25AE%25BF%25E9%2597%25AE%25E6%25A8%25A1%25E5%25BC%258F.zh%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 【CUDA 基础】4.3 内存访问模式 on telegram" href="https://telegram.me/share/url?text=%e3%80%90CUDA%20%e5%9f%ba%e7%a1%80%e3%80%914.3%20%e5%86%85%e5%ad%98%e8%ae%bf%e9%97%ae%e6%a8%a1%e5%bc%8f&url=https%3a%2f%2fgo.face2ai.com%2f%25E7%25BC%2596%25E7%25A8%258B%2fcuda%2fcuda-f-4-3-%25E5%2586%2585%25E5%25AD%2598%25E8%25AE%25BF%25E9%2597%25AE%25E6%25A8%25A1%25E5%25BC%258F.zh%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://go.face2ai.com>谭升的博客</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerHTML="copy";function s(){e.innerHTML="copied!",setTimeout(()=>{e.innerHTML="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>