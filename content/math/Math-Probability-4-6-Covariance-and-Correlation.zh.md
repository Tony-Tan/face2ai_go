---
title: ã€æ¦‚ç‡è®ºã€‘4-6:åæ–¹å·®å’Œç›¸å…³æ€§(Covariance and Correlation)
categories:
    - Mathematic
    - Probability
tags:
    - åæ–¹å·®
    - ç›¸å…³æ€§
toc: true
date: 2018-03-26 10:44:07
---

**Abstract:** æœ¬æ–‡ä»‹ç»åæ–¹å·®å’Œç›¸å…³æ€§çš„åŸºç¡€çŸ¥è¯†ï¼Œä»¥åŠéƒ¨åˆ†æ€§è´¨
**Keywords:** Covariance,Correlation,Properties of Covariance and Correlation

<!--more-->
# åæ–¹å·®å’Œç›¸å…³æ€§
æ¦‚ç‡è®ºåŸºç¡€çŸ¥è¯†ï¼ŒåŸºç¡€å·¥å…·å·²ç»è¿›å…¥åˆ°ååŠéƒ¨åˆ†äº†ï¼Œæ¥ä¸‹æ¥åé¢å°±æ˜¯å¯¹ç‰¹å®šåˆ†å¸ƒçš„ç ”ç©¶å’Œåˆ†æäº†ï¼Œä½¿ç”¨çš„å·¥å…·å°±æ˜¯æˆ‘ä»¬å·²ç»ä»‹ç»è¿‡çš„è¿™äº›çŸ¥è¯†ï¼Œèæ±‡è´¯é€šæ˜¯æ‰€æœ‰çŸ¥è¯†å­¦ä¹ çš„å”¯ä¸€è€ƒé‡ï¼ŒæŒæ¡çš„çŸ¥è¯†ç‚¹å¦‚æœä¸èƒ½èå…¥ä½“ç³»ï¼Œä¸€ä¸ªæœˆåå°±ç›¸å½“äºæ²¡å­¦è¿‡ï¼Œä½†æ˜¯æˆä½“ç³»çš„çŸ¥è¯†ä¸åŒï¼Œåªè¦æœ‰ä¸€ä¸ªæ ¹èŠ‚ç‚¹ï¼Œå°±èƒ½è”ç³»åˆ°æ•´ä¸ªä¸€é¢—çŸ¥è¯†æ ‘ã€‚

> ä¸€æ¯æ•¬æœé˜³ï¼Œä¸€æ¯æ•¬æœˆå…‰

æˆ‘ä»¬å‰é¢å‡ ä¸ªé‡è¦çš„æ•°å­—ç‰¹å¾é’ˆå¯¹çš„åŸºæœ¬éƒ½æ˜¯å•ä¸€éšæœºå˜é‡ï¼Œæˆ‘ä»¬å¾ˆæ¸…æ¥šï¼Œæˆ‘ä»¬åœ¨å®é™…æ“ä½œä¸­é¢å¯¹çš„åŸºæœ¬éƒ½æ˜¯å¤šéšæœºå˜é‡çš„è”åˆåˆ†å¸ƒï¼Œé‚£ä¹ˆæˆ‘ä»¬æ¥ä¸‹æ¥å°±æƒ³ç ”ç©¶ä¸‹ï¼Œä¸¤ä¸ªæˆ–è€…å¤šä¸ªéšæœºå˜é‡ä¹‹é—´æ˜¯æ€ä¹ˆäº’ç›¸å½±å“çš„ã€‚
åæ–¹å·®(Covariance)ï¼Œç›¸å…³æ€§(Correlation)æ˜¯åº¦é‡éšæœºå˜é‡é—´ç‹¬ç«‹æ€§çš„ä¸€ç§æ•°å­—ç‰¹å¾ï¼Œä½†æ˜¯å¿…é¡»æ³¨æ„ï¼Œè¿™ä¸¤ä¸ªæ•°å­—ç‰¹å¾åº¦é‡çš„æ˜¯éšæœºå˜é‡ä¹‹é—´çš„ **çº¿æ€§ç›¸å…³ç¨‹åº¦** ï¼Œè¿™é‡Œè¦å¥½å¥½æ³¨æ„ä¸€ä¸‹ï¼çº¿æ€§ç›¸å…³ç¨‹åº¦ã€‚
æ³¨æ„ï¼Œåæ–¹å·®å’Œç›¸å…³æ€§ï¼Œåªåˆ»ç”»çº¿æ€§ç›¸å…³ç¨‹åº¦ï¼
## åæ–¹å·® Covariance
å½“æˆ‘ä»¬å°†éšæœºå˜é‡ä»ä¸€ä¸ªæ‰©å±•åˆ°å¤šä¸ªï¼Œå‰é¢æåˆ°çš„æœŸæœ›ï¼Œæ–¹å·®ï¼Œä¸­å€¼ç­‰è¿™äº›é’ˆå¯¹å•ä¸ªéšæœºå˜é‡çš„æ•°å­—ç‰¹å¾å°±åªèƒ½åˆ»ç”»è”åˆåˆ†å¸ƒçš„æŸä¸€è¾¹ç¼˜åˆ†å¸ƒçš„æ€§è´¨äº†ã€‚æ‰€ä»¥æˆ‘ä»¬æå‡ºäº†æ–°çš„æ•°å­—ç‰¹å¾ï¼Œè¿™ä¸ªæ•°å­—ç‰¹å¾èƒ½æè¿°ä¸¤ä¸ªéšæœºå˜é‡ä¹‹é—´æœ‰æ²¡æœ‰å˜åŒ–ä¸Šçš„å…³ç³»ï¼Œæ¯”å¦‚ä»–ä»¬ç»å¸¸åŒæ—¶å˜å¤§æˆ–è€…å˜å°ï¼Œæˆ–è€…æ€»æ˜¯ä¸€ä¸ªå˜å¤§å¦ä¸€ä¸ªå˜å°ï¼Œè¿™ç§å…³è”çš„å…³ç³»ã€‚
é€šè¿‡è¿™ç§æ•°å­—ç‰¹å¾ï¼Œæˆ‘ä»¬èƒ½å¤Ÿåœ¨æ±‚å‡ºè‹¥å¹²ä¸ªè¿™ç§å˜é‡çš„æ–¹å·®ï¼Œä»¥åŠé€šè¿‡å·²ç»å¾—åˆ°çš„å‡ ä¸ªéšæœºå˜é‡çš„ç»“æœæ¥é¢„æµ‹å…¶ä»–å‡ ä¸ªã€‚å¦‚æœç¡®å®šäº†è¿™å‡ ä¸ªéšæœºå˜é‡ä¹‹é—´çš„å…³è”ï¼Œè¿™äº›ä¼¼ä¹éƒ½æ˜¯å¯è¡Œçš„ã€‚

>Definition Covariance. Let $X$ and $Y$ be random variables having finite means.Let $E(X)=\mu_X$ and $E(Y)=\mu_Y$ The covariance of X and Y,which is denoted by $Cov(X,Y)$ ,is defined as
$$
Cov(X,Y)=E[(X-\mu_X)(Y-\mu_Y)]
$$
if the expectation exists.

æ²¡é”™æˆ‘ä»¬æœ¬ç« å°±æ˜¯åœ¨ç ”ç©¶æœŸæœ›ï¼Œæ‰€ä»¥ï¼Œæœ¬ç« æ‰€æœ‰çš„æ•°å­—ç‰¹å¾éƒ½æ¥è‡ªæœŸæœ›ï¼ŒæœŸæœ›çš„å­˜åœ¨æ€§ä¹Ÿå·¦å³äº†è¿™äº›æ•°å­—ç‰¹å¾çš„å­˜åœ¨æ€§ã€‚
å¦‚æœ X å’ŒYçš„éƒ½æœ‰æœ‰é™çš„æ–¹å·®ï¼Œé‚£ä¹ˆæœŸæœ›å­˜åœ¨ï¼Œå¹¶ä¸” $Cov(X,Y)$  å­˜åœ¨ä¸”æœ‰é™ï¼Œä½†æ˜¯æ­£è´Ÿä¸å—é™åˆ¶ï¼Œå¯ä»¥æ˜¯æ­£æ•°ï¼Œè´Ÿæ•°ï¼Œ0

--------------
ä¸¾ä¸ªğŸŒ° ï¼š
å·²çŸ¥éšæœºå˜é‡ $X$  å’Œ $Y$ æœ‰è”åˆp.d.f.
$$
f(x,y)=
\begin{cases}
2xy+0.5&\text{ for } 0\leq x\leq 1 \text{ and } 0\leq y\leq 1\\
0&\text{otherwise}
\end{cases}
$$
æˆ‘ä»¬æ¥è®¡ç®— $X$ å’Œ $Y$ çš„åæ–¹å·®ã€‚

--------------

é¦–å…ˆæˆ‘ä»¬è¦åšçš„æ˜¯è®¡ç®—å‡å€¼ï¼Œæ±‚ $\mu_X,\mu_Y$

$$
\begin{aligned}
\mu_X&=\int^{1}_{0}\int^{1}_{0}[2x^2y+0.5x]dydx\\
&=\int^{1}_{0}[x^2+0.5x]dx\\
&=\frac{7}{12}
\end{aligned}
$$

åŒç†å¯ä»¥æ±‚å‡º $\mu_Y=\frac{7}{12}$
æ¥ä¸‹æ¥å°±æ˜¯æ±‚åæ–¹å·®äº†:
$$
\int^{1}_{0}\int^{1}_{0}(x-\frac{7}{12})(y-\frac{7}{12})(2xy+0.5)dydx
$$
æ±‚ç§¯åˆ†å°±ä¸å†™äº†ï¼Œå¾ˆç®€å•ï¼Œç»“æœæ˜¯ $Cov(X,Y)=\frac{1}{144}$

æŒ‰ç…§å®šä¹‰ç®—è‚¯å®šä¸æ˜¯æœ€ä¼˜çš„ï¼Œæœ‰ä¸€ä¸ªå…¬ç†å¥½åƒæ˜¯è¯´ä½ æ°¸è¿œä¸èƒ½ä¸€ä¸‹å°±æ‰¾åˆ°æœ€ä¼˜æ–¹æ³•ã€‚è®¡ç®—åæ–¹å·®ä¹Ÿæ˜¯ä¸€æ ·çš„ã€‚

>Theorem For all random variables X and Y such that  $\sigma^2_{X}<\infty$ and $\sigma^2_{Y}<\infty$ ,
$$
Cov(X,Y)=E(XY)-E(X)E(Y)
$$

è¿™ä¸ªå®šç†æ˜¯è¯´å½“ä¸¤ä¸ªéšæœºå˜é‡éƒ½æœ‰æ–¹å·®çš„æ—¶å€™ï¼Œä»–ä»¬çš„è”åˆåˆ†å¸ƒçš„åæ–¹å·®å¯ä»¥ç”¨ä»–ä»¬çš„æœŸæœ›æ¥æ±‚å¾—ï¼Œè¿™æ˜¯ä¸ªå®šç†ï¼Œå®šç†éƒ½æ˜¯å¯ä»¥è¢«è¯æ˜ï¼ˆå®šä¹‰ä¸è¡Œï¼‰
è¯æ˜ï¼š
$$
\begin{aligned}
Cov(X,Y)&=E(XY-\mu_X Y-\mu_Y X + \mu_X\mu_Y)\\
&=E(XY)-\mu_X E(Y)-\mu_y E(X) + \mu_X\mu_Y)\\
\end{aligned}
$$
å°±å¾—åˆ°äº†ä¸Šé¢å®šç†çš„ç»“è®ºï¼Œè¯æ˜è¿‡ç¨‹éå¸¸ç®€å•ã€‚

åæ–¹å·®çš„çš„ä¸»è¦ç”¨é€”å°±æ˜¯æ¥åˆ»ç”»ä¸¤ä¸ªæˆ–è€…å¤šä¸ªå˜é‡çš„ç›¸å…³ç¨‹åº¦ï¼Œæ¯”å¦‚ä¸¤ä¸ªéšæœºå˜é‡åŒæ—¶éƒ½å˜å¤§æˆ–è€…åŒæ—¶éƒ½å˜å°ï¼Œæˆ–è€…ä¸€ä¸ªå˜å¤§ä¸€ä¸ªå˜å°ã€‚
è§‚å¯Ÿå®šä¹‰æˆ‘ä»¬å¯ä»¥æ³¨æ„åˆ°ï¼Œå½“åæ–¹å·®å¤§äº0çš„æ—¶å€™ï¼Œä¸€èˆ¬æƒ…å†µä¸‹å¦‚æœå‡ºç°äº† $ X > \mu_X$ å°±åŸºæœ¬ä¸Šä¼šå‡ºç° $Y > \mu_Y$ ã€‚æ˜¯å¦ä¸€å®šä¼šå‡ºç° $Y > \mu_Y$ ï¼Ÿè¿™ä¸ªæ˜¯ä¸ç¡®å®šçš„ï¼Œä½†æ˜¯å‘ç”Ÿæ¦‚ç‡æå¤§ã€‚
åŒæ ·çš„æƒ…å†µé€‚åˆäºåæ–¹å·®æ˜¯è´Ÿæ•°ï¼Œæˆ–è€…$ X < \mu_X$ çš„æƒ…å†µ
å½“åæ–¹å·®æ˜¯0ï¼Œé‚£ä¹ˆ $X$ ä¸ $Y$ å¯¹åº”äºå…¶å‡å€¼çš„å¤§å°å˜æ¢æ¯”è¾ƒéšæ„ï¼Œæ²¡æœ‰å¤ªå¤§çš„ä¸€è‡´æ€§.

ä¸Šé¢ä»‹ç»çš„å°±æ˜¯åæ–¹å·®çš„ä¸€äº›æƒ…å†µï¼Œæ¥ä¸‹æ¥å°±æ˜¯ç›¸å…³æ€§çš„å¼•å…¥ã€‚
## ç›¸å…³æ€§ Correlation
ä»Šå¤©è®²è§£ä¸¤ä¸ªæ•°å­—ç‰¹å¾ï¼Œåæ–¹å·®å’Œç›¸å…³æ€§ï¼Œè¿™ä¸¤ä¸ªæ•°å­—ç‰¹å¾æœ€ç»ˆç›®çš„ä¸€æ ·éƒ½æ˜¯æƒ³æè¿°å¤šä¸ªå˜é‡ä¹‹é—´ä¸€è‡´æ€§å˜åŒ–çš„ç‰¹ç‚¹ï¼Œæ¯”å¦‚ï¼Œå½“ $X$ ä¸ºè¾ƒå¤§å€¼çš„æ—¶å€™  $Y$ æœ‰å¾ˆå¤§çš„å¯èƒ½å–è¾ƒå¤§å€¼ï¼Œæ³¨æ„ï¼Œæˆ‘ä»¬å‰é¢ç»™å‡ºçš„åæ–¹å·®çš„å¤§å°å°±æ˜¯è¿™ä¸ªå¯èƒ½æ€§çš„ä¸€ç§æè¿°ï¼Œä½†æ˜¯ï¼Œè¿™ä¸ªæè¿°ä¹Ÿæœ‰é—®é¢˜ï¼Œä»–ä¸ç¨³å®šï¼Œä¸ºå•¥ä¸ç¨³å®šï¼Œ
æ¯”å¦‚è¯´éšæœºå˜é‡ $X$ å’Œéšæœºå˜é‡ $Y$ ä»–ä»¬çš„åæ–¹å·®æ˜¯ $Cov(X,Y)$  æ ¹æ®åæ–¹å·®çš„è®¡ç®—æ³•åˆ™ï¼Œå½“æˆ‘ä»¬æŠŠéšæœºå˜é‡å˜æˆ $2X$ å’Œ $Y$ çš„æ—¶å€™ $Cov(2X,Y)=2Cov(X,Y)$ ï¼Œä½†ä»–ä»¬çš„ä¸€è‡´æ€§å…³ç³»åº”è¯¥æ˜¯ä¸å˜çš„ï¼Œåªæ˜¯å¯¹åº”çš„éšæœºå˜é‡çš„å¯èƒ½å€¼å˜åŒ–äº†ä¸å°‘ï¼Œä¸€è‡´æ€§å¹¶ä¸æ”¹å˜ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§æ•°å­—ç‰¹å¾èƒ½æè¿°è¿™ç§ä¸€è‡´æ€§ï¼Œä¸å› ä¸ºéšæœºå˜é‡ä¼¸ç¼©è€Œæ”¹å˜ã€‚

>Definition Correlation.Let X and Y be random variables with finite variances $\sigma^2_{X}$ and $\sigma^2_{Y}$ ,respectively. Then the correlation of $X$ and $Y$ ,which is denoted by $\rho(X,Y)$ ,is defined as follow:
$$
\rho(X,Y)=\frac{Cov(X,Y)}{\sigma_X^2 \sigma_Y^2}
$$

å›æƒ³ä¸€ä¸‹ï¼Œæˆ‘ä»¬ä¼¼ä¹è§è¿‡è¿™ç§æ¯”å€¼å½¢å¼çš„å®šä¹‰ï¼Œæ²¡é”™ï¼Œ4-4ä¸­çš„ååº¦ä¹Ÿæ˜¯è¿™ç§å®šä¹‰å½¢å¼ï¼Œå…¶ç»™å‡ºçš„è§£é‡Šå»é™¤åˆ†æ¯ä¸Šçš„ç‰¹å¾å¯¹ç›®æ ‡ç‰¹å¾çš„å½±å“ï¼Œäºæ˜¯æˆ‘ä»¬å¯ä»¥çœ‹å‡ºï¼Œå½“åæ–¹å·®å»é™¤åˆ†å¸ƒç¦»æ•£ç¨‹åº¦ä»¥åï¼Œå°±æ˜¯æˆ‘ä»¬çš„ç›¸å…³åº¦ç‰¹å¾äº†ã€‚
æ¥ç€æˆ‘ä»¬æœ‰ä¸€ä¸ªé‡è¦çš„ä¸ç­‰å¼éœ€è¦äº†è§£ã€‚
>Theorem Schwarz Inequality.For all random variables $U$ and $V$ such that $E(UV)$ exists,
$$
[E(UV)]^2\leq E(U^2)E(V^2)
$$
If,in addition,the right-hand side of $[E(UV)]^2\leq E(U^2)E(V^2)$ is finite,then the two sides of it equal the same value if and only if there are nonzero constants $a$ and $b$ such that $aU+bV=0$ with probability 1.

é¦–å…ˆç»™å‡ºäº†ä¸¤ä¸ªéšæœºå˜é‡çš„æœŸæœ›çš„ç›¸å…³ä¸ç­‰å¼ï¼Œæˆ‘ä»¬ä¼šåœ¨æ¥ä¸‹æ¥å®Œæˆè¯æ˜ï¼Œä½†æ˜¯è¡¥å……æ¡æ¬¾æ›´æœ‰æ„æ€ï¼Œè¯´çš„æ˜¯ï¼Œå°äºç­‰äºå·å³è¾¹å¦‚æœæ˜¯æœ‰é™çš„ï¼Œé‚£ä¹ˆç­‰å·æˆç«‹å½“ä¸”ä»…å½“å­˜åœ¨éé›¶å¸¸æ•° $a$ å’Œ $b$ ä½¿å¾— $aU+bV=0$ æ¨ªæˆç«‹ï¼ˆæˆ–è€…å«åšæ¦‚ç‡ä¸º1ï¼‰

é‚£ä¹ˆæˆ‘ä»¬æ¥è¯æ˜è¿™ä¸ªå®šç†ã€‚
è¯æ˜ï¼š
1. å¦‚æœ $E(U^2)=0$ é‚£ä¹ˆ $Pr(U=0)=1$ æ‰€ä»¥å¿…ç„¶æœ‰ $Pr(UV=0)=1$ é‚£ä¹ˆ $E(UV)=0$ äºæ˜¯ä¸ç­‰å¼æˆç«‹ã€‚
2. åŒç†å¯ä»¥è¯æ˜ $E(V^2)=0$ çš„æƒ…å†µã€‚
3. å½“ $E(U^2)$ æˆ–è€… $E(V^2)$  ä¸ºæ— é™çš„æ—¶å€™ï¼Œä¸ç­‰å¼ä¹Ÿæˆç«‹ã€‚
4. æ¥ä¸‹æ¥è¯æ˜ $0 < E(U^2) < \infty$ , $0 < E(V^2) < \infty$ çš„æƒ…å†µï¼Œå¯¹äºæ‰€æœ‰çš„ $a$ å’Œ $b$ é‚£ä¹ˆï¼š
ä¸ç­‰å¼ä¸€ï¼š
$$
0\leq E[(aU + bV)^2]=a^2E(U^2)+b^2E(V^2)+2abE(UV)
$$
ä»¥åŠï¼Œä¸ç­‰å¼äºŒï¼š
$$
0\leq E[(aU - bV)^2]=a^2E(U^2)+b^2E(V^2)-2abE(UV)
$$
å¦‚æœ ä»¤$a=[E(V^2)]^{1/2},b=[E(U^2)]^{1/2}$ é‚£ä¹ˆå°±æœ‰ä¸‹é¢çš„å…³ç³»ï¼š
ä¸ç­‰å¼ä¸‰ï¼š
$$
E(UV)\geq -[E(U^2)E(V^2)]^{1/2}
$$
æ ¹æ®ä¸ç­‰å¼äºŒï¼Œå°±æœ‰ä¸ç­‰å¼å››ï¼š
$$
E(UV)\leq [E(U^2)E(V^2)]^{1/2}
$$
ä¸Šé¢ä¸¤ä¸ªä¸ç­‰å¼ï¼Œä¸ç­‰å¼ä¸‰å’Œä¸ç­‰å¼å››å¾—å‡ºå®šç†ä¸­çš„ç»“è®ºã€‚
ä¸ç­‰å¼ä¸­ç­‰å·æˆç«‹ï¼Œå½“ä¸”ä»…å½“ä¸ç­‰å¼ä¸‰å’Œä¸ç­‰å¼å››ç­‰å·æˆç«‹ï¼Œä¸ç­‰å¼ä¸‰ç­‰å·æˆç«‹ï¼Œå½“ä¸”ä»…å½“ä¸ç­‰å¼ä¸€ç­‰äº0æˆç«‹ï¼Œä¹Ÿå°±æ˜¯å½“ä¸”ä»…å½“ $E[(aU+bV)^2]=0$ æˆç«‹ï¼Œå½“ä¸”ä»…å½“ $aU+bV=0$ æ’æˆç«‹ã€‚
åŒç†å¯ä»¥å¾—åˆ° $aU-bV=0$ æ’æˆç«‹ï¼Œè‡³æ­¤è¯æ¯•ï¼

>Theorem Cauchy-Schwarz Inequality.Let $X$ and $Y$ be random variables with finite variance.Then
$$
[Cov(X,Y)]^2\leq \sigma^2_X\sigma^2_Y
$$
and
$$
-1\leq \rho(X,Y)\leq 1
$$
Furthermor,the inequality in $[Cov(X,Y)]^2\leq \sigma^2_X\sigma^2_Y$ is an equality if and only if there are nonzero constants $a$ and $b$ and a constant $c$ such that $aX+bY=c$ with probability 1.

Cauchy-Schwarzä¸ç­‰å¼ï¼ŒæŸ¯è¥¿æ˜¯è°ä¸ä»‹ç»äº†ï¼ŒSchwarzç¿»è¯‘æˆä¸­æ–‡å«æ–½ç“¦èŒ¨ã€‚
è¿™ä¸ªä¸ç­‰å¼ç»™å‡ºäº†ç›¸å…³æ€§çš„å…³é”®ä¿¡æ¯ï¼Œä¹Ÿå°±æ˜¯ç›¸å…³æ€§åœ¨ $[-1,1]$ èŒƒå›´å†…ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•è¯æ˜ä»–ä»¬ï¼š
è¯æ˜
1. ä»¤$U=X-\mu_X$ å’Œ $V=Y-\mu_Y$
2.  æ ¹æ®åæ–¹å·®å®šç† $Cov(X,Y)=E(XY)-E(X)E(Y)$ å¯ä»¥ç›´æ¥å¾—åˆ° $[Cov(X,Y)]^2\leq \sigma^2_X\sigma^2_Y$
3. ç„¶åå°±å¯ä»¥å¾—åˆ° $-1\leq \rho(X,Y)\leq 1$ è¿™ä¸ªç»“è®º

è¿™ä¸ªè¯æ˜éå¸¸ç®€å•ï¼Œåªç”¨åˆ°äº†å‰é¢åæ–¹å·®çš„ä¸€ä¸ªè®¡ç®—å®šç†ï¼Œæ‰€ä»¥ï¼Œå¯è§ç›¸å…³æ€§åœ¨ $[-1,1]$ ä¹‹é—´æ³¢åŠ¨ã€‚

>Definition Positively/Negatively Correlation/Uncorrelated.It is said that $X$ and $Y$ are positively correlated if $\rho (X,Y)>0$ ,that $X$ and $Y$ are negatively correlated if $\rho(X,Y) < 0$ ,and that $X$ and $Y$ are uncorrelated if $\rho(X,Y)=0$

å®šä¹‰æ­£ç›¸å…³ï¼Œè´Ÿç›¸å…³ï¼Œè¿˜æ˜¯ä¸ç›¸å…³ã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬å°±è¦ç ”ç©¶åæ–¹å·®ï¼Œå’Œç›¸å…³æ€§çš„æ€§è´¨äº†ã€‚
## ç›¸å…³æ€§å’Œåæ–¹å·®çš„çš„æ€§è´¨ Properties of Covariance and Correlation
æ€§è´¨1ï¼šç‹¬ç«‹çš„éšæœºå˜é‡çš„ç›¸å…³æ€§
>If $X$ and $Y$ are independent random varibales with $0<\sigma^2_X<\infty$ and $0<\sigma^2_Y<\infty$ ,then
$$
Cov(X,Y)=\rho(X,Y)=0
$$

è¯æ˜ï¼Œå¦‚æœéšæœºå˜é‡ $X$ å’Œ $Y$ ç‹¬ç«‹ï¼Œé‚£ä¹ˆ $E(XY)=E(X)E(Y)$ ï¼Œæ ¹æ®å®šç† $Cov(X,Y)=E(XY)-E(X)E(Y)$  æœ‰ $Cov(X,Y)=0$ é‚£ä¹ˆå°±æœ‰ $\rho(X,Y)=0$
è¯æ¯•ã€‚

æ³¨æ„æ³¨æ„æ³¨æ„ï¼Œä¸¤ä¸ªå˜é‡ç‹¬ç«‹å¯ä»¥æ¨å¯¼å‡ºå…¶ç›¸å…³æ€§æ˜¯0ï¼Œä½†æ˜¯ç›¸å…³æ€§æ˜¯0å¹¶ä¸èƒ½æ¨åˆ°å‡ºéšæœºå˜é‡ç‹¬ç«‹ã€‚

-----------
è¿™é‡Œä¸¾ä¸ªä¾‹å­
éšæœºå˜é‡ $X,Y$ çš„è”åˆåˆ†å¸ƒæ˜¯åœ¨ä¸€ä¸ªåœ†èŒƒå›´å†…çš„å‡åŒ€åˆ†å¸ƒï¼Œå¯ä»¥å¾—åˆ°å…¶p.d.f. æ˜¯
$$
f(x)=
\begin{cases}
\frac{1}{2\pi}&\text{for } x^2+y^2 \leq 1\\
0&\text{otherwise }
\end{cases}
$$
å› ä¸ºéšæœºå˜é‡å˜åŒ–èŒƒå›´æ˜¯ä¸ªåœ†è€Œä¸æ˜¯çŸ©å½¢ï¼Œæ‰€ä»¥å¾ˆæ˜æ˜¾ Xå’ŒYä¸ç‹¬ç«‹ï¼ˆå‚è€ƒ[éšæœºå˜é‡çš„ç‹¬ç«‹æ€§](https://face2ai.com/Math-Probability-3-5-Marginal-Distributions/)ï¼‰ï¼Œä½†æ˜¯å¯ä»¥è®¡ç®—å…¶åæ–¹å·®ä¸º $Cov(X,Y)=E[XY]-E[X]E[Y]=0-0=0$ é‚£ä¹ˆå…¶ç›¸å…³æ€§ä¹Ÿæ˜¯ 0 ï¼Œäºæ˜¯ç›¸å…³çš„ä¸¤ä¸ªéšæœºå˜é‡ï¼Œå…¶åæ–¹å·®ï¼Œç›¸å…³æ€§ä¹Ÿå¯ä»¥æ˜¯0.
![](./circle.png)

---------

æ€§è´¨2ï¼šå¦‚æœä¸¤ä¸ªéšæœºå˜é‡æ˜¯çº¿æ€§å…³ç³»ï¼Œé‚£ä¹ˆç›¸å…³æ€§ä¸º1
>Theorem Suppose that $X$ is a random variable such that $0<\sigma^2_X<\infty$ ,and $Y=aX+b$ for some constants $a$ and $b$ ,where $a\neq 0$ ,If $a > 0$ the $\rho(X < Y)=1$ If $a < 0$ ,then $\rho(X,Y)=-1$

è¯æ˜ï¼š
1. å¦‚æœ $y=ax+b$
2. é‚£ä¹ˆ $\mu_Y=a\mu_X+b$ ,$Y-\mu_Y=a(X-\mu_X)$
3. æ ¹æ®åæ–¹å·®å®šä¹‰æœ‰ $Cov(X,Y)=aE[(X-\mu_X)^2]=a\sigma^2_X$
4. å› ä¸ºæœ‰ $\sigma_Y=|a|\sigma_X$ æ‰€ä»¥å®šç†ç»“è®ºå¾—åˆ°è¯æ˜ ï¼ˆè¿™æ­¥å¯ç”±æŸ¯è¥¿-æ–½ç“¦èŒ¨ä¸ç­‰å¼å¾—å‡ºï¼‰
5. è¯æ¯•

è¿™ä¸ªå®šç†å‘Šè¯‰æˆ‘ä»¬ï¼Œç›¸å…³æ€§å°±æ˜¯è¡¡é‡ä¸¤ä¸ªéšæœºå˜é‡çš„çº¿æ€§ç›¸å…³ç¨‹åº¦çš„ã€‚è¶Šæ¥è¿‘çº¿æ€§ï¼Œç›¸å…³æ€§çš„ç»å¯¹å€¼è¶Šæ¥è¿‘1ï¼Œåä¹‹è¶Šæ¥è¿‘0ï¼Œ
æ³¨æ„ç›¸å…³æ€§åªç”¨æ¥è¡¡é‡çº¿æ€§ç›¸å…³ã€‚ç›¸å…³æ€§è¶Šæ¥è¿‘é›¶å¹¶ä¸ä»£è¡¨éšæœºå˜é‡ä¸ç›¸å…³ï¼Œè€Œæ˜¯åªä»£è¡¨ä»–ä»¬ä¸çº¿æ€§ç›¸å…³ã€‚

æ€§è´¨ä¸‰ï¼šä¸¤ä¸ªéšæœºå˜é‡ç›¸åŠ ï¼Œå…¶åæ–¹å·®å’Œå•ä¸ªå˜é‡æ–¹å·®çš„å…³ç³»
>Theorem If $X$ and $Y$ are random variables such that $Var(X)<\infty$ and $Var(Y)<\infty$ ,then
$$
Var(X+Y)=Var(X)+Var(Y)-2Cov(X,Y)
$$

è¯æ˜ï¼š
å› ä¸º $E[X+Y]=\mu_X+\mu_Y$ ,æ‰€ä»¥
$$
\begin{aligned}
Var(X+Y)&=E[(X+Y-\mu_X-\mu_Y)^2]\\
&=E[(X-\mu_X)^2+(Y-\mu_Y)^2+2(X-\mu_X)(Y-\mu_Y)]\\
&=Var(X)+Var(Y)+2Cov(X,Y)
\end{aligned}
$$
ç®€å•çš„è®¡ç®—ï¼Œå°±ä¸å•°å—¦äº†ã€‚

æ¥ç€æ˜¯ä¸€ä¸ªæ¨è®ºï¼Œåœ¨ä¸Šé¢å®šç†æˆç«‹çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æœ‰ï¼š
>Corollary Let a,b and c be constants.Under the conditions of theorem upside
$$
Var(aX+bY+c)=a^2Var(X)+b^2Var(Y)+2abCov(X,Y)
$$

è¿˜æœ‰ä¸€ç§ç‰¹æ®Šçš„æƒ…å†µå°±æ˜¯
$$
Var(X-Y)=Var(X)+Var(Y)-2Cov(X,Y)
$$

æ€§è´¨å››ï¼šæ ¹æ®æ€§è´¨ä¸‰æ¨å¹¿åˆ°å¤šä¸ªéšæœºå˜é‡çš„æƒ…å†µï¼š
>Theorem If $X_1,\dots,X_n$ are random variables scuh that $Var(X_i)<\infty$ for $i=0,\dots,n$ then
$$
Var(\sum^{n}_{i=1}X_i)=\sum^{n}_{i=1}Var(X_i)+2{\sum\sum}_{i<j}Cov(X_i,X_j)
$$
è¿™ä¸ªå®šç†çš„è¯æ˜ç›¸å¯¹è¦éº»çƒ¦ç‚¹ï¼Œ
è¯æ˜ï¼š
1. é¦–å…ˆ
$$
Var(\sum^{n}_{i=1}X_i)=Cov(\sum^{n}_{i=1}X_i,\sum^{n}_{j=1}X_j)=\sum^{n}_{i=1}\sum^{n}_{j=1}Cov(X_i,X_j)
$$
2. æŠŠä¸Šé¢çš„æ±‚å’Œåˆ†æˆä¸¤éƒ¨åˆ†ä¸€éƒ¨åˆ†æ˜¯ $i=j$ ä¸€éƒ¨åˆ†æ˜¯ $i\neq j$ ï¼Œå› ä¸º $Var(x_i,x_j)=Var(x_j,x_i)$
$$
\begin{aligned}
Var(\sum^{n}_{i=1}X_i)&=\sum^{n}_{i=1}Varï¼ˆX_iï¼‰+{\sum\sum}_{i\neq j}Cov(X_i,X_j)\\
&=\sum^{n}_{i=1}Var(X_i)+2{\sum\sum}_{i<j}Cov(X_i,X_j)
\end{aligned}
$$

è¯æ˜è¿‡ç¨‹å¤§è‡´å¦‚ä¸Šæ‰€è¿°ï¼Œå¾ˆç®€å•çš„è®¡ç®—è¿‡ç¨‹ï¼Œå¦‚æœ‰ç–‘é—®å¯ä»¥å»å‚è€ƒä¸‹åŸæ–‡

ä¸Šè¿°å®šç†å¾—å‡ºä¸€ä¸ªæ¨è®º
>Corollary If $X_1,\dots,X_n$ are uncorrelated random varibales,then
$$
Var(\sum^{n}_{i=1}X_i)=\sum^{n}_{i=1}Var(X_i)
$$

## æ€»ç»“
ä»Šå¤©ä¸€ä¸‹ä»‹ç»äº†ä¸¤ä¸ªå¤šéšæœºå˜é‡çš„æ•°å­—ç‰¹å¾ï¼Œæ‰€æè¿°çš„æ€§è´¨ç±»ä¼¼ï¼Œä½†æ˜¯åˆå„æœ‰å„çš„ç”¨æ³•ï¼Œè¿™éƒ¨åˆ†å†…å®¹åœ¨æœºå™¨å­¦ä¹ ä¸­éå¸¸å¸¸è§ï¼Œå¤§å®¶è¦å¥½å¥½ç ”ç©¶ï¼Œå¤šåšç»ƒä¹ ã€‚
å¾…ç»­ã€‚ã€‚ã€‚





